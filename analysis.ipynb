{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Simulation Log (JSON) to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation_root = \"C:/kerta/AppData/LocalLow/DefaultCompany/Sumobot/Simulation\"\n",
    "# output_folder = \"D:/Simulation_CSV\"\n",
    "simulation_root = \"/Users/defdef/Library/Application Support/DefaultCompany/Sumobot/Simulation\"\n",
    "csv_folder = \"/Users/defdef/Documents/Simulation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION CODE\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_game_index(filename: str) -> int:\n",
    "    \"\"\"Extract numeric index from filename like 'game_001.json'.\"\"\"\n",
    "    match = re.search(r\"game_(\\d+)\", filename)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "\n",
    "def escape_csv(value: str) -> str:\n",
    "    \"\"\"Escape CSV fields like C# version.\"\"\"\n",
    "    if any(c in value for c in [',', '\"', '\\n']):\n",
    "        return '\"' + value.replace('\"', '\"\"') + '\"'\n",
    "    return value\n",
    "\n",
    "\n",
    "def safe_int(value, default=\"\") -> str:\n",
    "    \"\"\"Convert to int string, return default if None/empty.\"\"\"\n",
    "    if value is None or value == \"\":\n",
    "        return default\n",
    "    try:\n",
    "        return str(int(value))\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "\n",
    "def safe_float(value, default=\"\") -> str:\n",
    "    \"\"\"Convert to float string with consistent precision, return default if None/empty.\"\"\"\n",
    "    if value is None or value == \"\":\n",
    "        return default\n",
    "    try:\n",
    "        return f\"{float(value):.10g}\"  # Use general format, up to 10 significant digits\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "\n",
    "def safe_bool(value) -> str:\n",
    "    \"\"\"Convert boolean to '1' or '0'.\"\"\"\n",
    "    return \"1\" if value else \"0\"\n",
    "\n",
    "\n",
    "def safe_str(value, default=\"\") -> str:\n",
    "    \"\"\"Convert to string, handling None.\"\"\"\n",
    "    if value is None or value == \"\":\n",
    "        return default\n",
    "    return str(value)\n",
    "\n",
    "\n",
    "def convert_logs_to_csv(folder_path: str, output_path: str):\n",
    "    \"\"\"Convert all game_*.json files in folder to one CSV.\"\"\"\n",
    "    csv_rows = []\n",
    "\n",
    "    files = sorted(\n",
    "        glob(os.path.join(folder_path, \"game_*.json\")),\n",
    "        key=lambda f: extract_game_index(os.path.basename(f))\n",
    "    )\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing {folder_path}\", ncols=100):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            root = json.load(f)\n",
    "\n",
    "        game_index = root.get(\"Index\", -1)\n",
    "        game_timestamp = root.get(\"Timestamp\", \"\")\n",
    "        game_winner = root.get(\"Winner\", \"\")\n",
    "\n",
    "        rounds = root.get(\"Rounds\", [])\n",
    "        for round_data in rounds:\n",
    "            round_index = round_data.get(\"Index\", -1)\n",
    "            round_timestamp = round_data.get(\"Timestamp\", \"\")\n",
    "            round_winner = round_data.get(\"Winner\", \"\")\n",
    "\n",
    "            player_events = round_data.get(\"PlayerEvents\", [])\n",
    "            for event_log in player_events:\n",
    "                if event_log.get(\"Category\") == \"LastPosition\":\n",
    "                    continue\n",
    "\n",
    "                row = {\n",
    "                    \"GameIndex\": safe_int(game_index + 1),\n",
    "                    \"GameWinner\": \"2\" if game_winner == \"Draw\" else \"0\" if game_winner == \"Left\" else \"1\",\n",
    "                    \"GameTimestamp\": safe_str(game_timestamp),\n",
    "                    \"RoundIndex\": safe_int(round_index),\n",
    "                    \"RoundWinner\": \"2\" if round_winner == \"Draw\" else \"0\" if round_winner == \"Left\" else \"1\",\n",
    "                    \"RoundTimestamp\": safe_str(round_timestamp),\n",
    "                    \"StartedAt\": safe_float(event_log.get(\"StartedAt\")),\n",
    "                    \"UpdatedAt\": safe_float(event_log.get(\"UpdatedAt\")),\n",
    "                    \"Actor\": \"0\" if event_log.get(\"Actor\") == \"Left\" else \"1\",\n",
    "                }\n",
    "\n",
    "                target = event_log.get(\"Target\", \"\")\n",
    "                row[\"Target\"] = \"\" if target == \"\" else \"0\" if target == \"Left\" else \"1\"\n",
    "                row[\"Category\"] = safe_str(event_log.get(\"Category\"))\n",
    "                row[\"State\"] = safe_str(event_log.get(\"State\"))\n",
    "\n",
    "                act = event_log.get(\"Data\")\n",
    "                if act:\n",
    "                    row[\"Name\"] = safe_str(act.get(\"Name\"))\n",
    "                    row[\"Duration\"] = safe_float(act.get(\"Duration\"))\n",
    "                    reason = act.get(\"Reason\")\n",
    "                    row[\"Reason\"] = \"\" if reason is None or str(reason) == \"None\" else safe_str(reason)\n",
    "\n",
    "                    robot = act.get(\"Robot\")\n",
    "                    if robot:\n",
    "                        pos = robot.get(\"Position\", {})\n",
    "                        row.update({\n",
    "                            \"BotPosX\": safe_float(pos.get(\"X\")),\n",
    "                            \"BotPosY\": safe_float(pos.get(\"Y\")),\n",
    "                            \"BotLinv\": safe_float(robot.get(\"LinearVelocity\")),\n",
    "                            \"BotAngv\": safe_float(robot.get(\"AngularVelocity\")),\n",
    "                            \"BotRot\": safe_float(robot.get(\"Rotation\")),\n",
    "                            \"BotIsDashActive\": safe_bool(robot.get(\"IsDashActive\")),\n",
    "                            \"BotIsSkillActive\": safe_bool(robot.get(\"IsSkillActive\")),\n",
    "                            \"BotIsOutFromArena\": safe_bool(robot.get(\"IsOutFromArena\")),\n",
    "                        })\n",
    "\n",
    "                    enemy = act.get(\"EnemyRobot\")\n",
    "                    if enemy:\n",
    "                        pos = enemy.get(\"Position\", {})\n",
    "                        row.update({\n",
    "                            \"EnemyBotPosX\": safe_float(pos.get(\"X\")),\n",
    "                            \"EnemyBotPosY\": safe_float(pos.get(\"Y\")),\n",
    "                            \"EnemyBotLinv\": safe_float(enemy.get(\"LinearVelocity\")),\n",
    "                            \"EnemyBotAngv\": safe_float(enemy.get(\"AngularVelocity\")),\n",
    "                            \"EnemyBotRot\": safe_float(enemy.get(\"Rotation\")),\n",
    "                            \"EnemyBotIsDashActive\": safe_bool(enemy.get(\"IsDashActive\")),\n",
    "                            \"EnemyBotIsSkillActive\": safe_bool(enemy.get(\"IsSkillActive\")),\n",
    "                            \"EnemyBotIsOutFromArena\": safe_bool(enemy.get(\"IsOutFromArena\")),\n",
    "                        })\n",
    "\n",
    "                if event_log.get(\"Category\") == \"Collision\":\n",
    "                    col_data = event_log.get(\"Data\", {})\n",
    "                    row[\"ColActor\"] = safe_bool(col_data.get(\"IsActor\"))\n",
    "                    row[\"ColImpact\"] = safe_float(col_data.get(\"Impact\"))\n",
    "                    row[\"ColTieBreaker\"] = safe_bool(col_data.get(\"IsTieBreaker\"))\n",
    "                    row[\"ColLockDuration\"] = safe_float(col_data.get(\"LockDuration\"))\n",
    "\n",
    "                    col_robot = col_data.get(\"Robot\")\n",
    "                    if col_robot:\n",
    "                        pos = col_robot.get(\"Position\", {})\n",
    "                        row.update({\n",
    "                            \"ColBotPosX\": safe_float(pos.get(\"X\")),\n",
    "                            \"ColBotPosY\": safe_float(pos.get(\"Y\")),\n",
    "                            \"ColBotLinv\": safe_float(col_robot.get(\"LinearVelocity\")),\n",
    "                            \"ColBotAngv\": safe_float(col_robot.get(\"AngularVelocity\")),\n",
    "                            \"ColBotRot\": safe_float(col_robot.get(\"Rotation\")),\n",
    "                            \"ColBotIsDashActive\": safe_bool(col_robot.get(\"IsDashActive\")),\n",
    "                            \"ColBotIsSkillActive\": safe_bool(col_robot.get(\"IsSkillActive\")),\n",
    "                            \"ColBotIsOutFromArena\": safe_bool(col_robot.get(\"IsOutFromArena\")),\n",
    "                        })\n",
    "\n",
    "                    col_enemy = col_data.get(\"EnemyRobot\")\n",
    "                    if col_enemy:\n",
    "                        pos = col_enemy.get(\"Position\", {})\n",
    "                        row.update({\n",
    "                            \"ColEnemyBotPosX\": safe_float(pos.get(\"X\")),\n",
    "                            \"ColEnemyBotPosY\": safe_float(pos.get(\"Y\")),\n",
    "                            \"ColEnemyBotLinv\": safe_float(col_enemy.get(\"LinearVelocity\")),\n",
    "                            \"ColEnemyBotAngv\": safe_float(col_enemy.get(\"AngularVelocity\")),\n",
    "                            \"ColEnemyBotRot\": safe_float(col_enemy.get(\"Rotation\")),\n",
    "                            \"ColEnemyBotIsDashActive\": safe_bool(col_enemy.get(\"IsDashActive\")),\n",
    "                            \"ColEnemyBotIsSkillActive\": safe_bool(col_enemy.get(\"IsSkillActive\")),\n",
    "                            \"ColEnemyBotIsOutFromArena\": safe_bool(col_enemy.get(\"IsOutFromArena\")),\n",
    "                        })\n",
    "\n",
    "                csv_rows.append(row)\n",
    "\n",
    "    # Collect all CSV columns\n",
    "    preferred_order = [\n",
    "        \"GameIndex\",\"GameWinner\",\"GameTimestamp\",\"RoundIndex\",\"RoundWinner\",\"RoundTimestamp\",\"StartedAt\",\"UpdatedAt\",\"Actor\",\"Target\",\"Category\",\"State\",\"Name\",\"Duration\",\"Reason\",\"BotPosX\",\"BotPosY\",\"BotLinv\",\"BotAngv\",\"BotRot\",\"BotIsDashActive\",\"BotIsSkillActive\",\"BotIsOutFromArena\",\"EnemyBotPosX\",\"EnemyBotPosY\",\"EnemyBotLinv\",\"EnemyBotAngv\",\"EnemyBotRot\",\"EnemyBotIsDashActive\",\"EnemyBotIsSkillActive\",\"EnemyBotIsOutFromArena\",\"ColActor\",\"ColImpact\",\"ColTieBreaker\",\"ColLockDuration\",\"ColBotPosX\",\"ColBotPosY\",\"ColBotLinv\",\"ColBotAngv\",\"ColBotRot\",\"ColBotIsDashActive\",\"ColBotIsSkillActive\",\"ColBotIsOutFromArena\",\"ColEnemyBotPosX\",\"ColEnemyBotPosY\",\"ColEnemyBotLinv\",\"ColEnemyBotAngv\",\"ColEnemyBotRot\",\"ColEnemyBotIsDashActive\",\"ColEnemyBotIsSkillActive\",\"ColEnemyBotIsOutFromArena\"\n",
    "    ]\n",
    "    # Merge preferred order with dynamically discovered keys\n",
    "    all_keys = preferred_order + [k for k in {kk for d in csv_rows for kk in d.keys()} if k not in preferred_order]\n",
    "\n",
    "\n",
    "    with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(all_keys)\n",
    "        for row in csv_rows:\n",
    "            writer.writerow([row.get(k, \"\") for k in all_keys])\n",
    "\n",
    "    print(f\"âœ… Saved CSV: {output_path}\")\n",
    "\n",
    "\n",
    "def convert_all_configs(simulation_root: str, output_root: str):\n",
    "    \"\"\"Convert all config folders recursively (Timer_*).\"\"\"\n",
    "    config_folders = []\n",
    "    for root, dirs, _ in os.walk(simulation_root):\n",
    "        for d in dirs:\n",
    "            if d.startswith(\"Timer_\"):\n",
    "                config_folders.append(os.path.join(root, d))\n",
    "    \n",
    "    for i, config_folder in enumerate(config_folders, 1):\n",
    "        config_name = os.path.basename(config_folder)\n",
    "        parent_name = os.path.basename(os.path.dirname(config_folder))\n",
    "\n",
    "        print(f\"DEBUG: config_folder = {config_folder}\")\n",
    "        print(f\"DEBUG: parent_name = {parent_name}\")\n",
    "        print(f\"DEBUG: config_name = {config_name}\")\n",
    "\n",
    "        \n",
    "        # Create output folder with parent structure if it doesn't exist\n",
    "        output_folder = os.path.join(output_root, parent_name, config_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        output_path = os.path.join(output_folder, f\"{config_name}.csv\")\n",
    "        \n",
    "        if os.path.isfile(output_path):\n",
    "            print(f\"[{i}/{len(config_folders)}] Skipped {config_name} already exists\")\n",
    "            continue\n",
    "        \n",
    "        # Check if CSV exists in original location, move it instead of regenerating\n",
    "        old_csv_path = os.path.join(config_folder, f\"{config_name}.csv\")\n",
    "        if os.path.isfile(old_csv_path):\n",
    "            shutil.move(old_csv_path, output_path)\n",
    "            print(f\"[{i}/{len(config_folders)}] Moved {config_name} to output folder\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"[{i}/{len(config_folders)}] Processing {config_name}\")\n",
    "        convert_logs_to_csv(config_folder, output_path)\n",
    "        config_name = os.path.basename(config_folder)\n",
    "        \n",
    "        # Create output folder if it doesn't exist\n",
    "        output_folder = os.path.join(output_root, parent_name,config_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        output_path = os.path.join(output_folder, f\"{config_name}.csv\")\n",
    "        \n",
    "        if os.path.isfile(output_path):\n",
    "            print(f\"[{i}/{len(config_folders)}] Skipped {config_name} already exists\")\n",
    "            continue\n",
    "        \n",
    "        # Check if CSV exists in original location, move it instead of regenerating\n",
    "        old_csv_path = os.path.join(config_folder, f\"{config_name}.csv\")\n",
    "        if os.path.isfile(old_csv_path):\n",
    "            shutil.move(old_csv_path, output_path)\n",
    "            print(f\"[{i}/{len(config_folders)}] Moved {config_name} to output folder\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"[{i}/{len(config_folders)}] Processing {config_name}\")\n",
    "        convert_logs_to_csv(config_folder, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_all_configs(simulation_root,csv_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from functools import lru_cache\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd  # For pd.cut in time bins\n",
    "\n",
    "# Check if GPU support is available\n",
    "GPU_AVAILABLE = False\n",
    "try:\n",
    "    # Try a simple GPU operation to check availability\n",
    "    pl.LazyFrame({\"test\": [1]}).collect(engine=\"gpu\")\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"GPU support available - will use GPU acceleration\")\n",
    "except Exception:\n",
    "    print(\"Using CPU (GPU not available)\")\n",
    "\n",
    "\n",
    "def collect_with_gpu(lf):\n",
    "    \"\"\"Helper to collect LazyFrame with GPU if available\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        return lf.collect(engine=\"gpu\")\n",
    "    else:\n",
    "        return lf.collect()\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def parse_config_name_cached(name):\n",
    "    return parse_config_name(name)\n",
    "\n",
    "\n",
    "def parse_config_name(config_name: str):\n",
    "    \"\"\"Extract structured info from config folder name\"\"\"\n",
    "    segments = config_name.split(\"__\")\n",
    "    config = {}\n",
    "\n",
    "    for seg in segments:\n",
    "        if \"_\" in seg:\n",
    "            key, value = seg.split(\"_\", 1)\n",
    "            config[key] = value\n",
    "        else:\n",
    "            config[seg] = True\n",
    "\n",
    "    for k, v in config.items():\n",
    "        if isinstance(v, str) and re.match(r\"^-?\\d+(\\.\\d+)?$\", v):\n",
    "            config[k] = float(v)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def process_batch_csvs(csv_paths, batch_checkpoint_dir=\"batched\", time_bin_size=None, compute_timebins=False):\n",
    "    \"\"\"\n",
    "    Process a batch of CSV files and create checkpoint\n",
    "\n",
    "    Args:\n",
    "        csv_paths: List of CSV file paths to process\n",
    "        batch_checkpoint_dir: Directory to save checkpoints\n",
    "        time_bin_size: Size of time bins (only used if compute_timebins=True)\n",
    "        compute_timebins: Whether to compute time-binned data\n",
    "\n",
    "    Returns:\n",
    "        tuple: (batch_df, action_timebin_df, collision_timebin_df) or (batch_df, None, None)\n",
    "    \"\"\"\n",
    "    os.makedirs(batch_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    all_games_list = []\n",
    "    time_fragment_list = [] if compute_timebins else None\n",
    "    collision_fragment_list = [] if compute_timebins else None\n",
    "\n",
    "    for csv_path in csv_paths:\n",
    "        # Extract bot names and config from path\n",
    "        # Expected path: base_dir/BotA_vs_BotB/ConfigName/log.csv\n",
    "        parts = csv_path.split(os.sep)\n",
    "        matchup_folder = parts[-3]\n",
    "        config_folder = parts[-2]\n",
    "\n",
    "        match = re.match(r\"(.+)_vs_(.+)\", matchup_folder)\n",
    "        if not match:\n",
    "            continue\n",
    "        bot_a, bot_b = match.groups()\n",
    "\n",
    "        # Parse config\n",
    "        config = parse_config_name_cached(config_folder)\n",
    "\n",
    "        # Scan CSV with Polars lazy API\n",
    "        lf = pl.scan_csv(csv_path)\n",
    "\n",
    "        # Process game metrics\n",
    "        game_metrics_lf = process_single_csv_lazy(\n",
    "            lf,\n",
    "            bot_a,\n",
    "            bot_b,\n",
    "            config.get('Timer'),\n",
    "            config.get('ActInterval'),\n",
    "            config.get('Round'),\n",
    "            config.get('SkillLeft'),\n",
    "            config.get('SkillRight')\n",
    "        )\n",
    "\n",
    "        # Collect the results\n",
    "        game_metrics_df = collect_with_gpu(game_metrics_lf)\n",
    "        all_games_list.append(game_metrics_df)\n",
    "\n",
    "        # Process time bins if requested\n",
    "        if compute_timebins and time_bin_size:\n",
    "            # Process action time bins\n",
    "            action_tb = process_action_timebins_single_csv(\n",
    "                lf, bot_a, bot_b, config, time_bin_size\n",
    "            )\n",
    "            if action_tb:\n",
    "                time_fragment_list.extend(action_tb)\n",
    "\n",
    "            # Process collision time bins\n",
    "            collision_tb = process_collision_timebins_single_csv(\n",
    "                lf, bot_a, bot_b, config, time_bin_size\n",
    "            )\n",
    "            if collision_tb:\n",
    "                collision_fragment_list.extend(collision_tb)\n",
    "\n",
    "    # Concatenate all games from this batch\n",
    "    batch_df = None\n",
    "    action_timebin_df = None\n",
    "    collision_timebin_df = None\n",
    "\n",
    "    if all_games_list:\n",
    "        batch_df = pl.concat(all_games_list)\n",
    "\n",
    "    if compute_timebins:\n",
    "        if time_fragment_list:\n",
    "            action_timebin_df = pl.DataFrame(time_fragment_list)\n",
    "        if collision_fragment_list:\n",
    "            collision_timebin_df = pl.DataFrame(collision_fragment_list)\n",
    "\n",
    "    return batch_df, action_timebin_df, collision_timebin_df\n",
    "\n",
    "\n",
    "def process_action_timebins_single_csv(lf, bot_a, bot_b, config, time_bin_size):\n",
    "    \"\"\"\n",
    "    Process action time bins for a single CSV file\n",
    "    Returns list of time-binned action records\n",
    "    \"\"\"\n",
    "    # Scan and filter for actions\n",
    "    raw_data = lf.filter(\n",
    "        (pl.col(\"Category\") == \"Action\") & (pl.col(\"State\").cast(pl.Int32) != 2)\n",
    "    ).select([\n",
    "        \"GameIndex\", \"Actor\", \"UpdatedAt\", \"Name\"\n",
    "    ])\n",
    "\n",
    "    # Add match duration per game\n",
    "    match_dur_lf = lf.group_by(\"GameIndex\").agg([\n",
    "        pl.col(\"UpdatedAt\").max().alias(\"match_duration\")\n",
    "    ])\n",
    "\n",
    "    raw_data = raw_data.join(match_dur_lf, on=\"GameIndex\", how=\"left\")\n",
    "    raw_data_df = collect_with_gpu(raw_data)\n",
    "\n",
    "    time_fragment_list = []\n",
    "\n",
    "    # Process time bins per game\n",
    "    for game_idx in raw_data_df['GameIndex'].unique():\n",
    "        game_df = raw_data_df.filter(pl.col('GameIndex') == game_idx)\n",
    "        match_dur = game_df['match_duration'][0]\n",
    "\n",
    "        bins = np.arange(0, match_dur + time_bin_size, time_bin_size)\n",
    "        if len(bins) < 2:\n",
    "            continue\n",
    "\n",
    "        game_pd = game_df.to_pandas()\n",
    "\n",
    "        for side in [0, 1]:\n",
    "            actor_data = game_pd[game_pd['Actor'] == side]\n",
    "            if len(actor_data) == 0:\n",
    "                continue\n",
    "\n",
    "            actor_data = actor_data.copy()\n",
    "            actor_data['TimeBin'] = pd.cut(actor_data['UpdatedAt'], bins=bins,\n",
    "                                           labels=bins[:-1], include_lowest=True)\n",
    "\n",
    "            grouped = actor_data.groupby(['TimeBin', 'Name'], observed=False).size().reset_index(name='Count')\n",
    "\n",
    "            for _, row in grouped.iterrows():\n",
    "                time_fragment_list.append({\n",
    "                    'GameIndex': game_idx,\n",
    "                    'Bot': bot_a if side == 0 else bot_b,\n",
    "                    'Timer': config.get('Timer'),\n",
    "                    'ActInterval': config.get('ActInterval'),\n",
    "                    'Round': config.get('Round'),\n",
    "                    'SkillLeft': config.get('SkillLeft'),\n",
    "                    'SkillRight': config.get('SkillRight'),\n",
    "                    'TimeBin': float(row['TimeBin']),\n",
    "                    'Action': row['Name'],\n",
    "                    'Count': row['Count']\n",
    "                })\n",
    "\n",
    "    return time_fragment_list\n",
    "\n",
    "\n",
    "def process_collision_timebins_single_csv(lf, bot_a, bot_b, config, time_bin_size):\n",
    "    \"\"\"\n",
    "    Process collision time bins for a single CSV file\n",
    "    Returns list of time-binned collision records\n",
    "    \"\"\"\n",
    "    # Scan and filter for collisions\n",
    "    raw_data = lf.filter(\n",
    "        (pl.col(\"Category\") == \"Collision\") & (pl.col(\"State\") == 0)\n",
    "    ).select([\n",
    "        \"GameIndex\", \"Actor\", \"ColTieBreaker\", \"ColActor\", \"UpdatedAt\"\n",
    "    ])\n",
    "\n",
    "    # Add match duration per game\n",
    "    match_dur_lf = lf.group_by(\"GameIndex\").agg([\n",
    "        pl.col(\"UpdatedAt\").max().alias(\"match_duration\")\n",
    "    ])\n",
    "\n",
    "    raw_data = raw_data.join(match_dur_lf, on=\"GameIndex\", how=\"left\")\n",
    "    raw_data_df = collect_with_gpu(raw_data)\n",
    "\n",
    "    collision_fragment_list = []\n",
    "\n",
    "    # Process collision time bins per game\n",
    "    for game_idx in raw_data_df['GameIndex'].unique():\n",
    "        game_df = raw_data_df.filter(pl.col('GameIndex') == game_idx)\n",
    "        match_dur = game_df['match_duration'][0]\n",
    "\n",
    "        bins = np.arange(0, match_dur + time_bin_size, time_bin_size)\n",
    "        if len(bins) < 2:\n",
    "            continue\n",
    "\n",
    "        game_pd = game_df.to_pandas()\n",
    "        game_pd['TimeBin'] = pd.cut(game_pd['UpdatedAt'], bins=bins,\n",
    "                                   labels=bins[:-1], include_lowest=True)\n",
    "\n",
    "        for time_bin, bin_data in game_pd.groupby('TimeBin', observed=False):\n",
    "            actor_L_count = len(bin_data[(bin_data['Actor'] == True) &\n",
    "                                        (bin_data['ColTieBreaker'] == False) &\n",
    "                                        (bin_data[\"ColActor\"] == True)])\n",
    "            # print(f\"actor_L_count {actor_L_count}\")\n",
    "            actor_R_count = len(bin_data[(bin_data['Actor'] == False) &\n",
    "                                        (bin_data['ColTieBreaker'] == False) &\n",
    "                                        (bin_data[\"ColActor\"] == True)])\n",
    "\n",
    "            tie = bin_data['ColTieBreaker'].sum() if 'ColTieBreaker' in bin_data.columns else 0\n",
    "\n",
    "            collision_fragment_list.append({\n",
    "                'GameIndex': game_idx,\n",
    "                'Bot_L': bot_a,\n",
    "                'Bot_R': bot_b,\n",
    "                'Timer': config.get('Timer'),\n",
    "                'ActInterval': config.get('ActInterval'),\n",
    "                'Round': config.get('Round'),\n",
    "                'SkillLeft': config.get('SkillLeft'),\n",
    "                'SkillRight': config.get('SkillRight'),\n",
    "                'TimeBin': float(time_bin),\n",
    "                'Actor_L': actor_L_count,\n",
    "                'Actor_R': actor_R_count,\n",
    "                'Tie': int(tie),\n",
    "            })\n",
    "\n",
    "    return collision_fragment_list\n",
    "\n",
    "\n",
    "def process_single_csv_lazy(lf, bot_a, bot_b, timer, act_interval, round_val, skill_left, skill_right):\n",
    "    \"\"\"\n",
    "    Process a single CSV file using lazy evaluation\n",
    "    Implements the same aggregation logic as process_all_games_sql\n",
    "    Each CSV can contain multiple games (GameIndex)\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter for actions only\n",
    "    action_data = lf.filter(pl.col(\"Category\") == \"Action\")\n",
    "\n",
    "    # Compute durations with window function (lag by game/actor/name)\n",
    "    action_with_lag = action_data.with_columns([\n",
    "        pl.col(\"StartedAt\").shift(1).over([\"GameIndex\", \"Actor\", \"Name\"], order_by=\"UpdatedAt\").alias(\"prev_started_at\")\n",
    "    ])\n",
    "\n",
    "    # Compute actual durations per game/actor/action\n",
    "    action_durations = action_with_lag.group_by([\"GameIndex\", \"Actor\", \"Name\"]).agg([\n",
    "        pl.when((pl.col(\"State\").cast(pl.Int32) == 2) & pl.col(\"prev_started_at\").is_not_null())\n",
    "          .then(pl.col(\"UpdatedAt\") - pl.col(\"prev_started_at\"))\n",
    "          .otherwise(0)\n",
    "          .sum()\n",
    "          .alias(\"ActualDuration\")\n",
    "    ])\n",
    "\n",
    "    # Action counts per game/actor/action\n",
    "    action_counts = action_data.filter(pl.col(\"State\").cast(pl.Int32) != 2).group_by([\"GameIndex\", \"Actor\", \"Name\"]).agg([\n",
    "        pl.len().alias(\"action_count\")\n",
    "    ])\n",
    "\n",
    "    # Collision counts per game\n",
    "    collision_data = lf.filter(\n",
    "        (pl.col(\"Category\") == \"Collision\") & (pl.col(\"State\").cast(pl.Int32) == 0)\n",
    "    ).group_by(\"GameIndex\").agg([\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"ColTieBreaker\").cast(pl.Int32) == 0) & (pl.col(\"ColActor\").cast(pl.Int32) == 1))\n",
    "          .then(1).otherwise(0).sum().alias(\"collision_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"ColTieBreaker\").cast(pl.Int32) == 0) & (pl.col(\"ColActor\").cast(pl.Int32) == 1))\n",
    "          .then(1).otherwise(0).sum().alias(\"collision_R\"),\n",
    "        pl.col(\"ColTieBreaker\").cast(pl.Int32).fill_null(0).sum().alias(\"collision_tie\")\n",
    "    ])\n",
    "\n",
    "    # Game metadata (winner and duration per game)\n",
    "    game_meta = lf.group_by(\"GameIndex\").agg([\n",
    "        pl.col(\"GameWinner\").first().alias(\"Winner\"),\n",
    "        pl.col(\"UpdatedAt\").max().alias(\"MatchDur\")\n",
    "    ])\n",
    "\n",
    "    # Now aggregate durations and counts to game level\n",
    "    game_durations = action_durations.group_by(\"GameIndex\").agg([\n",
    "        pl.when(pl.col(\"Actor\").cast(pl.Int32) == 0).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"Duration_L\"),\n",
    "        pl.when(pl.col(\"Actor\").cast(pl.Int32) == 1).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"Duration_R\"),\n",
    "\n",
    "        # Per-action durations for left\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"Accelerate\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"Accelerate_Dur_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"TurnLeft\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"TurnLeft_Dur_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"TurnRight\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"TurnRight_Dur_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"Dash\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"Dash_Dur_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"SkillBoost\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"SkillBoost_Dur_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"SkillStone\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"SkillStone_Dur_L\"),\n",
    "\n",
    "        # Per-action durations for right\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"Accelerate\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"Accelerate_Dur_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"TurnLeft\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"TurnLeft_Dur_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"TurnRight\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"TurnRight_Dur_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"Dash\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"Dash_Dur_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"SkillBoost\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"SkillBoost_Dur_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"SkillStone\")).then(pl.col(\"ActualDuration\")).sum().fill_null(0).alias(\"SkillStone_Dur_R\"),\n",
    "    ])\n",
    "\n",
    "    # Aggregate action counts to game level\n",
    "    game_counts = action_counts.group_by(\"GameIndex\").agg([\n",
    "        pl.when(pl.col(\"Actor\").cast(pl.Int32) == 0).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"ActionCounts_L\"),\n",
    "        pl.when(pl.col(\"Actor\").cast(pl.Int32) == 1).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"ActionCounts_R\"),\n",
    "        pl.col(\"action_count\").sum().fill_null(0).alias(\"TotalActions\"),\n",
    "\n",
    "        # Per-action counts for left\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"Accelerate\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"Accelerate_Act_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"TurnLeft\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"TurnLeft_Act_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"TurnRight\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"TurnRight_Act_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"Dash\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"Dash_Act_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"SkillBoost\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"SkillBoost_Act_L\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 0) & (pl.col(\"Name\") == \"SkillStone\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"SkillStone_Act_L\"),\n",
    "\n",
    "        # Per-action counts for right\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"Accelerate\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"Accelerate_Act_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"TurnLeft\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"TurnLeft_Act_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"TurnRight\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"TurnRight_Act_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"Dash\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"Dash_Act_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"SkillBoost\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"SkillBoost_Act_R\"),\n",
    "        pl.when((pl.col(\"Actor\").cast(pl.Int32) == 1) & (pl.col(\"Name\") == \"SkillStone\")).then(pl.col(\"action_count\")).sum().fill_null(0).alias(\"SkillStone_Act_R\"),\n",
    "    ])\n",
    "\n",
    "    # Join everything at game level\n",
    "    final_metrics = game_meta.join(game_durations, on=\"GameIndex\", how=\"left\") \\\n",
    "                              .join(game_counts, on=\"GameIndex\", how=\"left\") \\\n",
    "                              .join(collision_data, on=\"GameIndex\", how=\"left\")\n",
    "\n",
    "    # Fill nulls for collisions and add metadata\n",
    "    final_metrics = final_metrics.with_columns([\n",
    "        pl.col(\"collision_L\").fill_null(0).alias(\"Collisions_L\"),\n",
    "        pl.col(\"collision_R\").fill_null(0).alias(\"Collisions_R\"),\n",
    "        pl.col(\"collision_tie\").fill_null(0).alias(\"Collisions_Tie\"),\n",
    "        pl.lit(bot_a).alias(\"Bot_L\"),\n",
    "        pl.lit(bot_b).alias(\"Bot_R\"),\n",
    "        pl.lit(timer).alias(\"Timer\"),\n",
    "        pl.lit(act_interval).alias(\"ActInterval\"),\n",
    "        pl.lit(round_val).alias(\"Round\"),\n",
    "        pl.lit(skill_left).alias(\"SkillLeft\"),\n",
    "        pl.lit(skill_right).alias(\"SkillRight\")\n",
    "    ]).drop([\"collision_L\", \"collision_R\", \"collision_tie\"])\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "\n",
    "def create_summary_matchup(all_games):\n",
    "    \"\"\"Create matchup summary using Polars with GPU acceleration\"\"\"\n",
    "    group_cols = [\"Bot_L\", \"Bot_R\", \"Timer\", \"ActInterval\", \"Round\", \"SkillLeft\", \"SkillRight\"]\n",
    "\n",
    "    # Find all action-specific columns\n",
    "    action_cols = [col for col in all_games.columns if any(col.endswith(suffix) for suffix in (\"_Act_L\", \"_Act_R\", \"_Dur_L\", \"_Dur_R\"))]\n",
    "\n",
    "    # Build aggregation list\n",
    "    agg_list = [\n",
    "        pl.col(\"GameIndex\").n_unique().alias(\"Games\"),\n",
    "        (pl.col(\"Winner\") == 0).sum().alias(\"Winner_L\"),\n",
    "        (pl.col(\"Winner\") == 1).sum().alias(\"Winner_R\"),\n",
    "        pl.col(\"ActionCounts_L\").sum(),\n",
    "        pl.col(\"ActionCounts_R\").sum(),\n",
    "        pl.col(\"TotalActions\").sum(),\n",
    "        pl.col(\"Duration_L\").sum(),\n",
    "        pl.col(\"Duration_R\").sum(),\n",
    "        pl.col(\"Collisions_L\").sum(),\n",
    "        pl.col(\"Collisions_R\").sum(),\n",
    "        pl.col(\"Collisions_Tie\").sum(),\n",
    "        pl.col(\"MatchDur\").mean(),\n",
    "    ]\n",
    "\n",
    "    # Add all action-specific columns\n",
    "    for col in action_cols:\n",
    "        agg_list.append(pl.col(col).sum())\n",
    "\n",
    "    # Use lazy frames for GPU acceleration\n",
    "    matchup_summary_lazy = all_games.lazy().group_by(group_cols).agg(agg_list)\n",
    "\n",
    "    # Add win rates\n",
    "    matchup_summary_lazy = matchup_summary_lazy.with_columns([\n",
    "        (pl.col(\"Winner_L\") / pl.col(\"Games\")).alias(\"WinRate_L\"),\n",
    "        (pl.col(\"Winner_R\") / pl.col(\"Games\")).alias(\"WinRate_R\")\n",
    "    ])\n",
    "\n",
    "    matchup_summary = collect_with_gpu(matchup_summary_lazy)\n",
    "\n",
    "    # Compute bot rankings based on overall performance\n",
    "    # Aggregate left bots\n",
    "    bot_summary_L_lazy = matchup_summary.lazy().group_by(\"Bot_L\").agg([\n",
    "        pl.col(\"Games\").sum().alias(\"TotalGames\"),\n",
    "        pl.col(\"Winner_L\").sum().alias(\"TotalWins\"),\n",
    "    ]).rename({\"Bot_L\": \"Bot\"})\n",
    "\n",
    "    # Aggregate right bots\n",
    "    bot_summary_R_lazy = matchup_summary.lazy().group_by(\"Bot_R\").agg([\n",
    "        pl.col(\"Games\").sum().alias(\"TotalGames\"),\n",
    "        pl.col(\"Winner_R\").sum().alias(\"TotalWins\"),\n",
    "    ]).rename({\"Bot_R\": \"Bot\"})\n",
    "\n",
    "    # Combine and compute ranks\n",
    "    bot_ranks_lazy = pl.concat([bot_summary_L_lazy, bot_summary_R_lazy]).group_by(\"Bot\").agg([\n",
    "        pl.col(\"TotalGames\").sum(),\n",
    "        pl.col(\"TotalWins\").sum(),\n",
    "    ]).with_columns([\n",
    "        (pl.col(\"TotalWins\") / pl.col(\"TotalGames\")).alias(\"WinRate\")\n",
    "    ]).with_columns([\n",
    "        pl.col(\"WinRate\").rank(descending=True).cast(pl.Int32).alias(\"Rank\")\n",
    "    ]).select([\"Bot\", \"Rank\"])\n",
    "\n",
    "    bot_ranks = collect_with_gpu(bot_ranks_lazy)\n",
    "\n",
    "    # Join ranks back to matchup summary\n",
    "    matchup_summary_lazy = matchup_summary.lazy().join(\n",
    "        bot_ranks.lazy().rename({\"Bot\": \"Bot_L\", \"Rank\": \"Rank_L\"}),\n",
    "        on=\"Bot_L\",\n",
    "        how=\"left\"\n",
    "    ).join(\n",
    "        bot_ranks.lazy().rename({\"Bot\": \"Bot_R\", \"Rank\": \"Rank_R\"}),\n",
    "        on=\"Bot_R\",\n",
    "        how=\"left\"\n",
    "    ).sort([\"Bot_L\", \"Bot_R\", \"Timer\", \"ActInterval\"])\n",
    "\n",
    "    matchup_summary = collect_with_gpu(matchup_summary_lazy)\n",
    "\n",
    "    # Save to CSV\n",
    "    matchup_summary.write_csv(\"summary_matchup.csv\")\n",
    "    print(\"Saved summary_matchup.csv\")\n",
    "\n",
    "    return matchup_summary\n",
    "\n",
    "\n",
    "def create_summary_bot(matchup_summary):\n",
    "    \"\"\"Create bot summary using Polars with GPU acceleration\"\"\"\n",
    "\n",
    "    # Use lazy frames for GPU acceleration\n",
    "    # First, normalize the data so each row represents one bot in one game\n",
    "    bot_summary_L_lazy = matchup_summary.lazy().select([\n",
    "        pl.col(\"Bot_L\").alias(\"Bot\"),\n",
    "        pl.col(\"Games\"),\n",
    "        pl.col(\"Winner_L\").alias(\"Wins\"),\n",
    "        pl.col(\"Duration_L\").alias(\"Duration\"),\n",
    "        pl.col(\"ActionCounts_L\").alias(\"TotalActions\"),\n",
    "        pl.col(\"Collisions_L\").alias(\"Collisions_Own\"),\n",
    "        pl.col(\"Collisions_Tie\"),\n",
    "    ])\n",
    "\n",
    "    bot_summary_R_lazy = matchup_summary.lazy().select([\n",
    "        pl.col(\"Bot_R\").alias(\"Bot\"),\n",
    "        pl.col(\"Games\"),\n",
    "        pl.col(\"Winner_R\").alias(\"Wins\"),\n",
    "        pl.col(\"Duration_R\").alias(\"Duration\"),\n",
    "        pl.col(\"ActionCounts_R\").alias(\"TotalActions\"),\n",
    "        pl.col(\"Collisions_R\").alias(\"Collisions_Own\"),\n",
    "        pl.col(\"Collisions_Tie\"),\n",
    "    ])\n",
    "\n",
    "    # Combine and calculate per-game averages, then aggregate by bot\n",
    "    bot_summary_lazy = pl.concat([bot_summary_L_lazy, bot_summary_R_lazy]).with_columns([\n",
    "        # Calculate per-game averages\n",
    "        (pl.col(\"Duration\") / pl.col(\"Games\")).alias(\"Duration_per_game\"),\n",
    "        (pl.col(\"TotalActions\") / pl.col(\"Games\")).alias(\"Actions_per_game\"),\n",
    "        ((pl.col(\"Collisions_Own\") + pl.col(\"Collisions_Tie\")) / pl.col(\"Games\")).alias(\"Collisions_per_game\"),\n",
    "        (pl.col(\"Wins\") / pl.col(\"Games\")).alias(\"WinRate_per_matchup\"),\n",
    "    ]).group_by(\"Bot\").agg([\n",
    "        pl.col(\"Games\").sum().alias(\"TotalGames\"),\n",
    "        pl.col(\"Wins\").sum().alias(\"TotalWins\"),\n",
    "        pl.col(\"WinRate_per_matchup\").mean().alias(\"WinRate_mean\"),\n",
    "        pl.col(\"WinRate_per_matchup\").std().alias(\"WinRate_std\"),\n",
    "        pl.col(\"Duration_per_game\").mean().alias(\"Duration_mean\"),\n",
    "        pl.col(\"Duration_per_game\").std().alias(\"Duration_std\"),\n",
    "        pl.col(\"Actions_per_game\").mean().alias(\"Actions_mean\"),\n",
    "        pl.col(\"Actions_per_game\").std().alias(\"Actions_std\"),\n",
    "        pl.col(\"Collisions_per_game\").mean().alias(\"Collisions_mean\"),\n",
    "        pl.col(\"Collisions_per_game\").std().alias(\"Collisions_std\"),\n",
    "    ]).with_columns([\n",
    "        # Format as \"mean (std)\" with 2 decimal places\n",
    "        (pl.col(\"WinRate_mean\").round(2).cast(pl.Utf8) + \" (\" + pl.col(\"WinRate_std\").round(2).cast(pl.Utf8) + \")\").alias(\"Win-rate\"),\n",
    "        (pl.col(\"Duration_mean\").round(2).cast(pl.Utf8) + \" (\" + pl.col(\"Duration_std\").round(2).cast(pl.Utf8) + \")\").alias(\"Action Duration\"),\n",
    "        (pl.col(\"Actions_mean\").round(2).cast(pl.Utf8) + \" (\" + pl.col(\"Actions_std\").round(2).cast(pl.Utf8) + \")\").alias(\"Actions\"),\n",
    "        (pl.col(\"Collisions_mean\").round(2).cast(pl.Utf8) + \" (\" + pl.col(\"Collisions_std\").round(2).cast(pl.Utf8) + \")\").alias(\"Collisions\"),\n",
    "    ]).with_columns([\n",
    "        pl.col(\"WinRate_mean\").rank(descending=True).cast(pl.Int32).alias(\"Rank\"),\n",
    "    ]).select([\n",
    "        \"Rank\",\n",
    "        \"Bot\",\n",
    "        \"Win-rate\",\n",
    "        \"Action Duration\",\n",
    "        \"Actions\",\n",
    "        \"Collisions\"\n",
    "    ]).sort(\"Rank\")\n",
    "\n",
    "    bot_summary = collect_with_gpu(bot_summary_lazy)\n",
    "\n",
    "    # Save\n",
    "    bot_summary.write_csv(\"summary_bot.csv\")\n",
    "    print(\"Saved summary_bot.csv\")\n",
    "\n",
    "    return bot_summary\n",
    "\n",
    "\n",
    "def compute_collision_time_bins_from_csvs(base_dir, time_bin_size=5):\n",
    "    \"\"\"\n",
    "    Compute time-binned COLLISION data from CSV files.\n",
    "    \"\"\"\n",
    "    # Find all CSV files\n",
    "    all_csvs = []\n",
    "    matchup_folders = [f for f in os.listdir(base_dir)\n",
    "                       if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "    for matchup_folder in matchup_folders:\n",
    "        matchup_path = os.path.join(base_dir, matchup_folder)\n",
    "        config_folders = [f for f in os.listdir(matchup_path)\n",
    "                         if os.path.isdir(os.path.join(matchup_path, f))]\n",
    "\n",
    "        for config_folder in config_folders:\n",
    "            config_path = os.path.join(matchup_path, config_folder)\n",
    "            csv_files = glob.glob(os.path.join(config_path, \"*.csv\"))\n",
    "            all_csvs.extend([(csv, matchup_folder, config_folder) for csv in csv_files])\n",
    "\n",
    "    print(f\" Computing time-binned collision data from {len(all_csvs)} CSV files...\")\n",
    "\n",
    "    collision_fragment_list = []\n",
    "\n",
    "    for csv_path, matchup_folder, config_folder in all_csvs:\n",
    "        match = re.match(r\"(.+)_vs_(.+)\", matchup_folder)\n",
    "        if not match:\n",
    "            continue\n",
    "        bot_a, bot_b = match.groups()\n",
    "\n",
    "        config = parse_config_name_cached(config_folder)\n",
    "\n",
    "        # Scan and filter for collisions\n",
    "        lf = pl.scan_csv(csv_path)\n",
    "        raw_data = lf.filter(\n",
    "            (pl.col(\"Category\") == \"Collision\") & (pl.col(\"State\") == 0)\n",
    "        ).select([\n",
    "            \"GameIndex\", \"Actor\", \"ColTieBreaker\", \"ColActor\", \"UpdatedAt\"\n",
    "        ])\n",
    "\n",
    "        # Add match duration per game\n",
    "        match_dur_lf = lf.group_by(\"GameIndex\").agg([\n",
    "            pl.col(\"UpdatedAt\").max().alias(\"match_duration\")\n",
    "        ])\n",
    "\n",
    "        raw_data = raw_data.join(match_dur_lf, on=\"GameIndex\", how=\"left\")\n",
    "        raw_data_df = collect_with_gpu(raw_data)\n",
    "\n",
    "        # Process collision time bins per game\n",
    "        for game_idx in raw_data_df['GameIndex'].unique():\n",
    "            game_df = raw_data_df.filter(pl.col('GameIndex') == game_idx)\n",
    "            match_dur = game_df['match_duration'][0]\n",
    "\n",
    "            bins = np.arange(0, match_dur + time_bin_size, time_bin_size)\n",
    "            if len(bins) < 2:\n",
    "                continue\n",
    "\n",
    "            game_pd = game_df.to_pandas()\n",
    "            game_pd['TimeBin'] = pd.cut(game_pd['UpdatedAt'], bins=bins,\n",
    "                                       labels=bins[:-1], include_lowest=True)\n",
    "\n",
    "            for time_bin, bin_data in game_pd.groupby('TimeBin', observed=False):\n",
    "                actor_L_count = len(bin_data[(bin_data['Actor'] == \"0\") &\n",
    "                                            (bin_data['ColTieBreaker'] == \"0\") &\n",
    "                                            (bin_data[\"ColActor\"] == \"1\")])\n",
    "                actor_R_count = len(bin_data[(bin_data['Actor'] == \"1\") &\n",
    "                                            (bin_data['ColTieBreaker'] == \"0\") &\n",
    "                                            (bin_data[\"ColActor\"] == \"1\")])\n",
    "\n",
    "                tie = bin_data['ColTieBreaker'].sum() if 'ColTieBreaker' in bin_data.columns else 0\n",
    "\n",
    "                collision_fragment_list.append({\n",
    "                    'GameIndex': game_idx,\n",
    "                    'Bot_L': bot_a,\n",
    "                    'Bot_R': bot_b,\n",
    "                    'Timer': config.get('Timer'),\n",
    "                    'ActInterval': config.get('ActInterval'),\n",
    "                    'Round': config.get('Round'),\n",
    "                    'SkillLeft': config.get('SkillLeft'),\n",
    "                    'SkillRight': config.get('SkillRight'),\n",
    "                    'TimeBin': float(time_bin),\n",
    "                    'Actor_L': actor_L_count,\n",
    "                    'Actor_R': actor_R_count,\n",
    "                    'Tie': int(tie),\n",
    "                })\n",
    "\n",
    "    collision_fragment_df = pl.DataFrame(collision_fragment_list)\n",
    "    print(f\"Computed {len(collision_fragment_df):,} collision time-binned records\")\n",
    "\n",
    "    return collision_fragment_df\n",
    "\n",
    "\n",
    "def summarize_action_timebins(time_fragment_df):\n",
    "    \"\"\"\n",
    "    Summarize action time fragment data with GPU acceleration.\n",
    "    Computes mean counts per bot/config/timebin/action.\n",
    "    \"\"\"\n",
    "    print(\" Summarizing action time-binned data...\")\n",
    "\n",
    "    # Use lazy frames for GPU acceleration\n",
    "    summary_lazy = time_fragment_df.lazy().group_by(\n",
    "        ['Bot', 'Timer', 'ActInterval', 'Round', 'TimeBin', 'Action']\n",
    "    ).agg([\n",
    "        pl.col('Count').mean().alias('MeanCount')\n",
    "    ]).sort(['Bot', 'Timer', 'ActInterval', 'Round', 'TimeBin', 'Action'])\n",
    "\n",
    "    summary = collect_with_gpu(summary_lazy)\n",
    "\n",
    "    # Save CSV\n",
    "    summary.write_csv(\"summary_action_timebins.csv\")\n",
    "    print(\"Saved summary_action_timebins.csv\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def summarize_collision_timebins(collision_fragment_df):\n",
    "    \"\"\"\n",
    "    Calculate collision time fragment data with GPU acceleration.\n",
    "    Aggregates Actor, Target, Tie counts per config/timebin.\n",
    "    \"\"\"\n",
    "    print(\" Creating collision detail time-binned data...\")\n",
    "\n",
    "    # Use lazy frames for GPU acceleration\n",
    "    summary_lazy = collision_fragment_df.lazy().group_by(\n",
    "        ['Bot_L', 'Bot_R', 'Timer', 'ActInterval', 'Round', 'TimeBin']\n",
    "    ).agg([\n",
    "        pl.col('Actor_L').sum().alias('Actor_L'),\n",
    "        pl.col('Actor_R').sum().alias('Actor_R'),\n",
    "        pl.col('Tie').sum().alias('Tie'),\n",
    "    ]).sort(['Bot_L', 'Bot_R', 'Timer', 'ActInterval', 'Round', 'TimeBin'])\n",
    "\n",
    "    summary = collect_with_gpu(summary_lazy)\n",
    "\n",
    "    # Save CSV\n",
    "    summary.write_csv(\"summary_collision_timebins.csv\")\n",
    "    print(\"Saved summary_collision_timebins.csv\")\n",
    "\n",
    "    return summary\n",
    "\n",
    "def batch_process_csvs(base_dir, batch_size=50, checkpoint_dir=\"batched\", time_bin_size=None, compute_timebins=False):\n",
    "    \"\"\"\n",
    "    Process CSVs in batches and save checkpoints\n",
    "    Similar to generator.py batch() function\n",
    "    Structure: base_dir/BotA_vs_BotB/ConfigFolder/*.csv\n",
    "\n",
    "    Args:\n",
    "        base_dir: Base directory containing simulation data\n",
    "        batch_size: Number of CSV files per batch\n",
    "        checkpoint_dir: Directory to save checkpoints\n",
    "        time_bin_size: Size of time bins (only used if compute_timebins=True)\n",
    "        compute_timebins: Whether to compute time-binned data\n",
    "    \"\"\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Create separate checkpoint dirs for timebins if needed\n",
    "    if compute_timebins:\n",
    "        action_timebin_dir = os.path.join(checkpoint_dir, \"action_timebins\")\n",
    "        collision_timebin_dir = os.path.join(checkpoint_dir, \"collision_timebins\")\n",
    "        os.makedirs(action_timebin_dir, exist_ok=True)\n",
    "        os.makedirs(collision_timebin_dir, exist_ok=True)\n",
    "\n",
    "    # Find all CSV files grouped by matchup/config\n",
    "    all_csvs = []\n",
    "    matchup_folders = [f for f in os.listdir(base_dir)\n",
    "                       if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "    for matchup_folder in matchup_folders:\n",
    "        matchup_path = os.path.join(base_dir, matchup_folder)\n",
    "        config_folders = [f for f in os.listdir(matchup_path)\n",
    "                         if os.path.isdir(os.path.join(matchup_path, f))]\n",
    "\n",
    "        for config_folder in config_folders:\n",
    "            config_path = os.path.join(matchup_path, config_folder)\n",
    "            csv_files = glob.glob(os.path.join(config_path, \"*.csv\"))\n",
    "            all_csvs.extend(csv_files)\n",
    "\n",
    "    print(f\"Found {len(all_csvs)} CSV files to process\")\n",
    "\n",
    "    # Determine which batches are already processed\n",
    "    processed_batches = set()\n",
    "    for f in os.listdir(checkpoint_dir):\n",
    "        match = re.match(r\"batch_(\\d+)\\.csv\", f)\n",
    "        if match:\n",
    "            processed_batches.add(int(match.group(1)))\n",
    "\n",
    "    # Process in batches\n",
    "    total_batches = (len(all_csvs) + batch_size - 1) // batch_size\n",
    "\n",
    "    for batch_idx in range(total_batches):\n",
    "        batch_num = batch_idx + 1\n",
    "\n",
    "        # Skip if already processed\n",
    "        if batch_num in processed_batches:\n",
    "            print(f\"Skipping batch {batch_num}/{total_batches} (already processed)\")\n",
    "            continue\n",
    "\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(all_csvs))\n",
    "        batch_csvs = all_csvs[start_idx:end_idx]\n",
    "\n",
    "        print(f\"\\nProcessing batch {batch_num}/{total_batches} ({len(batch_csvs)} files)...\")\n",
    "\n",
    "        batch_df, action_timebin_df, collision_timebin_df = process_batch_csvs(\n",
    "            batch_csvs, checkpoint_dir, time_bin_size=time_bin_size, compute_timebins=compute_timebins\n",
    "        )\n",
    "\n",
    "        # Save game metrics batch\n",
    "        if batch_df is not None:\n",
    "            batch_path = os.path.join(checkpoint_dir, f\"batch_{batch_num:02d}.csv\")\n",
    "            batch_df.write_csv(batch_path)\n",
    "            print(f\"Saved batch checkpoint: {batch_path}\")\n",
    "\n",
    "        # Save timebin batches if computed\n",
    "        if compute_timebins:\n",
    "            if action_timebin_df is not None:\n",
    "                action_path = os.path.join(action_timebin_dir, f\"batch_{batch_num:02d}.csv\")\n",
    "                action_timebin_df.write_csv(action_path)\n",
    "                print(f\"Saved action timebin batch: {action_path}\")\n",
    "\n",
    "            if collision_timebin_df is not None:\n",
    "                collision_path = os.path.join(collision_timebin_dir, f\"batch_{batch_num:02d}.csv\")\n",
    "                collision_timebin_df.write_csv(collision_path)\n",
    "                print(f\"Saved collision timebin batch: {collision_path}\")\n",
    "\n",
    "def generate_timebins_from_batches():\n",
    "    \"\"\"\n",
    "    Generate timebin summaries from batched timebin checkpoints\n",
    "    Loads batch files and creates final summaries\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸš€ Generating timebin summaries from batches\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Load action timebin batches\n",
    "    action_batch_files = sorted(glob.glob(\"batched/action_timebins/batch_*.csv\"))\n",
    "    if action_batch_files:\n",
    "        print(f\"\\nðŸ“‚ Loading {len(action_batch_files)} action timebin batch files...\")\n",
    "        action_lazy_frames = [pl.scan_csv(f) for f in action_batch_files]\n",
    "        action_timebin_df = collect_with_gpu(pl.concat(action_lazy_frames))\n",
    "        print(f\"Loaded {len(action_timebin_df):,} action timebin records\")\n",
    "\n",
    "        print(\"\\n Creating action time-bin summary...\")\n",
    "        summarize_action_timebins(action_timebin_df)\n",
    "\n",
    "    # Load collision timebin batches\n",
    "    collision_batch_files = sorted(glob.glob(\"batched/collision_timebins/batch_*.csv\"))\n",
    "    if collision_batch_files:\n",
    "        print(f\"\\nðŸ“‚ Loading {len(collision_batch_files)} collision timebin batch files...\")\n",
    "        collision_lazy_frames = [pl.scan_csv(f) for f in collision_batch_files]\n",
    "        collision_timebin_df = collect_with_gpu(pl.concat(collision_lazy_frames))\n",
    "        print(f\"Loaded {len(collision_timebin_df):,} collision timebin records\")\n",
    "\n",
    "        print(\"\\n Creating collision time-bin summary...\")\n",
    "        summarize_collision_timebins(collision_timebin_df)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸŽ‰ Done! Created:\")\n",
    "    if action_batch_files:\n",
    "        print(\"   - summary_action_timebins.csv\")\n",
    "    if collision_batch_files:\n",
    "        print(\"   - summary_collision_timebins.csv\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Batched CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timebin_size = 5\n",
    "batch_size = 2 # if there's 156 matchup simulation folder, it will generate 156 / 2 = 78 summarization batch csv\n",
    "\n",
    "batch_process_csvs(\n",
    "    csv_folder, \n",
    "    batch_size=batch_size,\n",
    "    time_bin_size=timebin_size,\n",
    "    compute_timebins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Final Summarization CSV from Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_timebins_from_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compiling (Arena Heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU support is available\n",
    "GPU_AVAILABLE = False\n",
    "try:\n",
    "    # Try a simple GPU operation to check availability\n",
    "    pl.LazyFrame({\"test\": [1]}).collect(engine=\"gpu\")\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"âœ… GPU support available - will use GPU acceleration\")\n",
    "except Exception:\n",
    "    print(\"âœ… Using CPU\")\n",
    "\n",
    "\n",
    "def collect_with_gpu(lf, streaming=True):\n",
    "    \"\"\"Helper to collect LazyFrame with GPU if available, otherwise uses CPU with streaming\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        try:\n",
    "            return lf.collect(engine=\"gpu\", streaming=streaming)\n",
    "        except Exception:\n",
    "            # Fallback to CPU if GPU collection fails\n",
    "            return lf.collect(streaming=streaming)\n",
    "    else:\n",
    "        return lf.collect(streaming=streaming)\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "arena_center = np.array([0.24, 1.97])\n",
    "arena_radius = 4.73485\n",
    "\n",
    "# Adjustable parameters\n",
    "tile_size = 0.7   # Larger = bigger heatmap tiles (lower resolution)\n",
    "# arrow_size = 50   # Larger = longer arrows\n",
    "\n",
    "def load_data_chunked(csv_path, chunksize=50000, actor_filter=None):\n",
    "    \"\"\"\n",
    "    Load CSV data using Polars with GPU acceleration and streaming\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to CSV file\n",
    "        chunksize: Number of rows per chunk (ignored for Polars, kept for API compatibility)\n",
    "        actor_filter: Filter for specific actor (0 for left, 1 for right, None for both)\n",
    "    \"\"\"\n",
    "    # Scan CSV without schema enforcement - let Polars infer naturally\n",
    "    # Use ignore_errors to handle inconsistent column types across files\n",
    "    # rechunk=False reduces memory overhead by avoiding unnecessary rechunking\n",
    "    lf = pl.scan_csv(csv_path, ignore_errors=True, rechunk=False)\n",
    "\n",
    "    # Select ONLY required columns to drastically reduce memory usage\n",
    "    # This is critical for 135GB files - we only load what we need\n",
    "    lf = lf.select([\n",
    "        \"GameIndex\",     # For grouping by game\n",
    "        \"UpdatedAt\",     # For time-based analysis\n",
    "        \"Actor\",         # For filtering by bot\n",
    "        \"BotPosX\",       # X position\n",
    "        \"BotPosY\",       # Y position\n",
    "        \"BotRot\"         # Rotation (used for null checking)\n",
    "    ])\n",
    "\n",
    "    # Filter by actor if specified, casting Actor inline for comparison\n",
    "    # IMPORTANT: Do this BEFORE collect to reduce memory usage\n",
    "    if actor_filter is not None:\n",
    "        lf = lf.filter(pl.col(\"Actor\").cast(pl.Int64) == actor_filter)\n",
    "\n",
    "    # Drop invalid entries BEFORE collecting to reduce memory footprint\n",
    "    lf = lf.drop_nulls(subset=[\"BotPosX\", \"BotPosY\", \"BotRot\"])\n",
    "\n",
    "    # Collect with GPU acceleration and streaming enabled\n",
    "    # streaming=True processes data in batches to avoid OOM\n",
    "    df = collect_with_gpu(lf, streaming=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_heatmap_data(x, y, tile_size):\n",
    "    \"\"\"Create heatmap data from position coordinates\"\"\"\n",
    "    if len(x) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    xrange = np.arange(x.min(), x.max() + tile_size, tile_size)\n",
    "    yrange = np.arange(y.min(), y.max() + tile_size, tile_size)\n",
    "    heatmap, xedges, yedges = np.histogram2d(x, y, bins=[xrange, yrange])\n",
    "\n",
    "    return heatmap, xedges, yedges\n",
    "\n",
    "def plot_phase_heatmap(ax, phase_df, phase_name):\n",
    "    \"\"\"Plot contour density heatmap for a single phase\"\"\"\n",
    "    if phase_df.is_empty():\n",
    "        ax.text(0.5, 0.5, f\"No data for {phase_name}\",\n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "        return\n",
    "\n",
    "    x = phase_df[\"BotPosX\"].to_numpy() - arena_center[0]\n",
    "    y = phase_df[\"BotPosY\"].to_numpy() - arena_center[1]  # Shift by arena center\n",
    "\n",
    "    # Create 2D kernel density estimation for smooth contours\n",
    "    if len(x) > 1:\n",
    "        from scipy.stats import gaussian_kde\n",
    "\n",
    "        # Create KDE\n",
    "        try:\n",
    "            xy = np.vstack([x, y])\n",
    "            kde = gaussian_kde(xy)\n",
    "\n",
    "            # Create grid for evaluation (data shifted by arena_center, so center is at origin)\n",
    "            x_min, x_max = 0 - arena_radius - 1, 0 + arena_radius + 1\n",
    "            y_min, y_max = 0 - arena_radius - 1, 0 + arena_radius + 1\n",
    "\n",
    "            xx, yy = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]\n",
    "            positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "            density = np.reshape(kde(positions).T, xx.shape)\n",
    "\n",
    "            # Plot filled contours (density heatmap)\n",
    "            ax.contourf(xx, yy, density, levels=15, cmap=\"Greens\", alpha=0.8, zorder=1)\n",
    "\n",
    "            # Optionally add contour lines for better definition\n",
    "            ax.contour(xx, yy, density, levels=5, colors='darkgreen', alpha=0.3, linewidths=0.5, zorder=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Fallback to scatter if KDE fails\n",
    "            print(f\"Warning: KDE failed for {phase_name}, using scatter plot. Error: {e}\")\n",
    "            ax.scatter(x, y, alpha=0.1, s=1, c='green', zorder=1)\n",
    "\n",
    "    # Draw arena boundary AFTER contours so it appears on top (data shifted by arena_center)\n",
    "    arena_center_shifted = np.array([0, 0])  # Center is at origin after shift\n",
    "    circle = plt.Circle(arena_center_shifted, arena_radius,\n",
    "                       fill=False, edgecolor=\"red\",\n",
    "                       linewidth=2, linestyle=\"--\", zorder=3)\n",
    "    ax.add_artist(circle)\n",
    "\n",
    "    # Labels & Arena Bounds\n",
    "    ax.set_title(f\"{phase_name}\\n(n={len(phase_df):,} samples)\")\n",
    "    ax.set_xlabel(\"BotPosX (shifted)\")\n",
    "    ax.set_ylabel(\"BotPosY (shifted)\")\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    ax.set_xlim(0 - arena_radius - 1, 0 + arena_radius + 1)\n",
    "    ax.set_ylim(0 - arena_radius - 1, 0 + arena_radius + 1)\n",
    "\n",
    "    # Add grid\n",
    "    ax.grid(True, alpha=0.3, zorder=0)\n",
    "\n",
    "\n",
    "def plot_position_distribution(df_combined, bot_name, actor_position=\"both\"):\n",
    "    \"\"\"\n",
    "    Plot X and Y position distributions in a single frame (overlaid histograms)\n",
    "    Y values are shifted by -2 since the game starts at y=2\n",
    "\n",
    "    Args:\n",
    "        df_combined: Combined Polars DataFrame with bot position data\n",
    "        bot_name: Name of the bot\n",
    "        actor_position: Position filter text for title\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    if df_combined.is_empty():\n",
    "        return None\n",
    "\n",
    "    x = df_combined[\"BotPosX\"].to_numpy() - arena_center[0]\n",
    "    y = df_combined[\"BotPosY\"].to_numpy() - arena_center[1]  # Shift by arena center\n",
    "\n",
    "    # Create figure with single subplot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "    # Plot X distribution\n",
    "    ax.hist(x, bins=30, alpha=0.7, color='green', edgecolor='darkgreen',\n",
    "            label=f'{bot_name} X', linewidth=0.5)\n",
    "\n",
    "    # Plot Y distribution (overlaid, shifted)\n",
    "    ax.hist(y, bins=30, alpha=0.7, color='red', edgecolor='darkred',\n",
    "            label=f'{bot_name} Y', linewidth=0.5)\n",
    "\n",
    "    # Customize plot\n",
    "    position_text = f\" ({actor_position} side)\" if actor_position != \"both\" else \"\"\n",
    "    ax.set_title(f\"Distribution of {bot_name} Positions (Overlayed){position_text}\\n(n={len(df_combined):,} samples)\",\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Position (shifted by arena center)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=12)\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_joint_heatmap_with_distributions(phase_df, phase_name, bot_name=\"\", actor_position=\"both\"):\n",
    "    \"\"\"\n",
    "    Create a joint plot with contour heatmap and marginal distributions (like seaborn jointplot)\n",
    "    Y values are shifted by -2 since the game starts at y=2\n",
    "\n",
    "    Args:\n",
    "        phase_df: Polars DataFrame with position data for a specific phase\n",
    "        phase_name: Name of the phase (e.g., \"Early Game\")\n",
    "        bot_name: Name of the bot\n",
    "        actor_position: Position filter text for title\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    if phase_df.is_empty():\n",
    "        return None\n",
    "\n",
    "    x = phase_df[\"BotPosX\"].to_numpy() - arena_center[0]\n",
    "    y = phase_df[\"BotPosY\"].to_numpy() - arena_center[1]  # Shift by arena center\n",
    "\n",
    "    # Create figure with GridSpec for joint plot layout\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    gs = GridSpec(4, 4, figure=fig, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # Main central plot (contour heatmap)\n",
    "    ax_main = fig.add_subplot(gs[1:4, 0:3])\n",
    "\n",
    "    # Top marginal (X distribution)\n",
    "    ax_top = fig.add_subplot(gs[0, 0:3], sharex=ax_main)\n",
    "\n",
    "    # Right marginal (Y distribution)\n",
    "    ax_right = fig.add_subplot(gs[1:4, 3], sharey=ax_main)\n",
    "\n",
    "    # Set white background for main axis\n",
    "    ax_main.set_facecolor('white')\n",
    "\n",
    "    # Plot contour heatmap on main axis\n",
    "    if len(x) > 1:\n",
    "        from scipy.stats import gaussian_kde\n",
    "        from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "        try:\n",
    "            xy = np.vstack([x, y])\n",
    "            kde = gaussian_kde(xy)\n",
    "\n",
    "            # Create grid for evaluation (data shifted by arena_center, so center is at origin)\n",
    "            x_min, x_max = 0 - arena_radius - 1, 0 + arena_radius + 1\n",
    "            y_min, y_max = 0 - arena_radius - 1, 0 + arena_radius + 1\n",
    "\n",
    "            xx, yy = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]\n",
    "            positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "            density = np.reshape(kde(positions).T, xx.shape)\n",
    "\n",
    "            # Mask low-density areas to keep background white\n",
    "            threshold = np.percentile(density, 40)  # Mask bottom n% of density\n",
    "            density_masked = np.ma.masked_where(density < threshold, density)\n",
    "\n",
    "            # Create custom colormap: white -> light green -> strong dark green (more layers)\n",
    "            colors_list = [ '#E0FFE0', '#C0FFC0', '#90EE90', '#66DD66',\n",
    "                          '#32CD32', '#2AAA2A', '#228B22', '#1A6B1A', '#006400']\n",
    "            n_bins = 256\n",
    "            cmap = LinearSegmentedColormap.from_list('green_gradient', colors_list, N=n_bins)\n",
    "\n",
    "            # Plot filled contours with masked data - only areas above threshold\n",
    "            ax_main.contourf(xx, yy, density_masked, levels=10, cmap=cmap, zorder=1)\n",
    "            ax_main.contour(xx, yy, density_masked, levels=10, colors='darkgreen', alpha=0.4,\n",
    "                           linewidths=0.5, zorder=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: KDE failed for {phase_name}, using scatter plot. Error: {e}\")\n",
    "            ax_main.scatter(x, y, alpha=0.1, s=1, c='green', zorder=1)\n",
    "\n",
    "    # Draw arena boundary (Y shifted by -2)\n",
    "    arena_center_shifted = np.array([0, 0])  # Center is at origin after shift\n",
    "    circle = plt.Circle(arena_center_shifted, arena_radius,\n",
    "                       fill=False, edgecolor=\"red\",\n",
    "                       linewidth=2, linestyle=\"--\", zorder=3)\n",
    "    ax_main.add_artist(circle)\n",
    "\n",
    "    # Configure main axis\n",
    "    ax_main.set_xlabel(\"X Position (shifted)\", fontsize=12)\n",
    "    ax_main.set_ylabel(\"Y Position (shifted)\", fontsize=12)\n",
    "    ax_main.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax_main.set_xlim(0 - arena_radius - 1, 0 + arena_radius + 1)\n",
    "    ax_main.set_ylim(0 - arena_radius - 1, 0 + arena_radius + 1)\n",
    "    ax_main.grid(True, alpha=0.3, zorder=0)\n",
    "\n",
    "    # Plot marginal distributions\n",
    "    # Top: X distribution (histogram with KDE line)\n",
    "    ax_top.hist(x, bins=50, color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.5, density=True)\n",
    "\n",
    "    # Add KDE line for X\n",
    "    if len(x) > 1:\n",
    "        try:\n",
    "            from scipy.stats import gaussian_kde\n",
    "            kde_x = gaussian_kde(x)\n",
    "            x_range = np.linspace(x.min(), x.max(), 200)\n",
    "            ax_top.plot(x_range, kde_x(x_range), 'darkblue', linewidth=2)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    ax_top.set_ylabel(\"Density\", fontsize=10)\n",
    "    ax_top.tick_params(labelbottom=False)\n",
    "    ax_top.spines['right'].set_visible(False)\n",
    "    ax_top.spines['top'].set_visible(False)\n",
    "\n",
    "    # Right: Y distribution (histogram with KDE line, rotated)\n",
    "    ax_right.hist(y, bins=50, color='steelblue', alpha=0.7, edgecolor='black',\n",
    "                  linewidth=0.5, orientation='horizontal', density=True)\n",
    "\n",
    "    # Add KDE line for Y\n",
    "    if len(y) > 1:\n",
    "        try:\n",
    "            from scipy.stats import gaussian_kde\n",
    "            kde_y = gaussian_kde(y)\n",
    "            y_range = np.linspace(y.min(), y.max(), 200)\n",
    "            ax_right.plot(kde_y(y_range), y_range, 'darkblue', linewidth=2)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    ax_right.set_xlabel(\"Density\", fontsize=10)\n",
    "    ax_right.tick_params(labelleft=False)\n",
    "    ax_right.spines['right'].set_visible(False)\n",
    "    ax_right.spines['top'].set_visible(False)\n",
    "\n",
    "    # Add title\n",
    "    position_text = f\" ({actor_position} side)\" if actor_position != \"both\" else \"\"\n",
    "    title = f\"Contour Heatmap with Marginal Distributions\\n{bot_name}{position_text} - {phase_name}\\n(n={len(phase_df):,} samples)\"\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.98)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def extract_timer_from_config(config_folder):\n",
    "    \"\"\"\n",
    "    Extract Timer value from config folder name\n",
    "    e.g., \"Timer_15__ActInterval_0.1\" -> 15\n",
    "\n",
    "    Args:\n",
    "        config_folder: Config folder name\n",
    "\n",
    "    Returns:\n",
    "        Timer value as float or None if not found\n",
    "    \"\"\"\n",
    "    import re\n",
    "    match = re.search(r'Timer_(\\d+(?:\\.\\d+)?)', config_folder)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_bot_data_from_simulation(base_dir, bot_name, actor_position=\"left\", chunksize=50000, max_configs=None, group_by_timer=False, also_load_distance=False):\n",
    "    \"\"\"\n",
    "    Load all CSV data for a specific bot from the simulation directory\n",
    "\n",
    "    Args:\n",
    "        base_dir: Base simulation directory\n",
    "        bot_name: Name of the bot (e.g., \"Bot_BT\", \"Bot_NN\", \"Bot_Primitive\")\n",
    "        actor_position: \"left\" (Actor 0) or \"right\" (Actor 1) or \"both\"\n",
    "        chunksize: Chunk size for reading CSV files\n",
    "        max_configs: Maximum number of config folders to process (None for all)\n",
    "        group_by_timer: If True, return dict of {timer_value: DataFrame}, else return combined DataFrame\n",
    "        also_load_distance: If True, also return timer-grouped distance data\n",
    "\n",
    "    Returns:\n",
    "        Combined DataFrame with all bot data, or dict of DataFrames grouped by Timer\n",
    "        If also_load_distance=True, returns tuple: (bot_data, distance_data)\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    timer_grouped_data = {}  # {timer_value: [dataframes]}\n",
    "    timer_distance_data = {}  # {timer_value: [distance dataframes]}\n",
    "\n",
    "    # Find all matchup folders containing this bot\n",
    "    matchup_folders = [f for f in os.listdir(base_dir)\n",
    "                      if os.path.isdir(os.path.join(base_dir, f)) and bot_name in f]\n",
    "\n",
    "    print(f\"Found {len(matchup_folders)} matchup folders for {bot_name}\")\n",
    "\n",
    "    total_csvs = 0\n",
    "    for matchup_folder in matchup_folders:\n",
    "        matchup_path = os.path.join(base_dir, matchup_folder)\n",
    "\n",
    "        # Determine actor filter based on bot position in matchup\n",
    "        # Bot_A_vs_Bot_B: Bot_A is actor 0 (left), Bot_B is actor 1 (right)\n",
    "        parts = matchup_folder.split(\"_vs_\")\n",
    "        if len(parts) == 2:\n",
    "            left_bot = parts[0]\n",
    "            is_left_bot = (bot_name == left_bot)\n",
    "\n",
    "            if actor_position == \"left\" and is_left_bot:\n",
    "                actor_filter = 0\n",
    "            elif actor_position == \"left\" and not is_left_bot:\n",
    "                continue  # Skip this matchup\n",
    "            elif actor_position == \"right\" and not is_left_bot:\n",
    "                actor_filter = 1\n",
    "            elif actor_position == \"right\" and is_left_bot:\n",
    "                continue  # Skip this matchup\n",
    "            elif actor_position == \"both\":\n",
    "                actor_filter = 0 if is_left_bot else 1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Get all config folders\n",
    "        config_folders = [f for f in os.listdir(matchup_path)\n",
    "                         if os.path.isdir(os.path.join(matchup_path, f))]\n",
    "\n",
    "        if max_configs:\n",
    "            config_folders = config_folders[:max_configs]\n",
    "\n",
    "        print(f\"  {matchup_folder}: {len(config_folders)} configs\")\n",
    "\n",
    "        # Process each config folder\n",
    "        for config_folder in tqdm(config_folders, desc=f\"  Loading {matchup_folder}\", leave=False):\n",
    "            config_path = os.path.join(matchup_path, config_folder)\n",
    "\n",
    "            # Find CSV file in this config folder\n",
    "            csv_files = glob.glob(os.path.join(config_path, \"*.csv\"))\n",
    "\n",
    "            if csv_files:\n",
    "                csv_path = csv_files[0]  # Should only be 1 CSV per config\n",
    "                df = load_data_chunked(csv_path, chunksize, actor_filter=actor_filter)\n",
    "\n",
    "                if not df.is_empty():\n",
    "                    # Also load distance data if requested\n",
    "                    if also_load_distance:\n",
    "                        df_all_actors = load_data_chunked(csv_path, chunksize, actor_filter=None)\n",
    "                        if not df_all_actors.is_empty():\n",
    "                            dist_df = calculate_distance_between_bots(df_all_actors)\n",
    "                            if not dist_df.is_empty():\n",
    "                                timer = extract_timer_from_config(config_folder)\n",
    "                                if timer is not None:\n",
    "                                    if timer not in timer_distance_data:\n",
    "                                        timer_distance_data[timer] = []\n",
    "                                    timer_distance_data[timer].append(dist_df)\n",
    "\n",
    "                    if group_by_timer:\n",
    "                        # Extract timer value and group\n",
    "                        timer = extract_timer_from_config(config_folder)\n",
    "                        if timer is not None:\n",
    "                            if timer not in timer_grouped_data:\n",
    "                                timer_grouped_data[timer] = []\n",
    "                            timer_grouped_data[timer].append(df)\n",
    "                    else:\n",
    "                        all_data.append(df)\n",
    "                    total_csvs += 1\n",
    "\n",
    "    if group_by_timer:\n",
    "        # Return dict of combined DataFrames per timer\n",
    "        if not timer_grouped_data:\n",
    "            print(\"No valid data found.\")\n",
    "            if also_load_distance:\n",
    "                return {}, {}\n",
    "            return {}\n",
    "\n",
    "        print(f\"\\nLoaded {total_csvs} CSV files\")\n",
    "        result = {}\n",
    "        for timer, dfs in timer_grouped_data.items():\n",
    "            print(f\"Combining data for Timer={timer}...\")\n",
    "            result[timer] = pl.concat(dfs, how=\"vertical_relaxed\")\n",
    "            print(f\"  Timer {timer}: {len(result[timer]):,} samples\")\n",
    "\n",
    "        if also_load_distance:\n",
    "            return result, timer_distance_data\n",
    "        return result\n",
    "    else:\n",
    "        # Return combined DataFrame\n",
    "        if not all_data:\n",
    "            print(\"No valid data found.\")\n",
    "            if also_load_distance:\n",
    "                return pl.DataFrame(), {}\n",
    "            return pl.DataFrame()\n",
    "\n",
    "        print(f\"\\nLoaded {total_csvs} CSV files\")\n",
    "        print(\"Combining all data...\")\n",
    "        df_combined = pl.concat(all_data, how=\"vertical_relaxed\")\n",
    "\n",
    "        print(f\"Total samples: {len(df_combined):,}\")\n",
    "\n",
    "        if also_load_distance:\n",
    "            return df_combined, timer_distance_data\n",
    "        return df_combined\n",
    "\n",
    "\n",
    "def calculate_distance_between_bots(df):\n",
    "    \"\"\"\n",
    "    Calculate distance between Bot 1 (Actor 0) and Bot 2 (Actor 1) for each game frame\n",
    "\n",
    "    Args:\n",
    "        df: Polars DataFrame with columns including Actor, BotPosX, BotPosY, GameIndex, UpdatedAt\n",
    "\n",
    "    Returns:\n",
    "        Polars DataFrame with distance between bots for each frame\n",
    "    \"\"\"\n",
    "    # Split data by actor - cast Actor inline for filtering\n",
    "    bot1_df = df.filter(pl.col(\"Actor\").cast(pl.Int64) == 0).select([\n",
    "        \"GameIndex\", \"UpdatedAt\", \"BotPosX\", \"BotPosY\"\n",
    "    ]).rename({\"BotPosX\": \"Bot1_X\", \"BotPosY\": \"Bot1_Y\"})\n",
    "\n",
    "    bot2_df = df.filter(pl.col(\"Actor\").cast(pl.Int64) == 1).select([\n",
    "        \"GameIndex\", \"UpdatedAt\", \"BotPosX\", \"BotPosY\"\n",
    "    ]).rename({\"BotPosX\": \"Bot2_X\", \"BotPosY\": \"Bot2_Y\"})\n",
    "\n",
    "    # Merge on GameIndex and UpdatedAt to align frames\n",
    "    merged = bot1_df.join(bot2_df, on=[\"GameIndex\", \"UpdatedAt\"], how=\"inner\")\n",
    "\n",
    "    # Calculate Euclidean distance\n",
    "    merged = merged.with_columns([\n",
    "        (((pl.col(\"Bot1_X\") - pl.col(\"Bot2_X\"))**2 +\n",
    "          (pl.col(\"Bot1_Y\") - pl.col(\"Bot2_Y\"))**2).sqrt()).alias(\"Distance\")\n",
    "    ])\n",
    "\n",
    "    return merged\n",
    "\n",
    "def calculate_distance_from_center(df):\n",
    "    \"\"\"\n",
    "    Calculate distance from arena center for each bot\n",
    "\n",
    "    Args:\n",
    "        df: Polars DataFrame with columns including Actor, BotPosX, BotPosY\n",
    "\n",
    "    Returns:\n",
    "        Polars DataFrame with distance from center for each bot\n",
    "    \"\"\"\n",
    "    # Calculate distance from center for each position\n",
    "    df = df.with_columns([\n",
    "        (((pl.col(\"BotPosX\") - arena_center[0])**2 +\n",
    "          (pl.col(\"BotPosY\") - arena_center[1])**2).sqrt()).alias(\"DistanceFromCenter\")\n",
    "    ])\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_distance_histogram_from_data(distance_data, bot_name, output_path=None):\n",
    "    \"\"\"\n",
    "    Plot histogram of distance between bot and all opponents\n",
    "\n",
    "    Args:\n",
    "        distance_data: Dict of {timer: [list of distance dataframes]}\n",
    "        bot_name: Name of the bot to analyze\n",
    "        output_path: Path to save the figure\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    if not distance_data:\n",
    "        print(\"No valid distance data found\")\n",
    "        return None\n",
    "\n",
    "    # Combine all distance data across all timers and opponents\n",
    "    all_distances = []\n",
    "    for timer, dfs in distance_data.items():\n",
    "        combined_df = pl.concat(dfs, how=\"vertical_relaxed\")\n",
    "        all_distances.append(combined_df[\"Distance\"].to_numpy())\n",
    "\n",
    "    # Concatenate all distances\n",
    "    distances = np.concatenate(all_distances)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot histogram\n",
    "    ax.hist(distances, bins=30, color='steelblue', edgecolor='black', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Distance Between Bots\", fontsize=12)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=12)\n",
    "    ax.set_title(f\"Distribution of Distance Between Bots\\n{bot_name} vs All Opponents\\n(n={len(distances):,} samples)\",\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add statistics text\n",
    "    mean_dist = np.mean(distances)\n",
    "    median_dist = np.median(distances)\n",
    "    std_dist = np.std(distances)\n",
    "    stats_text = f\"Mean: {mean_dist:.2f}\\nMedian: {median_dist:.2f}\\nStd: {std_dist:.2f}\"\n",
    "    ax.text(0.98, 0.98, stats_text,\n",
    "            transform=ax.transAxes, ha='right', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10, family='monospace')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or return\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved distance histogram to {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_distance_from_center_histogram(bot_data, bot_name, output_path=None):\n",
    "    \"\"\"\n",
    "    Plot histogram of distance from center for a specific bot\n",
    "\n",
    "    Args:\n",
    "        bot_data: DataFrame or dict of DataFrames with bot position data\n",
    "        bot_name: Name of the bot to analyze\n",
    "        output_path: Path to save the figure\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    # Handle both single DataFrame and dict of DataFrames\n",
    "    if isinstance(bot_data, dict):\n",
    "        # Combine all timer data\n",
    "        all_dfs = []\n",
    "        for timer, df in bot_data.items():\n",
    "            all_dfs.append(df)\n",
    "        combined_df = pl.concat(all_dfs, how=\"vertical_relaxed\")\n",
    "    else:\n",
    "        combined_df = bot_data\n",
    "\n",
    "    if combined_df.is_empty():\n",
    "        print(\"No valid data found\")\n",
    "        return None\n",
    "\n",
    "    # Calculate distance from center\n",
    "    df_with_center_dist = calculate_distance_from_center(combined_df)\n",
    "    distances = df_with_center_dist[\"DistanceFromCenter\"].to_numpy()\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot histogram\n",
    "    ax.hist(distances, bins=30, color='green', edgecolor='darkgreen', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "    # Add arena radius line\n",
    "    ax.axvline(arena_radius, color='red', linestyle='--', linewidth=2, label=f'Arena Radius ({arena_radius:.2f})')\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Distance from Center\", fontsize=12)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=12)\n",
    "    ax.set_title(f\"Distribution of Distance from Center\\n{bot_name}\\n(n={len(distances):,} samples)\",\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add statistics text\n",
    "    mean_dist = np.mean(distances)\n",
    "    median_dist = np.median(distances)\n",
    "    std_dist = np.std(distances)\n",
    "    stats_text = f\"Mean: {mean_dist:.2f}\\nMedian: {median_dist:.2f}\\nStd: {std_dist:.2f}\"\n",
    "    ax.text(0.02, 0.98, stats_text,\n",
    "            transform=ax.transAxes, ha='left', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10, family='monospace')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or return\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved distance from center histogram to {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_distance_over_time_from_data(timer_data, bot_name, output_path=None):\n",
    "    \"\"\"\n",
    "    Plot mean distance over time from pre-loaded timer-grouped data\n",
    "\n",
    "    Args:\n",
    "        timer_data: Dict of {timer: [list of distance dataframes]}\n",
    "        bot_name: Name of the bot to analyze\n",
    "        output_path: Path to save the figure\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    if not timer_data:\n",
    "        print(\"No valid data found\")\n",
    "        return None\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # Process each timer value\n",
    "    colors = plt.cm.tab10(range(len(timer_data)))\n",
    "\n",
    "    for idx, (timer, dfs) in enumerate(sorted(timer_data.items())):\n",
    "        # Combine all games for this timer (across all opponents)\n",
    "        combined_df = pl.concat(dfs, how=\"vertical_relaxed\")\n",
    "\n",
    "        print(f\"  Timer {timer}s: {len(combined_df):,} data points\")\n",
    "\n",
    "        # Calculate mean distance over time bins\n",
    "        # Bin UpdatedAt into time intervals, but only up to the Timer value\n",
    "        time_bins = 50  # Number of bins\n",
    "        # Use the Timer value as the max time for this specific config\n",
    "        max_time = timer  # Cut at the Timer config value\n",
    "        bin_size = max_time / time_bins\n",
    "\n",
    "        # Create time bins and calculate mean distance per bin\n",
    "        time_points = []\n",
    "        mean_distances = []\n",
    "        std_distances = []\n",
    "\n",
    "        for i in range(time_bins):\n",
    "            bin_start = i * bin_size\n",
    "            bin_end = (i + 1) * bin_size\n",
    "\n",
    "            bin_data = combined_df.filter(\n",
    "                (pl.col('UpdatedAt') >= bin_start) &\n",
    "                (pl.col('UpdatedAt') < bin_end)\n",
    "            )\n",
    "\n",
    "            if not bin_data.is_empty():\n",
    "                time_points.append((bin_start + bin_end) / 2)\n",
    "                mean_distances.append(bin_data['Distance'].mean())\n",
    "                # Handle None for std (when only 1 data point)\n",
    "                std_val = bin_data['Distance'].std()\n",
    "                std_distances.append(std_val if std_val is not None else 0.0)\n",
    "\n",
    "        # Convert to numpy for plotting\n",
    "        time_points = np.array(time_points)\n",
    "        mean_distances = np.array(mean_distances)\n",
    "        std_distances = np.array(std_distances)\n",
    "\n",
    "        # Plot line with markers\n",
    "        timer_label = f\"Timer {int(timer)}s\" if timer == int(timer) else f\"Timer {timer}s\"\n",
    "        ax.plot(time_points, mean_distances, marker='o', markersize=4,\n",
    "                linewidth=2, label=timer_label, color=colors[idx], alpha=0.8)\n",
    "\n",
    "        # Add confidence interval (mean Â± std)\n",
    "        ax.fill_between(time_points,\n",
    "                        mean_distances - std_distances,\n",
    "                        mean_distances + std_distances,\n",
    "                        alpha=0.2, color=colors[idx])\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Time (seconds)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Mean Distance Between Bots\", fontsize=12)\n",
    "    ax.set_title(f\"Mean Distance Over Time (vs All Opponents)\\n{bot_name}\",\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Limit x-axis to the maximum Timer value found\n",
    "    max_timer = max(timer_data.keys())\n",
    "    ax.set_xlim(0, max_timer)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or return\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved distance over time to {output_path}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_distance_distributions_all_matchups(base_dir, output_dir=\"arena_heatmaps\", chunksize=50000, max_configs=None, skip_initial=0.0):\n",
    "    \"\"\"\n",
    "    Create distance distribution plots per bot (averaged across all matchups).\n",
    "    Saves to {output_dir}/{bot_name}/distance_distribution.png\n",
    "\n",
    "    Args:\n",
    "        base_dir: Base simulation directory\n",
    "        output_dir: Output directory (should be arena_heatmaps folder)\n",
    "        chunksize: Chunk size for reading CSV files\n",
    "        max_configs: Maximum number of configs to process per matchup\n",
    "        skip_initial: Skip initial N seconds of data to remove spawn point bias (default: 0.0)\n",
    "    \"\"\"\n",
    "    # Find all matchup folders\n",
    "    matchup_folders = [f for f in os.listdir(base_dir)\n",
    "                      if os.path.isdir(os.path.join(base_dir, f)) and \"_vs_\" in f]\n",
    "\n",
    "    print(f\"Found {len(matchup_folders)} matchup folders\")\n",
    "\n",
    "    # Collect data per bot (across all matchups)\n",
    "    bot_distance_data = {}  # {bot_name: [distance_between_series, distance_from_center_series]}\n",
    "\n",
    "    # Process each matchup\n",
    "    for matchup_folder in matchup_folders:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Processing {matchup_folder}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Extract bot names\n",
    "        parts = matchup_folder.split(\"_vs_\")\n",
    "        if len(parts) != 2:\n",
    "            print(f\"  Skipping invalid matchup folder name: {matchup_folder}\")\n",
    "            continue\n",
    "\n",
    "        bot1_name, bot2_name = parts[0], parts[1]\n",
    "\n",
    "        # Load data for this matchup\n",
    "        df = load_all_game_data(base_dir, bot1_name, bot2_name, chunksize, max_configs)\n",
    "\n",
    "        if df.is_empty():\n",
    "            print(f\"  No data found for {matchup_folder}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Apply skip_initial filter if specified (per game)\n",
    "        if skip_initial > 0:\n",
    "            print(f\"  â© Skipping initial {skip_initial}s of data per game to remove spawn bias...\")\n",
    "            df = df.filter(\n",
    "                pl.col(\"UpdatedAt\") >= pl.col(\"UpdatedAt\").min().over(\"GameIndex\") + skip_initial\n",
    "            )\n",
    "            if df.is_empty():\n",
    "                print(f\"  No data remaining after skipping initial {skip_initial}s, skipping matchup...\")\n",
    "                continue\n",
    "            print(f\"  Samples after filter: {len(df):,}\")\n",
    "\n",
    "        # Calculate distance between bots\n",
    "        print(\"  Calculating distance between bots...\")\n",
    "        dist_between = calculate_distance_between_bots(df)\n",
    "\n",
    "        # Calculate distance from center for each bot\n",
    "        print(\"  Calculating distance from center...\")\n",
    "        df_with_center_dist = calculate_distance_from_center(df)\n",
    "\n",
    "        # Split by actor - bot1 is actor 0, bot2 is actor 1\n",
    "        bot1_center_dist = df_with_center_dist.filter(pl.col(\"Actor\").cast(pl.Int64) == 0)[\"DistanceFromCenter\"]\n",
    "        bot2_center_dist = df_with_center_dist.filter(pl.col(\"Actor\").cast(pl.Int64) == 1)[\"DistanceFromCenter\"]\n",
    "\n",
    "        # Store data for each bot\n",
    "        if bot1_name not in bot_distance_data:\n",
    "            bot_distance_data[bot1_name] = {\"between\": [], \"from_center\": []}\n",
    "        if bot2_name not in bot_distance_data:\n",
    "            bot_distance_data[bot2_name] = {\"between\": [], \"from_center\": []}\n",
    "\n",
    "        # Add distance between for both bots (it's the same data)\n",
    "        bot_distance_data[bot1_name][\"between\"].append(dist_between[\"Distance\"])\n",
    "        bot_distance_data[bot2_name][\"between\"].append(dist_between[\"Distance\"])\n",
    "\n",
    "        # Add distance from center for each bot\n",
    "        bot_distance_data[bot1_name][\"from_center\"].append(bot1_center_dist)\n",
    "        bot_distance_data[bot2_name][\"from_center\"].append(bot2_center_dist)\n",
    "\n",
    "    # Create distance distribution plot for each bot\n",
    "    for bot_name, data in bot_distance_data.items():\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Creating distance distribution for {bot_name}...\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Concatenate all data for this bot\n",
    "        combined_between = pl.concat(data[\"between\"])\n",
    "        combined_from_center = pl.concat(data[\"from_center\"])\n",
    "\n",
    "        between_numpy = combined_between.to_numpy()\n",
    "        from_center_numpy = combined_from_center.to_numpy()\n",
    "\n",
    "        # Create 2-subplot figure\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "        # Plot 1: Distance between bots (averaged across all matchups)\n",
    "        ax1.hist(between_numpy, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax1.set_title(f\"Distance Between {bot_name} and Opponents (All Matchups)\", fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel(\"Distance Between Bots\", fontsize=12)\n",
    "        ax1.set_ylabel(\"Frequency\", fontsize=12)\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax1.text(0.98, 0.98, f\"n={len(between_numpy):,}\",\n",
    "                transform=ax1.transAxes, ha='right', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "        # Plot 2: Distance from center\n",
    "        ax2.hist(from_center_numpy, bins=30, color='green', edgecolor='black', alpha=0.7)\n",
    "        ax2.set_title(f\"Distance from Center: {bot_name}\", fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel(\"Distance from Center\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Frequency\", fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "        # Add arena radius reference line\n",
    "        ax2.axvline(x=arena_radius, color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Arena Radius ({arena_radius:.2f})', alpha=0.8)\n",
    "        ax2.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "        ax2.text(0.98, 0.98, f\"n={len(from_center_numpy):,}\",\n",
    "                transform=ax2.transAxes, ha='right', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save to bot's folder\n",
    "        bot_output_dir = os.path.join(output_dir, bot_name)\n",
    "        os.makedirs(bot_output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(bot_output_dir, \"distance_distribution.png\")\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved to {output_path}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"âœ… Completed! Distance distribution plots saved in bot folders\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def load_all_game_data(base_dir, bot1_name=None, bot2_name=None, chunksize=50000, max_configs=None):\n",
    "    \"\"\"\n",
    "    Load all game data from simulation directory, optionally filtered by bot matchup\n",
    "\n",
    "    Args:\n",
    "        base_dir: Base simulation directory\n",
    "        bot1_name: Name of bot 1 (optional filter)\n",
    "        bot2_name: Name of bot 2 (optional filter)\n",
    "        chunksize: Chunk size for reading CSV files\n",
    "        max_configs: Maximum number of configs to process (None for all)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with all game data including both actors\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Find matchup folders\n",
    "    if bot1_name and bot2_name:\n",
    "        # Specific matchup\n",
    "        matchup_folder = f\"{bot1_name}_vs_{bot2_name}\"\n",
    "        matchup_folders = [matchup_folder] if os.path.exists(os.path.join(base_dir, matchup_folder)) else []\n",
    "    else:\n",
    "        # All matchups\n",
    "        matchup_folders = [f for f in os.listdir(base_dir)\n",
    "                          if os.path.isdir(os.path.join(base_dir, f)) and \"_vs_\" in f]\n",
    "\n",
    "    print(f\"Found {len(matchup_folders)} matchup folders\")\n",
    "\n",
    "    total_csvs = 0\n",
    "    for matchup_folder in matchup_folders:\n",
    "        matchup_path = os.path.join(base_dir, matchup_folder)\n",
    "\n",
    "        # Get all config folders\n",
    "        config_folders = [f for f in os.listdir(matchup_path)\n",
    "                         if os.path.isdir(os.path.join(matchup_path, f))]\n",
    "\n",
    "        if max_configs:\n",
    "            config_folders = config_folders[:max_configs]\n",
    "\n",
    "        print(f\"  {matchup_folder}: {len(config_folders)} configs\")\n",
    "\n",
    "        # Process each config folder\n",
    "        for config_folder in tqdm(config_folders, desc=f\"  Loading {matchup_folder}\", leave=False):\n",
    "            config_path = os.path.join(matchup_path, config_folder)\n",
    "\n",
    "            # Find CSV file\n",
    "            csv_files = glob.glob(os.path.join(config_path, \"*.csv\"))\n",
    "\n",
    "            if csv_files:\n",
    "                csv_path = csv_files[0]\n",
    "                # Load WITHOUT actor filter (we need both bots)\n",
    "                df = load_data_chunked(csv_path, chunksize, actor_filter=None)\n",
    "\n",
    "                if not df.is_empty():\n",
    "                    all_data.append(df)\n",
    "                    total_csvs += 1\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No valid data found.\")\n",
    "        return pl.DataFrame()\n",
    "\n",
    "    print(f\"\\nLoaded {total_csvs} CSV files\")\n",
    "    print(\"Combining all data...\")\n",
    "    df_combined = pl.concat(all_data, how=\"vertical_relaxed\")\n",
    "\n",
    "    print(f\"Total samples: {len(df_combined):,}\")\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "def create_phased_heatmaps_all_bots(base_dir, output_dir=\"arena_heatmap\", actor_position=\"both\", chunksize=50000, max_configs=None, mode=\"all\", use_timer=False, use_time_windows=False, include_distance_over_time=True, skip_initial=0.0):\n",
    "    \"\"\"\n",
    "    Create heatmaps and position distribution plots for all bots in the simulation directory\n",
    "    Saves individual phase/timer images for each bot\n",
    "\n",
    "    Args:\n",
    "        base_dir: Base simulation directory\n",
    "        output_dir: Output directory for heatmaps (default: \"arena_heatmap\")\n",
    "        actor_position: \"left\", \"right\", or \"both\"\n",
    "        chunksize: Chunk size for reading CSV files\n",
    "        max_configs: Maximum number of configs to process per matchup\n",
    "        mode: What to generate - \"heatmap\", \"position\", or \"all\" (default: \"all\")\n",
    "        use_timer: If True, group by Timer values instead of phases\n",
    "        use_time_windows: If True, group by fixed time windows [0-15s, 15-30s, 30-45s, 45-60s]\n",
    "        include_distance_over_time: If True, also generate distance over time plot (default: True)\n",
    "        skip_initial: Skip initial N seconds of data to remove spawn point bias (default: 0.0)\n",
    "    \"\"\"\n",
    "    # Find all unique bot names from matchup folders\n",
    "    matchup_folders = [f for f in os.listdir(base_dir)\n",
    "                      if os.path.isdir(os.path.join(base_dir, f)) and \"_vs_\" in f]\n",
    "\n",
    "    bot_names = set()\n",
    "    for matchup in matchup_folders:\n",
    "        parts = matchup.split(\"_vs_\")\n",
    "        if len(parts) == 2:\n",
    "            bot_names.add(parts[0])\n",
    "            bot_names.add(parts[1])\n",
    "\n",
    "    bot_names = sorted(bot_names)\n",
    "    print(f\"Found {len(bot_names)} unique bots: {bot_names}\")\n",
    "\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each bot\n",
    "    for bot_name in bot_names:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Processing {bot_name}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Create bot-specific directory\n",
    "        bot_dir = os.path.join(output_dir, bot_name)\n",
    "        os.makedirs(bot_dir, exist_ok=True)\n",
    "\n",
    "        # Generate heatmaps if requested\n",
    "        if mode in [\"heatmap\", \"all\"]:\n",
    "            if use_timer:\n",
    "                # Timer-based mode - load data with distance if needed\n",
    "                print(\"\\nLoading data grouped by Timer...\")\n",
    "                if include_distance_over_time:\n",
    "                    timer_data, distance_data = load_bot_data_from_simulation(\n",
    "                        base_dir, bot_name, actor_position, chunksize, max_configs,\n",
    "                        group_by_timer=True, also_load_distance=True\n",
    "                    )\n",
    "                else:\n",
    "                    timer_data = load_bot_data_from_simulation(\n",
    "                        base_dir, bot_name, actor_position, chunksize, max_configs,\n",
    "                        group_by_timer=True\n",
    "                    )\n",
    "\n",
    "                if not timer_data:\n",
    "                    print(f\"No data found for {bot_name}, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Apply skip_initial filter if specified\n",
    "                if skip_initial > 0:\n",
    "                    print(f\"\\nâ© Skipping initial {skip_initial}s of data per game to remove spawn bias...\")\n",
    "                    filtered_timer_data = {}\n",
    "                    for timer, df in timer_data.items():\n",
    "                        # Filter out data where UpdatedAt < (min_UpdatedAt_for_that_game + skip_initial) per game\n",
    "                        df_filtered = df.filter(\n",
    "                            pl.col(\"UpdatedAt\") >= pl.col(\"UpdatedAt\").min().over(\"GameIndex\") + skip_initial\n",
    "                        )\n",
    "                        if not df_filtered.is_empty():\n",
    "                            filtered_timer_data[timer] = df_filtered\n",
    "                            print(f\"  Timer {timer}: {len(df):,} -> {len(df_filtered):,} samples\")\n",
    "                    timer_data = filtered_timer_data\n",
    "\n",
    "                # Create plots for each timer value\n",
    "                for timer in sorted(timer_data.keys()):\n",
    "                    df = timer_data[timer]\n",
    "                    print(f\"\\nProcessing Timer={timer}...\")\n",
    "                    print(f\"  Samples: {len(df):,}\")\n",
    "                    print(f\"  Time range: {df['UpdatedAt'].min():.2f} - {df['UpdatedAt'].max():.2f}\")\n",
    "\n",
    "                    label = f\"Timer {int(timer)}s\" if timer == int(timer) else f\"Timer {timer}s\"\n",
    "                    fig = plot_joint_heatmap_with_distributions(df, label, bot_name, actor_position)\n",
    "\n",
    "                    if fig is not None:\n",
    "                        # Save with timer in filename\n",
    "                        timer_str = f\"{int(timer)}\" if timer == int(timer) else f\"{timer}\"\n",
    "                        output_path = os.path.join(bot_dir, f\"timer_{timer_str}.png\")\n",
    "                        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "                        print(f\"  Saved to {output_path}\")\n",
    "                        plt.close(fig)\n",
    "\n",
    "                # Generate distance plots if requested and data is available\n",
    "                if include_distance_over_time and distance_data:\n",
    "                    print(f\"\\nGenerating distance over time plot...\")\n",
    "                    output_path = os.path.join(bot_dir, \"distance_over_time.png\")\n",
    "                    fig = plot_distance_over_time_from_data(distance_data, bot_name, output_path)\n",
    "                    if fig is not None:\n",
    "                        plt.close(fig)\n",
    "\n",
    "                    print(f\"Generating distance histogram...\")\n",
    "                    output_path = os.path.join(bot_dir, \"distance_histogram.png\")\n",
    "                    fig = plot_distance_histogram_from_data(distance_data, bot_name, output_path)\n",
    "                    if fig is not None:\n",
    "                        plt.close(fig)\n",
    "\n",
    "                    print(f\"Generating distance from center histogram...\")\n",
    "                    output_path = os.path.join(bot_dir, \"distance_from_center_histogram.png\")\n",
    "                    fig = plot_distance_from_center_histogram(timer_data, bot_name, output_path)\n",
    "                    if fig is not None:\n",
    "                        plt.close(fig)\n",
    "\n",
    "            elif use_time_windows:\n",
    "                # Time window mode - fixed time windows [0-15s, 15-30s, 30-45s, 45-60s]\n",
    "                print(\"\\nLoading all data for time window grouping...\")\n",
    "                df_combined = load_bot_data_from_simulation(base_dir, bot_name, actor_position, chunksize, max_configs, group_by_timer=False)\n",
    "\n",
    "                if df_combined.is_empty():\n",
    "                    print(f\"No data found for {bot_name}, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Apply skip_initial filter if specified (per game)\n",
    "                if skip_initial > 0:\n",
    "                    print(f\"\\nâ© Skipping initial {skip_initial}s of data per game to remove spawn bias...\")\n",
    "                    original_count = len(df_combined)\n",
    "                    df_combined = df_combined.filter(\n",
    "                        pl.col(\"UpdatedAt\") >= pl.col(\"UpdatedAt\").min().over(\"GameIndex\") + skip_initial\n",
    "                    )\n",
    "                    print(f\"  Filtered: {original_count:,} -> {len(df_combined):,} samples\")\n",
    "\n",
    "                    if df_combined.is_empty():\n",
    "                        print(f\"No data remaining after filtering for {bot_name}, skipping...\")\n",
    "                        continue\n",
    "\n",
    "                # Define time windows: [0-15s], [15-30s], [30-45s], [45-60s]\n",
    "                time_windows = [\n",
    "                    (skip_initial, 15, f\"{skip_initial}-15s\") if skip_initial > 0 else (0, 15, \"0-15s\"),\n",
    "                    (15, 30, \"15-30s\"),\n",
    "                    (30, 45, \"30-45s\"),\n",
    "                    (45, 60, \"45-60s\")\n",
    "                ]\n",
    "\n",
    "                print(f\"\\nSplitting data into fixed time windows...\")\n",
    "                # Create plots for each time window\n",
    "                for start, end, window_name in time_windows:\n",
    "                    # Filter data for this time window\n",
    "                    window_df = df_combined.filter(\n",
    "                        (pl.col(\"UpdatedAt\") >= start) & (pl.col(\"UpdatedAt\") < end)\n",
    "                    )\n",
    "\n",
    "                    if window_df.is_empty():\n",
    "                        print(f\"  No data for {window_name}, skipping...\")\n",
    "                        continue\n",
    "\n",
    "                    print(f\"\\nProcessing {window_name}...\")\n",
    "                    print(f\"  Samples: {len(window_df):,}\")\n",
    "                    print(f\"  Time range: {window_df['UpdatedAt'].min():.2f} - {window_df['UpdatedAt'].max():.2f}\")\n",
    "\n",
    "                    # Create joint plot\n",
    "                    fig = plot_joint_heatmap_with_distributions(window_df, window_name, bot_name, actor_position)\n",
    "\n",
    "                    if fig is not None:\n",
    "                        # Save with window name in filename\n",
    "                        output_path = os.path.join(bot_dir, f\"window_{start}-{end}s.png\")\n",
    "                        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "                        print(f\"  Saved to {output_path}\")\n",
    "                        plt.close(fig)\n",
    "\n",
    "            else:\n",
    "                # Phase-based mode (original)\n",
    "                print(\"\\nLoading all data...\")\n",
    "                df_combined = load_bot_data_from_simulation(base_dir, bot_name, actor_position, chunksize, max_configs, group_by_timer=False)\n",
    "\n",
    "                if df_combined.is_empty():\n",
    "                    print(f\"No data found for {bot_name}, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Apply skip_initial filter if specified (per game)\n",
    "                if skip_initial > 0:\n",
    "                    print(f\"\\nâ© Skipping initial {skip_initial}s of data per game to remove spawn bias...\")\n",
    "                    original_count = len(df_combined)\n",
    "                    df_combined = df_combined.filter(\n",
    "                        pl.col(\"UpdatedAt\") >= pl.col(\"UpdatedAt\").min().over(\"GameIndex\") + skip_initial\n",
    "                    )\n",
    "                    print(f\"  Filtered: {original_count:,} -> {len(df_combined):,} samples\")\n",
    "\n",
    "                    if df_combined.is_empty():\n",
    "                        print(f\"No data remaining after filtering for {bot_name}, skipping...\")\n",
    "                        continue\n",
    "\n",
    "                print(f\"Time range: {df_combined['UpdatedAt'].min():.2f} - {df_combined['UpdatedAt'].max():.2f}\")\n",
    "\n",
    "                # Split into phases\n",
    "                print(\"\\nSplitting into phases...\")\n",
    "                phases = split_into_phases(df_combined, num_phases=3)\n",
    "                phase_names = [\"Early Game\", \"Mid Game\", \"Late Game\"]\n",
    "\n",
    "                # Create and save individual heatmaps for each phase\n",
    "                for idx, (phase_df, phase_name) in enumerate(zip(phases, phase_names)):\n",
    "                    print(f\"Creating {phase_name} joint heatmap with marginal distributions...\")\n",
    "\n",
    "                    if phase_df.is_empty():\n",
    "                        print(f\"  No data for {phase_name}, skipping...\")\n",
    "                        continue\n",
    "\n",
    "                    # Create joint plot with marginal distributions\n",
    "                    fig = plot_joint_heatmap_with_distributions(phase_df, phase_name, bot_name, actor_position)\n",
    "\n",
    "                    if fig is not None:\n",
    "                        # Save\n",
    "                        output_path = os.path.join(bot_dir, f\"{idx}.png\")\n",
    "                        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "                        print(f\"  Saved to {output_path}\")\n",
    "                        plt.close(fig)\n",
    "\n",
    "        # Generate position distribution if requested\n",
    "        if mode in [\"position\", \"all\"]:\n",
    "            # Load combined data if not already loaded (needed for position distribution)\n",
    "            if use_timer or use_time_windows:\n",
    "                print(\"\\nLoading combined data for position distribution...\")\n",
    "                df_combined = load_bot_data_from_simulation(base_dir, bot_name, actor_position, chunksize, max_configs, group_by_timer=False)\n",
    "\n",
    "                # Apply skip_initial filter if specified (per game)\n",
    "                if skip_initial > 0 and not df_combined.is_empty():\n",
    "                    print(f\"\\nâ© Skipping initial {skip_initial}s of data per game to remove spawn bias...\")\n",
    "                    original_count = len(df_combined)\n",
    "                    df_combined = df_combined.filter(\n",
    "                        pl.col(\"UpdatedAt\") >= pl.col(\"UpdatedAt\").min().over(\"GameIndex\") + skip_initial\n",
    "                    )\n",
    "                    print(f\"  Filtered: {original_count:,} -> {len(df_combined):,} samples\")\n",
    "\n",
    "            # Check if we have data\n",
    "            if 'df_combined' in locals() and not df_combined.is_empty():\n",
    "                # Create position distribution plot\n",
    "                print(f\"Creating position distribution plot...\")\n",
    "                fig_dist = plot_position_distribution(df_combined, bot_name, actor_position)\n",
    "\n",
    "                if fig_dist is not None:\n",
    "                    dist_path = os.path.join(bot_dir, \"position_distribution.png\")\n",
    "                    fig_dist.savefig(dist_path, dpi=150, bbox_inches='tight')\n",
    "                    print(f\"  Saved to {dist_path}\")\n",
    "                    plt.close(fig_dist)\n",
    "            else:\n",
    "                print(f\"No data available for position distribution\")\n",
    "\n",
    "    # ========== Generate distance distributions per bot ==========\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Generating distance distributions for each bot (across all matchups)...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Collect data per bot (across all matchups)\n",
    "    bot_distance_data = {}  # {bot_name: [distance_between_series, distance_from_center_series]}\n",
    "\n",
    "    # Process each matchup\n",
    "    for matchup_folder in matchup_folders:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Processing matchup: {matchup_folder}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Extract bot names\n",
    "        parts = matchup_folder.split(\"_vs_\")\n",
    "        if len(parts) != 2:\n",
    "            print(f\"  Skipping invalid matchup folder name: {matchup_folder}\")\n",
    "            continue\n",
    "\n",
    "        bot1_name, bot2_name = parts[0], parts[1]\n",
    "\n",
    "        # Load data for this matchup\n",
    "        df = load_all_game_data(base_dir, bot1_name, bot2_name, chunksize, max_configs)\n",
    "\n",
    "        if df.is_empty():\n",
    "            print(f\"  No data found for {matchup_folder}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Apply skip_initial filter if specified (per game)\n",
    "        if skip_initial > 0:\n",
    "            print(f\"  â© Skipping initial {skip_initial}s of data per game to remove spawn bias...\")\n",
    "            df = df.filter(\n",
    "                pl.col(\"UpdatedAt\") >= pl.col(\"UpdatedAt\").min().over(\"GameIndex\") + skip_initial\n",
    "            )\n",
    "            if df.is_empty():\n",
    "                print(f\"  No data remaining after skipping initial {skip_initial}s, skipping matchup...\")\n",
    "                continue\n",
    "            print(f\"  Samples after filter: {len(df):,}\")\n",
    "\n",
    "        # Calculate distance between bots\n",
    "        print(\"  Calculating distance between bots...\")\n",
    "        dist_between = calculate_distance_between_bots(df)\n",
    "\n",
    "        # Calculate distance from center for each bot\n",
    "        print(\"  Calculating distance from center...\")\n",
    "        df_with_center_dist = calculate_distance_from_center(df)\n",
    "\n",
    "        # Split by actor - bot1 is actor 0, bot2 is actor 1\n",
    "        bot1_center_dist = df_with_center_dist.filter(pl.col(\"Actor\").cast(pl.Int64) == 0)[\"DistanceFromCenter\"]\n",
    "        bot2_center_dist = df_with_center_dist.filter(pl.col(\"Actor\").cast(pl.Int64) == 1)[\"DistanceFromCenter\"]\n",
    "\n",
    "        # Store data for each bot\n",
    "        if bot1_name not in bot_distance_data:\n",
    "            bot_distance_data[bot1_name] = {\"between\": [], \"from_center\": []}\n",
    "        if bot2_name not in bot_distance_data:\n",
    "            bot_distance_data[bot2_name] = {\"between\": [], \"from_center\": []}\n",
    "\n",
    "        # Add distance between for both bots (it's the same data)\n",
    "        bot_distance_data[bot1_name][\"between\"].append(dist_between[\"Distance\"])\n",
    "        bot_distance_data[bot2_name][\"between\"].append(dist_between[\"Distance\"])\n",
    "\n",
    "        # Add distance from center for each bot\n",
    "        bot_distance_data[bot1_name][\"from_center\"].append(bot1_center_dist)\n",
    "        bot_distance_data[bot2_name][\"from_center\"].append(bot2_center_dist)\n",
    "\n",
    "    # Create distance distribution plot for each bot\n",
    "    for bot_name, data in bot_distance_data.items():\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Creating distance distribution for {bot_name}...\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Concatenate all data for this bot\n",
    "        combined_between = pl.concat(data[\"between\"])\n",
    "        combined_from_center = pl.concat(data[\"from_center\"])\n",
    "\n",
    "        between_numpy = combined_between.to_numpy()\n",
    "        from_center_numpy = combined_from_center.to_numpy()\n",
    "\n",
    "        # Create 2-subplot figure\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "        # Plot 1: Distance between bots (averaged across all matchups)\n",
    "        ax1.hist(between_numpy, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax1.set_title(f\"Distance Between {bot_name} and Opponents (All Matchups)\", fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel(\"Distance Between Bots\", fontsize=12)\n",
    "        ax1.set_ylabel(\"Frequency\", fontsize=12)\n",
    "        ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax1.text(0.98, 0.98, f\"n={len(between_numpy):,}\",\n",
    "                transform=ax1.transAxes, ha='right', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "        # Plot 2: Distance from center\n",
    "        ax2.hist(from_center_numpy, bins=30, color='green', edgecolor='black', alpha=0.7)\n",
    "        ax2.set_title(f\"Distance from Center: {bot_name}\", fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel(\"Distance from Center\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Frequency\", fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "        # Add arena radius reference line\n",
    "        ax2.axvline(x=arena_radius, color='red', linestyle='--', linewidth=2,\n",
    "                   label=f'Arena Radius ({arena_radius:.2f})', alpha=0.8)\n",
    "        ax2.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "        ax2.text(0.98, 0.98, f\"n={len(from_center_numpy):,}\",\n",
    "                transform=ax2.transAxes, ha='right', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save to bot's folder\n",
    "        bot_output_dir = os.path.join(output_dir, bot_name)\n",
    "        os.makedirs(bot_output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(bot_output_dir, \"distance_distribution.png\")\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved to {output_path}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"âœ… Completed! All visualizations saved to: {output_dir}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run to Generate Arena Heatmap figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "create_phased_heatmaps_all_bots(\n",
    "            csv_folder,\n",
    "            output_dir = \"arena_heatmaps\",\n",
    "            actor_position=\"both\",\n",
    "            chunksize=50000,\n",
    "            max_configs=None,  # None for all configs, only fill to test, e.g. 2 or 5 configs\n",
    "            mode=\"all\",  # Generate both heatmaps and position distributions\n",
    "            use_timer=False, # Group by existing Timer configuration\n",
    "            use_time_windows=True, # Use time windows [skip_initial-15, 15-30, 30-45, 45-60]\n",
    "            include_distance_over_time=True,  \n",
    "            skip_initial=2.5\n",
    "        )\n",
    "\n",
    "elapsed_seconds = time.time() - start\n",
    "hours, remainder = divmod(elapsed_seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "processing_time = f\"{int(hours):02d}:{int(minutes):02d}:{seconds:.2f}\"\n",
    "print(f\"\\nProcessing Time: {processing_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import io\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "import plotly.io as pio\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "\"\"\"\n",
    "Configuration and constants for sumobot analyzer\n",
    "\"\"\"\n",
    "\n",
    "# =====================\n",
    "# Arena Configuration\n",
    "# =====================\n",
    "arena_center = np.array([0.24, 1.97])\n",
    "arena_radius = 4.73485\n",
    "\n",
    "# =====================\n",
    "# Visualization Parameters\n",
    "# =====================\n",
    "tile_size = 0.7   # Larger = bigger heatmap tiles (lower resolution)\n",
    "\n",
    "# =====================\n",
    "# Bot Marker Configuration\n",
    "# =====================\n",
    "# Map bot names to matplotlib marker shapes for easy visual differentiation\n",
    "BOT_MARKER_MAP = {\n",
    "    \"Bot_NN\": \"o\",           # #1: NN - Circle\n",
    "    \"Bot_ML_Classification\": \"s\",          # #2: MLP - Square\n",
    "    \"Bot_MCTS\": \"8\",         # #3: MCTS - Octagon\n",
    "    \"Bot_FuzzyLogic\": \"^\",        # #4: Fuzzy - Triangle up\n",
    "    \"Bot_Primitive\": \"p\",    # #5: Primitive - Pentagon\n",
    "    \"Bot_GA\": \"h\",           # #6: GA - Hexagon\n",
    "    \"Bot_SLM_ActionGPT\": \"*\",          # #7: SLM - Star\n",
    "    \"Bot_PPO\": \"8\",          # #8: PPO - Octagon\n",
    "    \"Bot_BT\": \"X\",           # #9: BT - X filled\n",
    "    \"Bot_UtilityAI\": \"P\",      # #10: Utility - Plus\n",
    "    \"Bot_LLM_ActionGPT\": \"D\",          # #11: LLM - Diamond\n",
    "    \"Bot_FSM\": \"v\",          # #12: FSM - Triangle down\n",
    "    \"Bot_DQN\": \"d\",          # #13: DQN - Thin diamond\n",
    "}\n",
    "\n",
    "# Default marker if bot not in map\n",
    "DEFAULT_MARKER = \"o\"\n",
    "\n",
    "# =====================\n",
    "# Metric Name Mapping\n",
    "# =====================\n",
    "# Map metric/key names to proper display names\n",
    "METRIC_NAME_MAP = {\n",
    "    # Time-related metrics\n",
    "    \"MatchDur\": \"Match Duration\",\n",
    "    \"ActInterval\": \"Action Interval\",\n",
    "    \"Timer\": \"Timer\",\n",
    "    \"Duration\": \"Duration\",\n",
    "\n",
    "    # Win/Performance metrics\n",
    "    \"WinRate\": \"Win Rate\",\n",
    "    \"WinRate_L\": \"Win Rate (Left)\",\n",
    "    \"WinRate_R\": \"Win Rate (Right)\",\n",
    "    \"Rank\": \"Rank\",\n",
    "\n",
    "    # Action metrics\n",
    "    \"ActionCounts\": \"Action Counts\",\n",
    "    \"ActionCounts_L\": \"Action Counts (Left)\",\n",
    "    \"ActionCounts_R\": \"Action Counts (Right)\",\n",
    "    \"Actions\": \"Actions\",\n",
    "    \"AvgActions_L\": \"Avg Actions (Left)\",\n",
    "    \"AvgActions_R\": \"Avg Actions (Right)\",\n",
    "\n",
    "    # Collision metrics\n",
    "    \"Collisions\": \"Collisions\",\n",
    "    \"Collisions_L\": \"Collisions (Left)\",\n",
    "    \"Collisions_R\": \"Collisions (Right)\",\n",
    "    \"TotalCollisions\": \"Total Collisions\",\n",
    "    \"Actor_L\": \"Actor (Left)\",\n",
    "    \"Actor_R\": \"Actor (Right)\",\n",
    "    \"Tie\": \"Tie\",\n",
    "\n",
    "    # Specific action types\n",
    "    \"Accelerate_Act\": \"Accelerate\",\n",
    "    \"Accelerate_Dur\": \"Accelerate\",\n",
    "    \"Accelerate_Act_L\": \"Accelerate (Left)\",\n",
    "    \"Accelerate_Act_R\": \"Accelerate (Right)\",\n",
    "    \"TurnLeft_Act\": \"Turn Left\",\n",
    "    \"TurnLeft_Dur\": \"Turn Left\",\n",
    "    \"TurnLeft_Act_L\": \"Turn Left (Left)\",\n",
    "    \"TurnLeft_Act_R\": \"Turn Left (Right)\",\n",
    "    \"TurnRight_Act\": \"Turn Right\",\n",
    "    \"TurnRight_Dur\": \"Turn Right\",\n",
    "    \"TurnRight_Act_L\": \"Turn Right (Left)\",\n",
    "    \"TurnRight_Act_R\": \"Turn Right (Right)\",\n",
    "    \"Dash_Act\": \"Dash\",\n",
    "    \"Dash_Dur\": \"Dash\",\n",
    "\n",
    "    # Skill actions\n",
    "    \"SkillBoost_Act\": \"Skill Boost\",\n",
    "    \"SkillBoost_Dur\": \"Skill Boost\",\n",
    "    \"SkillBoost_Act_L\": \"Skill Boost (Left)\",\n",
    "    \"SkillBoost_Act_R\": \"Skill Boost (Right)\",\n",
    "    \"SkillStone_Act\": \"Skill Stone\",\n",
    "    \"SkillStone_Dur\": \"Skill Stone\",\n",
    "    \"SkillStone_Act_L\": \"Skill Stone (Left)\",\n",
    "    \"SkillStone_Act_R\": \"Skill Stone (Right)\",\n",
    "    \"TotalSkillAct\": \"Total Skill Actions\",\n",
    "\n",
    "    # Round/Game metrics\n",
    "    \"Round\": \"Round\",\n",
    "    \"RoundNumeric\": \"Round\",\n",
    "    \"SkillTypeNumeric\": \"Skill Type\",\n",
    "    \"Games\": \"Games\",\n",
    "\n",
    "    # Bot identifiers\n",
    "    \"Bot\": \"Bot\",\n",
    "    \"Bot_L\": \"Bot (Left)\",\n",
    "    \"Bot_R\": \"Bot (Right)\",\n",
    "    \"Enemy\": \"Enemy\",\n",
    "    \"Left_Side\": \"Left Side\",\n",
    "    \"Right_Side\": \"Right Side\",\n",
    "\n",
    "    # Skill types\n",
    "    \"Skill\": \"Skill\",\n",
    "    \"SkillType\": \"Skill Type\",\n",
    "    \"SkillLeft\": \"Skill (Left)\",\n",
    "    \"SkillRight\": \"Skill (Right)\",\n",
    "    \"SkillNumeric\": \"Skill (Numeric)\",\n",
    "\n",
    "    # Time bins\n",
    "    \"TimeBin\": \"Time Bin\",\n",
    "\n",
    "    # Other metrics\n",
    "    \"AvgDuration\": \"Avg Duration\",\n",
    "    \"MeanCount\": \"Mean Count\",\n",
    "    \"Count\": \"Count\",\n",
    "    \"Action\": \"Action\",\n",
    "    \"Side\": \"Side\",\n",
    "    \"BotWithRank\": \"Bot (with Rank)\",\n",
    "    \"BotWithRankLeft\": \"Bot (Left, with Rank)\",\n",
    "    \"BotWithRankRight\": \"Bot (Right, with Rank)\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_metric_name(metric_key):\n",
    "    \"\"\"\n",
    "    Get proper display name for a metric key.\n",
    "\n",
    "    Args:\n",
    "        metric_key: Raw metric/column name\n",
    "\n",
    "    Returns:\n",
    "        Proper display name if found in map, otherwise returns the raw metric key\n",
    "    \"\"\"\n",
    "    return METRIC_NAME_MAP.get(metric_key, metric_key)\n",
    "\n",
    "\n",
    "def get_bot_marker(bot_name):\n",
    "    \"\"\"\n",
    "    Get marker shape for a given bot name.\n",
    "\n",
    "    Args:\n",
    "        bot_name: Name of the bot\n",
    "\n",
    "    Returns:\n",
    "        Matplotlib marker string\n",
    "    \"\"\"\n",
    "    return BOT_MARKER_MAP.get(bot_name, DEFAULT_MARKER)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_legend_padding(ax, x_labels=None, rotation=0, base_padding=-0.15):\n",
    "    \"\"\"\n",
    "    Calculate dynamic padding for legend based on x-axis label length and rotation.\n",
    "\n",
    "    Args:\n",
    "        ax: Matplotlib axes object\n",
    "        x_labels: List of x-axis labels (optional, will try to get from ax if not provided)\n",
    "        rotation: Rotation angle of x-axis labels in degrees\n",
    "        base_padding: Base padding value (default: -0.15)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted padding value for bbox_to_anchor\n",
    "    \"\"\"\n",
    "    if x_labels is None:\n",
    "        # Try to get labels from the axis\n",
    "        x_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "    if not x_labels or all(not label for label in x_labels):\n",
    "        return base_padding\n",
    "\n",
    "    # Calculate maximum label length\n",
    "    max_label_len = max(len(str(label)) for label in x_labels)\n",
    "\n",
    "    # Calculate padding based on rotation and length\n",
    "    if rotation >= 30:\n",
    "        # For rotated labels, length affects vertical space more\n",
    "        # Longer labels need more space\n",
    "        extra_padding = (max_label_len - 10) * 0.005  # Adjust factor as needed\n",
    "        extra_padding = max(0, min(extra_padding, 0.15))  # Cap between 0 and 0.15\n",
    "    else:\n",
    "        # For horizontal labels, less impact\n",
    "        extra_padding = (max_label_len - 15) * 0.003\n",
    "        extra_padding = max(0, min(extra_padding, 0.1))\n",
    "\n",
    "    return base_padding - extra_padding\n",
    "\n",
    "def plot_grouped(summary, key=\"WinRate\", group_by=\"ActInterval\", width=10, height=7, chart_type=\"line\", error_type=\"std\"):\n",
    "    \"\"\"\n",
    "    Plot average win rate per bot, grouped by a specific configuration variable.\n",
    "\n",
    "    Parameters:\n",
    "        group_by: one of [\"ActInterval\", \"Timer\", \"Round\", \"SkillType\"]\n",
    "        chart_type: \"line\" for line chart with error bands, \"bar\" for bar chart\n",
    "        error_type: \"se\" for standard error (recommended), \"std\" for standard deviation,\n",
    "                    \"ci\" for 95% confidence interval\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Handle SkillType special case ---\n",
    "    # SkillType combines SkillLeft and SkillRight into a unified grouping\n",
    "    if group_by == \"SkillType\":\n",
    "        left_group_col = \"SkillLeft\"\n",
    "        right_group_col = \"SkillRight\"\n",
    "    else:\n",
    "        left_group_col = group_by\n",
    "        right_group_col = group_by\n",
    "\n",
    "    # --- Merge both sides ---\n",
    "    left_cols = [\"Bot_L\", f\"{key}_L\", left_group_col]\n",
    "    right_cols = [\"Bot_R\", f\"{key}_R\", right_group_col]\n",
    "\n",
    "    if \"Rank_L\" in summary.columns:\n",
    "        left_cols.append(\"Rank_L\")\n",
    "    if \"Rank_R\" in summary.columns:\n",
    "        right_cols.append(\"Rank_R\")\n",
    "\n",
    "    left = summary[left_cols].rename(\n",
    "        columns={\"Bot_L\": \"Bot\", f\"{key}_L\": key, \"Rank_L\": \"Rank\", left_group_col: group_by}\n",
    "    )\n",
    "    right = summary[right_cols].rename(\n",
    "        columns={\"Bot_R\": \"Bot\", f\"{key}_R\": key, \"Rank_R\": \"Rank\", right_group_col: group_by}\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([left, right], ignore_index=True)\n",
    "\n",
    "    # Fill missing Rank with large number so unranked bots go last\n",
    "    if \"Rank\" not in combined.columns:\n",
    "        combined[\"Rank\"] = np.nan\n",
    "    combined[\"Rank\"] = combined[\"Rank\"].fillna(9999)\n",
    "\n",
    "    # --- Aggregate (with std and count) ---\n",
    "    grouped = (\n",
    "        combined.groupby([\"Bot\", group_by], dropna=False)\n",
    "        .agg({key: [\"mean\", \"std\", \"count\"], \"Rank\": \"first\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Flatten column names\n",
    "    grouped.columns = [\"Bot\", group_by, f\"{key}_mean\", f\"{key}_std\", f\"{key}_count\", \"Rank\"]\n",
    "    grouped[f\"{key}_std\"] = grouped[f\"{key}_std\"].fillna(0)  # Handle cases with no std\n",
    "    grouped[f\"{key}_count\"] = grouped[f\"{key}_count\"].fillna(1)  # Avoid division by zero\n",
    "\n",
    "    # --- Sort bots by Rank ---\n",
    "    bot_order = grouped.groupby(\"Bot\")[\"Rank\"].first().sort_values().index.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "    if chart_type == \"line\":\n",
    "        # --- Line chart with error bands ---\n",
    "        x_values = sorted(grouped[group_by].unique())\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(bot_order)))\n",
    "\n",
    "        for i, bot in enumerate(bot_order):\n",
    "            bot_data = grouped[grouped[\"Bot\"] == bot].sort_values(group_by)\n",
    "            rank = int(bot_data[\"Rank\"].iloc[0])\n",
    "\n",
    "            means = []\n",
    "            errors = []\n",
    "            for x_val in x_values:\n",
    "                row = bot_data[bot_data[group_by] == x_val]\n",
    "                if not row.empty:\n",
    "                    mean_val = row[f\"{key}_mean\"].values[0]\n",
    "                    std_val = row[f\"{key}_std\"].values[0]\n",
    "                    count_val = row[f\"{key}_count\"].values[0]\n",
    "\n",
    "                    means.append(mean_val)\n",
    "\n",
    "                    # Calculate error based on error_type\n",
    "                    if error_type == \"se\":\n",
    "                        # Standard Error\n",
    "                        error = std_val / np.sqrt(count_val) if count_val > 0 else 0\n",
    "                    elif error_type == \"ci\":\n",
    "                        # 95% Confidence Interval (approximation using 1.96 * SE)\n",
    "                        error = 1.96 * (std_val / np.sqrt(count_val)) if count_val > 0 else 0\n",
    "                    else:  # \"std\"\n",
    "                        error = std_val\n",
    "\n",
    "                    errors.append(error)\n",
    "                else:\n",
    "                    means.append(np.nan)\n",
    "                    errors.append(0)\n",
    "\n",
    "            means = np.array(means)\n",
    "            errors = np.array(errors)\n",
    "\n",
    "            # Plot line with thicker style and bot-specific marker\n",
    "            marker = get_bot_marker(bot)\n",
    "            ax.plot(x_values, means, marker=marker, linestyle='-', linewidth=2.5, markersize=7,\n",
    "                   label=f\"{bot} (#{rank})\", color=colors[i])\n",
    "\n",
    "            # Plot error band with lighter transparency\n",
    "            # ax.fill_between(x_values, means - errors, means + errors,\n",
    "            #               alpha=0.15, color=colors[i])\n",
    "\n",
    "        ax.set_xlabel(get_metric_name(group_by), fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(get_metric_name(key), fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks(x_values)\n",
    "        ax.set_xticklabels([str(x) for x in x_values])\n",
    "\n",
    "        # Set Y-axis limits for WinRate\n",
    "        if key == \"WinRate\":\n",
    "            ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    else:\n",
    "        # --- Bar chart (original) ---\n",
    "        grouped_bar = grouped.rename(columns={f\"{key}_mean\": key})\n",
    "        grouped_bar[\"Bot\"] = pd.Categorical(grouped_bar[\"Bot\"], categories=bot_order, ordered=True)\n",
    "        grouped_bar = grouped_bar.sort_values([\"Bot\", group_by])\n",
    "\n",
    "        labels = [\n",
    "            f\"{b} (#{int(grouped_bar[grouped_bar['Bot'] == b]['Rank'].iloc[0])})\"\n",
    "            for b in bot_order\n",
    "        ]\n",
    "\n",
    "        groups = sorted(grouped_bar[group_by].unique())\n",
    "        x = np.arange(len(bot_order))\n",
    "        bar_width = 0.8 / len(groups)\n",
    "\n",
    "        for i, g in enumerate(groups):\n",
    "            subset = grouped_bar[grouped_bar[group_by] == g]\n",
    "            avg_by_bot = subset.set_index(\"Bot\").reindex(bot_order)[key].fillna(0)\n",
    "            ax.bar(x + i * bar_width, avg_by_bot, width=bar_width, label=str(g))\n",
    "\n",
    "        ax.set_xticks(x + bar_width * (len(groups) - 1) / 2)\n",
    "        ax.set_xticklabels(labels, rotation=30, ha=\"right\")\n",
    "        ax.set_xlabel(\"Bots\")\n",
    "\n",
    "    # --- Common styling ---\n",
    "    ax.set_title(f\"{get_metric_name(key)} grouped by {get_metric_name(group_by)}\", fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "    # Calculate dynamic padding for legend\n",
    "    legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "    ax.legend(title=\"Bot (Rank)\" if chart_type == \"line\" else group_by,\n",
    "             loc='upper center', bbox_to_anchor=(0.5, legend_padding), fontsize=10, framealpha=0.9, ncol=3, markerscale=1.2)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5, linewidth=0.8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "def prepare_individual_bot_data(df, bot_name):\n",
    "    \"\"\"\n",
    "    Prepare data for a specific bot combining left and right perspectives.\n",
    "\n",
    "    Args:\n",
    "        df: Summary matchup dataframe\n",
    "        bot_name: Name of the bot to analyze\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with bot's data from all configurations\n",
    "    \"\"\"\n",
    "    # Bot_L perspective\n",
    "    df_left = df[df['Bot_L'] == bot_name].copy()\n",
    "    df_left['WinRate'] = df_left['WinRate_L']\n",
    "    df_left['Actions'] = df_left['ActionCounts_L']\n",
    "    df_left['Collisions'] = df_left['Collisions_L']\n",
    "    df_left['Collisions_Hit'] = df_left['Collisions_L']  # Hit (Actor_L)\n",
    "    df_left['Collisions_Struck'] = df_left['Collisions_R']  # Struck (Actor_R)\n",
    "    df_left['Collisions_Tie'] = df_left['Collisions_Tie']  # Tie\n",
    "    df_left['Duration'] = df_left['Duration_L']\n",
    "    df_left['Accelerate_Act'] = df_left['Accelerate_Act_L']\n",
    "    df_left['TurnLeft_Act'] = df_left['TurnLeft_Act_L']\n",
    "    df_left['TurnRight_Act'] = df_left['TurnRight_Act_L']\n",
    "    df_left['Dash_Act'] = df_left['Dash_Act_L']\n",
    "    df_left['SkillBoost_Act'] = df_left['SkillBoost_Act_L']\n",
    "    df_left['SkillStone_Act'] = df_left['SkillStone_Act_L']\n",
    "\n",
    "    df_left['Accelerate_Dur'] = df_left['Accelerate_Dur_L']\n",
    "    df_left['TurnLeft_Dur'] = df_left['TurnLeft_Dur_L']\n",
    "    df_left['TurnRight_Dur'] = df_left['TurnRight_Dur_L']\n",
    "    df_left['Dash_Dur'] = df_left['Dash_Dur_L']\n",
    "    # df_left['SkillBoost_Dur'] = df_left['SkillBoost_Dur_L']\n",
    "    # df_left['SkillStone_Dur'] = df_left['SkillStone_Dur_L']\n",
    "\n",
    "    df_left['SkillType'] = df_left['SkillLeft']\n",
    "\n",
    "    # Bot_R perspective\n",
    "    df_right = df[df['Bot_R'] == bot_name].copy()\n",
    "    df_right['WinRate'] = df_right['WinRate_R']\n",
    "    df_right['Actions'] = df_right['ActionCounts_R']\n",
    "    df_right['Collisions'] = df_right['Collisions_R']\n",
    "    df_right['Collisions_Hit'] = df_right['Collisions_R']  # Hit (Actor_R when on right)\n",
    "    df_right['Collisions_Struck'] = df_right['Collisions_L']  # Struck (Actor_L when on right)\n",
    "    df_right['Collisions_Tie'] = df_right['Collisions_Tie']  # Tie\n",
    "    df_right['Duration'] = df_right['Duration_R']\n",
    "    df_right['Accelerate_Act'] = df_right['Accelerate_Act_R']\n",
    "    df_right['TurnLeft_Act'] = df_right['TurnLeft_Act_R']\n",
    "    df_right['TurnRight_Act'] = df_right['TurnRight_Act_R']\n",
    "    df_right['Dash_Act'] = df_right['Dash_Act_R']\n",
    "    df_right['SkillBoost_Act'] = df_right['SkillBoost_Act_R']\n",
    "    df_right['SkillStone_Act'] = df_right['SkillStone_Act_R']\n",
    "\n",
    "    df_right['Accelerate_Dur'] = df_right['Accelerate_Dur_R']\n",
    "    df_right['TurnLeft_Dur'] = df_right['TurnLeft_Dur_R']\n",
    "    df_right['TurnRight_Dur'] = df_right['TurnRight_Dur_R']\n",
    "    df_right['Dash_Dur'] = df_right['Dash_Dur_R']\n",
    "    # df_right['SkillBoost_Dur'] = df_right['SkillBoost_Dur_R']\n",
    "    # df_right['SkillStone_Dur'] = df_right['SkillStone_Dur_R']\n",
    "\n",
    "    df_right['SkillType'] = df_right['SkillRight']\n",
    "\n",
    "    # Combine both perspectives\n",
    "    bot_data = pd.concat([df_left, df_right], ignore_index=True)\n",
    "\n",
    "    # Add derived columns\n",
    "    bot_data['RoundNumeric'] = bot_data['Round'].map({'BestOf1': 1, 'BestOf3': 3})\n",
    "    bot_data['TotalSkillAct'] = bot_data['SkillBoost_Act'] + bot_data['SkillStone_Act']\n",
    "\n",
    "    # Encode SkillType as numeric for correlation\n",
    "    skill_map = {'Stone': 1, 'Boost': 2}\n",
    "    bot_data['SkillTypeNumeric'] = bot_data['SkillType'].map(skill_map)\n",
    "\n",
    "    return bot_data\n",
    "\n",
    "\n",
    "def plot_individual_correlation_scatter(data, x_col, y_col, title, bot_name,\n",
    "                                       alpha=0.95, figsize=(10, 8), add_jitter=False):\n",
    "    \"\"\"\n",
    "    Create scatter plot with regression line and Pearson correlation for individual bot.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame with bot's data\n",
    "        x_col: Column name for x-axis\n",
    "        y_col: Column name for y-axis (should be WinRate)\n",
    "        title: Plot title\n",
    "        bot_name: Name of the bot\n",
    "        alpha: Transparency of scatter points\n",
    "        figsize: Figure size tuple\n",
    "        add_jitter: If True, add jitter to x-axis for discrete variables\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    # Remove NaN values\n",
    "    plot_data = data[[x_col, y_col]].dropna().copy()\n",
    "\n",
    "    if len(plot_data) < 2:\n",
    "        return None\n",
    "\n",
    "    # Calculate Pearson correlation (on original data)\n",
    "    pearson_r, pearson_p = stats.pearsonr(plot_data[x_col], plot_data[y_col])\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Add jitter for discrete variables to spread out points\n",
    "    x_values = plot_data[x_col].values.copy()\n",
    "    if add_jitter:\n",
    "        # Determine jitter amount based on the range of x values\n",
    "        unique_vals = np.unique(x_values)\n",
    "        if len(unique_vals) <= 5:  # Discrete variable\n",
    "            x_range = x_values.max() - x_values.min()\n",
    "            jitter_amount = x_range * 0.02 if x_range > 0 else 0.01\n",
    "            x_jittered = x_values + np.random.normal(0, jitter_amount, size=len(x_values))\n",
    "        else:\n",
    "            x_jittered = x_values\n",
    "    else:\n",
    "        x_jittered = x_values\n",
    "\n",
    "    # Scatter plot with jittered x values\n",
    "    ax.scatter(x_jittered, plot_data[y_col],\n",
    "              alpha=alpha, s=60, color='steelblue', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "    # Add regression line (using original non-jittered data)\n",
    "    slope, intercept = np.polyfit(x_values, plot_data[y_col], 1)\n",
    "    x_line = np.linspace(x_values.min(), x_values.max(), 100)\n",
    "    y_line = slope * x_line + intercept\n",
    "    ax.plot(x_line, y_line, 'r-', linewidth=2.5, label=f'Regression Line')\n",
    "\n",
    "    # Add correlation info to plot\n",
    "    corr_text = f'Pearson r = {pearson_r:.3f}\\np-value = {pearson_p:.3e}\\nn = {len(plot_data)}'\n",
    "    ax.text(0.05, 0.95, corr_text, transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "            facecolor='wheat', alpha=0.8), fontsize=11, family='monospace')\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(get_metric_name(x_col), fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(get_metric_name(y_col), fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{title}\\n{bot_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.legend(loc='best', fontsize=10, framealpha=0.9, markerscale=1.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_individual_bot_correlations(df, bot_name, width=10, height=8,alpha=0.2):\n",
    "    \"\"\"\n",
    "    Create all correlation plots for a specific bot.\n",
    "    For config variables, plots win rate directly against the config values.\n",
    "    For actions/collisions, creates separate plots for each config value.\n",
    "\n",
    "    Args:\n",
    "        df: Summary matchup dataframe\n",
    "        bot_name: Name of the bot to analyze\n",
    "        width: Figure width\n",
    "        height: Figure height\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of figures with nested structure for config-separated plots\n",
    "    \"\"\"\n",
    "    # Prepare data for this bot\n",
    "    data = prepare_individual_bot_data(df, bot_name)\n",
    "\n",
    "    if data.empty:\n",
    "        return {}\n",
    "\n",
    "    figs = {}\n",
    "\n",
    "    # a. Winrate vs ActInterval (direct correlation)\n",
    "    fig = plot_individual_correlation_scatter(\n",
    "        data,\n",
    "        x_col='ActInterval',\n",
    "        y_col='WinRate',\n",
    "        title='Win Rate vs Action Interval',\n",
    "        bot_name=bot_name,\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False\n",
    "    )\n",
    "    if fig:\n",
    "        figs['actinterval'] = fig\n",
    "\n",
    "    # b. Winrate vs Round type (direct correlation)\n",
    "    # Build dynamic round type mapping for title\n",
    "    round_mapping = data[['Round', 'RoundNumeric']].drop_duplicates().dropna()\n",
    "    round_labels = ', '.join([f\"{int(row['RoundNumeric'])}={row['Round']}\"\n",
    "                              for _, row in round_mapping.sort_values('RoundNumeric').iterrows()])\n",
    "    round_title = f'Win Rate vs Round Type ({round_labels})' if round_labels else 'Win Rate vs Round Type'\n",
    "\n",
    "    fig = plot_individual_correlation_scatter(\n",
    "        data,\n",
    "        x_col='RoundNumeric',\n",
    "        y_col='WinRate',\n",
    "        title=round_title,\n",
    "        bot_name=bot_name,\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False\n",
    "    )\n",
    "    if fig:\n",
    "        figs['roundtype'] = fig\n",
    "\n",
    "    # c. Winrate vs Timer (direct correlation)\n",
    "    fig = plot_individual_correlation_scatter(\n",
    "        data,\n",
    "        x_col='Timer',\n",
    "        y_col='WinRate',\n",
    "        title='Win Rate vs Timer Duration',\n",
    "        bot_name=bot_name,\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False\n",
    "    )\n",
    "    if fig:\n",
    "        figs['timer'] = fig\n",
    "\n",
    "    # d. Winrate vs Skill Type (direct correlation)\n",
    "    fig = plot_individual_correlation_scatter(\n",
    "        data,\n",
    "        x_col='SkillTypeNumeric',\n",
    "        y_col='WinRate',\n",
    "        title='Win Rate vs Skill Type (1=Stone, 2=Boost)',\n",
    "        bot_name=bot_name,\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False\n",
    "    )\n",
    "    if fig:\n",
    "        figs['skilltype'] = fig\n",
    "\n",
    "    # e. Winrate vs Individual Actions (combined across all configs)\n",
    "    action_types = ['Accelerate_Act', 'TurnLeft_Act', 'TurnRight_Act',\n",
    "                   'Dash_Act', 'SkillBoost_Act', 'SkillStone_Act']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(width*1.8, height*1.2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, action in enumerate(action_types):\n",
    "        if action not in data.columns:\n",
    "            continue\n",
    "\n",
    "        plot_data = data[[action, 'WinRate']].dropna()\n",
    "\n",
    "        if len(plot_data) < 2:\n",
    "            axes[idx].text(0.5, 0.5, f'Insufficient data',\n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            continue\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson_r, pearson_p = stats.pearsonr(plot_data[action], plot_data['WinRate'])\n",
    "\n",
    "        # Scatter plot\n",
    "        axes[idx].scatter(plot_data[action], plot_data['WinRate'],\n",
    "                        alpha=alpha, s=50, color='steelblue', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "        # Regression line\n",
    "        if len(plot_data) >= 2 and plot_data[action].std() > 0:\n",
    "            slope, intercept = np.polyfit(plot_data[action], plot_data['WinRate'], 1)\n",
    "            x_line = np.linspace(plot_data[action].min(), plot_data[action].max(), 100)\n",
    "            y_line = slope * x_line + intercept\n",
    "            axes[idx].plot(x_line, y_line, 'r-', linewidth=2)\n",
    "\n",
    "        # Correlation info\n",
    "        corr_text = f'r={pearson_r:.3f}\\np={pearson_p:.2e}'\n",
    "        axes[idx].text(0.05, 0.95, corr_text, transform=axes[idx].transAxes,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat', alpha=0.8), fontsize=9, family='monospace')\n",
    "\n",
    "        axes[idx].set_xlabel(get_metric_name(action), fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_ylabel(get_metric_name('WinRate'), fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_title(f'{get_metric_name(\"WinRate\")} vs {get_metric_name(action)}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.suptitle(f'Win Rate vs Individual Action Types\\n{bot_name}',\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    figs['actions'] = fig\n",
    "\n",
    "    # f. Winrate vs Individual Actions Duration (combined across all configs)\n",
    "    action_dur_types = ['Accelerate_Dur', 'TurnLeft_Dur', 'TurnRight_Dur', 'Dash_Dur']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(width*1.2, height*1.2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, action in enumerate(action_dur_types):\n",
    "        if action not in data.columns:\n",
    "            continue\n",
    "\n",
    "        plot_data = data[[action, 'WinRate']].dropna()\n",
    "\n",
    "        if len(plot_data) < 2:\n",
    "            axes[idx].text(0.5, 0.5, f'Insufficient data',\n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            continue\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson_r, pearson_p = stats.pearsonr(plot_data[action], plot_data['WinRate'])\n",
    "\n",
    "        # Scatter plot\n",
    "        axes[idx].scatter(plot_data[action], plot_data['WinRate'],\n",
    "                        alpha=alpha, s=50, color='steelblue', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "        # Regression line\n",
    "        if len(plot_data) >= 2 and plot_data[action].std() > 0:\n",
    "            slope, intercept = np.polyfit(plot_data[action], plot_data['WinRate'], 1)\n",
    "            x_line = np.linspace(plot_data[action].min(), plot_data[action].max(), 100)\n",
    "            y_line = slope * x_line + intercept\n",
    "            axes[idx].plot(x_line, y_line, 'r-', linewidth=2)\n",
    "\n",
    "        # Correlation info\n",
    "        corr_text = f'r={pearson_r:.3f}\\np={pearson_p:.2e}'\n",
    "        axes[idx].text(0.05, 0.95, corr_text, transform=axes[idx].transAxes,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat', alpha=0.8), fontsize=9, family='monospace')\n",
    "\n",
    "        axes[idx].set_xlabel(get_metric_name(action), fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_ylabel(get_metric_name('WinRate'), fontsize=10, fontweight='bold')\n",
    "        axes[idx].set_title(f'{get_metric_name(\"WinRate\")} vs {get_metric_name(action)}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.suptitle(f'Win Rate vs Individual Action Duration\\n{bot_name}',\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    figs['actions_dur'] = fig\n",
    "\n",
    "    # g. Winrate vs Collision Types (Hit, Struck, Tie) - Combined across all configs\n",
    "    collision_types = ['Collisions_Hit', 'Collisions_Struck', 'Collisions_Tie']\n",
    "    collision_labels = {'Collisions_Hit': 'Hit', 'Collisions_Struck': 'Struck', 'Collisions_Tie': 'Tie'}\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(width*1.8, height))\n",
    "\n",
    "    for idx, col_type in enumerate(collision_types):\n",
    "        if col_type not in data.columns:\n",
    "            continue\n",
    "\n",
    "        plot_data = data[[col_type, 'WinRate']].dropna()\n",
    "\n",
    "        if len(plot_data) < 2:\n",
    "            axes[idx].text(0.5, 0.5, f'Insufficient data',\n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            continue\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson_r, pearson_p = stats.pearsonr(plot_data[col_type], plot_data['WinRate'])\n",
    "\n",
    "        # Scatter plot\n",
    "        axes[idx].scatter(plot_data[col_type], plot_data['WinRate'],\n",
    "                        alpha=alpha, s=60, color='steelblue', edgecolors='black', linewidth=0.5)\n",
    "\n",
    "        # Regression line\n",
    "        if len(plot_data) >= 2 and plot_data[col_type].std() > 0:\n",
    "            slope, intercept = np.polyfit(plot_data[col_type], plot_data['WinRate'], 1)\n",
    "            x_line = np.linspace(plot_data[col_type].min(), plot_data[col_type].max(), 100)\n",
    "            y_line = slope * x_line + intercept\n",
    "            axes[idx].plot(x_line, y_line, 'r-', linewidth=2.5)\n",
    "\n",
    "        # Correlation info\n",
    "        corr_text = f'r={pearson_r:.3f}\\np={pearson_p:.2e}'\n",
    "        axes[idx].text(0.05, 0.95, corr_text, transform=axes[idx].transAxes,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat', alpha=0.8), fontsize=10, family='monospace')\n",
    "\n",
    "        axes[idx].set_xlabel(collision_labels[col_type], fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_ylabel(get_metric_name('WinRate'), fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_title(f'{get_metric_name(\"WinRate\")} vs {collision_labels[col_type]}',\n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    plt.suptitle(f'Win Rate vs Collision Types\\n{bot_name}',\n",
    "                 fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    figs['collisions'] = fig\n",
    "\n",
    "    return figs\n",
    "\n",
    "\n",
    "def calculate_legend_padding(ax, x_labels=None, rotation=0, base_padding=-0.15):\n",
    "    \"\"\"\n",
    "    Calculate dynamic padding for legend based on x-axis label length and rotation.\n",
    "\n",
    "    Args:\n",
    "        ax: Matplotlib axes object\n",
    "        x_labels: List of x-axis labels (optional, will try to get from ax if not provided)\n",
    "        rotation: Rotation angle of x-axis labels in degrees\n",
    "        base_padding: Base padding value (default: -0.15)\n",
    "\n",
    "    Returns:\n",
    "        Adjusted padding value for bbox_to_anchor\n",
    "    \"\"\"\n",
    "    if x_labels is None:\n",
    "        # Try to get labels from the axis\n",
    "        x_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "\n",
    "    if not x_labels or all(not label for label in x_labels):\n",
    "        return base_padding\n",
    "\n",
    "    # Calculate maximum label length\n",
    "    max_label_len = max(len(str(label)) for label in x_labels)\n",
    "\n",
    "    # Calculate padding based on rotation and length\n",
    "    if rotation >= 30:\n",
    "        # For rotated labels, length affects vertical space more\n",
    "        # Longer labels need more space\n",
    "        extra_padding = (max_label_len - 10) * 0.1  # Adjust factor as needed\n",
    "        extra_padding = max(0, min(extra_padding, 0.1))  # Cap between 0 and 0.15\n",
    "    else:\n",
    "        # For horizontal labels, less impact\n",
    "        extra_padding = (max_label_len - 15) * 0.1\n",
    "        extra_padding = max(0, min(extra_padding, 0.1))\n",
    "\n",
    "    return base_padding - extra_padding\n",
    "\n",
    "\n",
    "def plot_with_bot_markers(ax, data, x, y, hue, hue_order=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot line plot with bot-specific markers.\n",
    "\n",
    "    Args:\n",
    "        ax: Matplotlib axes object\n",
    "        data: pandas DataFrame with plot data\n",
    "        x: Column name for x-axis\n",
    "        y: Column name for y-axis\n",
    "        hue: Column name for grouping (bot names or bot names with rank)\n",
    "        hue_order: List specifying order of hue values (optional)\n",
    "        **kwargs: Additional plot keywords (linewidth, alpha, etc.)\n",
    "\n",
    "    Example:\n",
    "        >>> fig, ax = plt.subplots()\n",
    "        >>> plot_with_bot_markers(ax, data=df, x=\"Timer\", y=\"WinRate\",\n",
    "        ...                       hue=\"BotWithRank\", hue_order=bot_order)\n",
    "    \"\"\"\n",
    "    # Default plot settings\n",
    "    plot_kwargs = {'linewidth': 2, 'markersize': 8}\n",
    "    plot_kwargs.update(kwargs)\n",
    "\n",
    "    # Determine which bots to plot\n",
    "    bots_to_plot = hue_order if hue_order else data[hue].unique()\n",
    "\n",
    "    for bot_label in bots_to_plot:\n",
    "        bot_data = data[data[hue] == bot_label]\n",
    "        if bot_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Extract original bot name (before \" (#rank)\" if present)\n",
    "        bot_name = bot_label.split(\" (\")[0] if \" (\" in str(bot_label) else str(bot_label)\n",
    "        marker = get_bot_marker(bot_name)\n",
    "\n",
    "        ax.plot(bot_data[x], bot_data[y], marker=marker, label=bot_label, **plot_kwargs)\n",
    "\n",
    "def update_bot_marker_map(new_mappings):\n",
    "    \"\"\"\n",
    "    Update the bot marker map with new mappings.\n",
    "\n",
    "    Args:\n",
    "        new_mappings: Dictionary of {bot_name: marker_shape}\n",
    "\n",
    "    Example:\n",
    "        >>> update_bot_marker_map({\"Bot_NewBot\": \"H\"})\n",
    "    \"\"\"\n",
    "    BOT_MARKER_MAP.update(new_mappings)\n",
    "\n",
    "\n",
    "def get_bot_winrates(summary: pd.DataFrame, bot_name: str):\n",
    "    \"\"\"Return aggregated winrates for one bot against all others.\"\"\"\n",
    "    left = (\n",
    "        summary[summary[\"Bot_L\"] == bot_name]\n",
    "        .groupby(\"Bot_R\")[\"WinRate_L\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Bot_R\": \"Enemy\", \"WinRate_L\": \"WinRate\"})\n",
    "    )\n",
    "\n",
    "    right = (\n",
    "        summary[summary[\"Bot_R\"] == bot_name]\n",
    "        .groupby(\"Bot_L\")[\"WinRate_R\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Bot_L\": \"Enemy\", \"WinRate_R\": \"WinRate\"})\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([left, right])\n",
    "    final = combined.groupby(\"Enemy\")[\"WinRate\"].mean().reset_index()\n",
    "\n",
    "    return final.sort_values(\"WinRate\", ascending=False)\n",
    "\n",
    "def build_winrate_matrix(summary: pd.DataFrame):\n",
    "    \"\"\"Return pivot matrix of win rates (row = bot, col = enemy).\"\"\"\n",
    "    # Combine both directions\n",
    "    left = summary[[\"Bot_L\", \"Bot_R\", \"WinRate_L\",\"Rank_L\"]].rename(\n",
    "        columns={\"Bot_L\": \"Left_Side\", \"Bot_R\": \"Right_Side\", \"WinRate_L\": \"WinRate\",\"Rank_L\":\"Rank\"}\n",
    "    )\n",
    "    right = summary[[\"Bot_R\", \"Bot_L\", \"WinRate_R\",\"Rank_R\"]].rename(\n",
    "        columns={\"Bot_R\": \"Left_Side\", \"Bot_L\": \"Right_Side\", \"WinRate_R\": \"WinRate\",\"Rank_L\":\"Rank\"}\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([left, right], ignore_index=True)\n",
    "\n",
    "    # --- Get bot rank mapping ---\n",
    "    rank_map = (\n",
    "        combined.groupby(\"Left_Side\")[\"Rank\"]\n",
    "        .mean()\n",
    "        .sort_values()\n",
    "        .round(0)\n",
    "        .astype(int)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # --- Rename bot labels with rank ---\n",
    "    combined[\"BotWithRankLeft\"] = combined[\"Left_Side\"].map(\n",
    "        lambda b: f\"{b} (#{rank_map.get(b, '?')})\"\n",
    "    )\n",
    "    combined[\"BotWithRankRight\"] = combined[\"Right_Side\"].map(\n",
    "        lambda b: f\"{b} (#{rank_map.get(b, '?')})\"\n",
    "    )\n",
    "\n",
    "    # Aggregate mean winrate over all configs\n",
    "    matrix_df = combined.groupby([\"BotWithRankLeft\", \"BotWithRankRight\"])[\"WinRate\"].mean().reset_index()\n",
    "\n",
    "    # Pivot into matrix\n",
    "    pivot = matrix_df.pivot(index=\"BotWithRankLeft\", columns=\"BotWithRankRight\", values=\"WinRate\")\n",
    "\n",
    "    # Fill missing (never faced) with NaN\n",
    "    return pivot\n",
    "\n",
    "def plot_winrate_matrix(summary, width=8, height=6):\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    pivot = build_winrate_matrix(summary)\n",
    "    sns.heatmap(\n",
    "        pivot, annot=True, cmap=\"Blues\", center=0.5,\n",
    "        fmt=\".2f\", linewidths=0.5, cbar_kws={'label': 'Win Rate'}\n",
    "    )\n",
    "    plt.title(f\"{get_metric_name('Bot')} vs {get_metric_name('Bot')} {get_metric_name('WinRate')} Matrix\")\n",
    "    plt.ylabel(get_metric_name(\"Bot\"))\n",
    "    plt.xlabel(f\"{get_metric_name('Enemy')} {get_metric_name('Bot')}\")\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_time_related(summary, width=8, height=6):\n",
    "    figs = []\n",
    "    # group by ActInterval, Timer, and Bot_L to average duration per bot per timer\n",
    "    grouped = (\n",
    "        summary.groupby([\"ActInterval\", \"Timer\", \"Bot_L\",\"Rank_L\"], as_index=False)\n",
    "        .agg({\"MatchDur\": \"mean\"})\n",
    "    )\n",
    "    grouped[\"AvgDuration\"] = grouped[\"MatchDur\"]\n",
    "\n",
    "    rank_map = (\n",
    "        grouped.groupby(\"Bot_L\")[\"Rank_L\"]\n",
    "        .mean()\n",
    "        .sort_values()\n",
    "        .round(0)\n",
    "        .astype(int)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # --- Rename bot labels with rank ---\n",
    "    grouped[\"BotWithRank\"] = grouped[\"Bot_L\"].map(\n",
    "        lambda b: f\"{b} (#{rank_map.get(b, '?')})\"\n",
    "    )\n",
    "\n",
    "    # Sort bots by rank\n",
    "    bot_order = sorted(rank_map.keys(), key=lambda b: rank_map.get(b, 999))\n",
    "    bot_order_with_rank = [f\"{b} (#{int(rank_map[b])})\" for b in bot_order]\n",
    "\n",
    "    for interval in grouped[\"ActInterval\"].unique():\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        subset = grouped[grouped[\"ActInterval\"] == interval]\n",
    "\n",
    "        # Plot bots in rank order\n",
    "        for bot in bot_order:\n",
    "            bot_data = subset[subset[\"Bot_L\"] == bot]\n",
    "            if bot_data.empty:\n",
    "                continue\n",
    "            label = bot_data[\"BotWithRank\"].iloc[0]\n",
    "            marker = get_bot_marker(bot)\n",
    "            ax.plot(bot_data[\"Timer\"], bot_data[\"AvgDuration\"], marker=marker, label=label,\n",
    "                   markersize=8, linewidth=2)\n",
    "\n",
    "        ax.set_title(f\"Avg {get_metric_name('MatchDur')} vs {get_metric_name('Timer')} ({get_metric_name('ActInterval')} = {interval})\")\n",
    "        ax.set_xlabel(f\"{get_metric_name('Timer')} (s)\")\n",
    "        ax.set_ylabel(f\"Actual {get_metric_name('MatchDur')} (s)\")\n",
    "\n",
    "        # Calculate dynamic padding for legend\n",
    "        legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "        ax.legend(title='Bot (Rank)', loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=3,\n",
    "                 framealpha=0.9, markerscale=1.2)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "        unique_timers = sorted(subset[\"Timer\"].unique())\n",
    "        ax.set_xticks(unique_timers)\n",
    "        ax.set_xticklabels([f\"{t}s\" for t in unique_timers])\n",
    "\n",
    "        figs.append(fig)\n",
    "    return figs\n",
    "\n",
    "def plot_action_win_related(summary, width=8, height=6):\n",
    "    # Step 1: Compute average actions per game (as before)\n",
    "    summary[\"AvgActions_L\"] = summary[\"ActionCounts_L\"] / summary[\"Games\"]\n",
    "    summary[\"AvgActions_R\"] = summary[\"ActionCounts_R\"] / summary[\"Games\"]\n",
    "\n",
    "    # Step 2: Convert each matchup into per-bot rows\n",
    "    left = summary[[\"Bot_L\", \"Bot_R\", \"AvgActions_L\", \"WinRate_L\"]].rename(\n",
    "        columns={\"Bot_L\": \"Bot\", \"Bot_R\": \"Enemy\", \"AvgActions_L\": \"Actions\", \"WinRate_L\": \"WinRate\"}\n",
    "    )\n",
    "    right = summary[[\"Bot_R\", \"Bot_L\", \"AvgActions_R\", \"WinRate_R\"]].rename(\n",
    "        columns={\"Bot_R\": \"Bot\", \"Bot_L\": \"Enemy\", \"AvgActions_R\": \"Actions\", \"WinRate_R\": \"WinRate\"}\n",
    "    )\n",
    "    combined = pd.concat([left, right], ignore_index=True)\n",
    "\n",
    "    corr = combined[\"Actions\"].corr(combined[\"WinRate\"])\n",
    "    print(f\"Correlation between Actions and Win Rate: {corr:.3f}\")\n",
    "\n",
    "    fig = plt.figure(figsize=(width,height))\n",
    "    sns.regplot(data=combined, x=\"Actions\", y=\"WinRate\", scatter_kws={\"alpha\":0.6})\n",
    "    plt.title(f\"Correlation Between {get_metric_name('Actions')} and {get_metric_name('WinRate')}\")\n",
    "    plt.xlabel(f\"Average {get_metric_name('Actions')} per Game\")\n",
    "    plt.ylabel(get_metric_name(\"WinRate\"))\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.text(\n",
    "        0.6, 0.85,\n",
    "        f\"Correlation result: {corr}.\\n\"\n",
    "        \"> 0.5 â†’ strong positive relationship (more actions â†’ more wins)\\n~0.0 â†’ no clear relation\\n< -0.5 â†’ inverse relationship (passive bots win more)\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=6,\n",
    "        bbox=dict(facecolor='lightyellow', alpha=0.5, edgecolor='gold', boxstyle=\"round,pad=0.4\")\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_highest_action(summary, width=8, height=6, n_action = 6):\n",
    "    action_cols = [col for col in summary.columns if col.endswith(\"_Act_L\")]\n",
    "\n",
    "    # Get rank mapping if available\n",
    "    if \"Rank_L\" in summary.columns:\n",
    "        rank_map = summary.groupby(\"Bot_L\")[\"Rank_L\"].first().to_dict()\n",
    "        bot_order = sorted(rank_map.keys(), key=lambda b: rank_map[b])\n",
    "    else:\n",
    "        rank_map = {}\n",
    "        bot_order = sorted(summary[\"Bot_L\"].unique())\n",
    "\n",
    "    df_actions = summary.melt(\n",
    "        id_vars=[\"Bot_L\"],\n",
    "        value_vars=action_cols,\n",
    "        var_name=\"Action\",\n",
    "        value_name=\"Count\"\n",
    "    )\n",
    "    df_actions[\"Action\"] = df_actions[\"Action\"].str.replace(\"_Act_L\", \"\")\n",
    "    df_actions = df_actions.groupby([\"Bot_L\", \"Action\"])[\"Count\"].sum().reset_index()\n",
    "\n",
    "    # Add rank to bot names if available\n",
    "    if rank_map:\n",
    "        df_actions[\"BotWithRank\"] = df_actions[\"Bot_L\"].map(lambda b: f\"{b} (#{int(rank_map.get(b, 999))})\")\n",
    "        bot_order_with_rank = [f\"{b} (#{int(rank_map[b])})\" for b in bot_order]\n",
    "        hue_col = \"BotWithRank\"\n",
    "        hue_order = bot_order_with_rank\n",
    "    else:\n",
    "        hue_col = \"Bot_L\"\n",
    "        hue_order = bot_order\n",
    "\n",
    "    top_actions = df_actions.groupby(\"Bot_L\").apply(lambda x: x.nlargest(n_action, \"Count\")).reset_index(drop=True)\n",
    "\n",
    "    # Re-add BotWithRank for top_actions\n",
    "    if rank_map:\n",
    "        top_actions[\"BotWithRank\"] = top_actions[\"Bot_L\"].map(lambda b: f\"{b} (#{int(rank_map.get(b, 999))})\")\n",
    "\n",
    "    fig = plt.figure(figsize=(width,height))\n",
    "    sns.barplot(\n",
    "        data=top_actions,\n",
    "        x=\"Count\",\n",
    "        y=\"Action\",\n",
    "        hue=hue_col,\n",
    "        hue_order=hue_order\n",
    "    )\n",
    "    plt.title(\"Top 3 Actions Taken per Bot\")\n",
    "    plt.xlabel(\"Action Count\")\n",
    "    plt.ylabel(\"Action\")\n",
    "    legend_title = \"Bot (Rank)\" if rank_map else \"Bot\"\n",
    "    plt.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_win_rate_stability_over_timer(summary, width=8, height=6):\n",
    "    # Melt the WinRate columns so both sides are in one column\n",
    "    df_melted = summary.melt(\n",
    "        id_vars=[\"Bot_L\", \"Bot_R\", \"Timer\"],\n",
    "        value_vars=[\"WinRate_L\", \"WinRate_R\"],\n",
    "        var_name=\"Side\",\n",
    "        value_name=\"WinRate\"\n",
    "    )\n",
    "\n",
    "    # Extract bot name depending on side\n",
    "    df_melted[\"Bot\"] = df_melted.apply(\n",
    "        lambda r: r[\"Bot_L\"] if r[\"Side\"] == \"WinRate_L\" else r[\"Bot_R\"],\n",
    "        axis=1\n",
    "    )\n",
    "    avg = df_melted.groupby([\"Bot\", \"Timer\"])[\"WinRate\"].mean().reset_index()\n",
    "\n",
    "    # Plot\n",
    "    heat = avg.pivot(index=\"Bot\", columns=\"Timer\", values=\"WinRate\")\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    sns.heatmap(heat, annot=True, cmap=\"RdYlGn\", vmin=0, vmax=1)\n",
    "    plt.title(\"Win Rate Stability vs Timer (Heatmap)\")\n",
    "    plt.xlabel(\"Timer\")\n",
    "    plt.ylabel(\"Bot\")\n",
    "    return fig\n",
    "\n",
    "def plot_timebins_intensity(\n",
    "    df,\n",
    "    group_by=\"Bot\",\n",
    "    timer=None,\n",
    "    act_interval=None,\n",
    "    round=None,\n",
    "    mode=\"total\",        # \"total\" | \"per_action\" | \"select\"\n",
    "    action_name=None,    # used when mode == \"select\"\n",
    "    width=10,\n",
    "    height=6,\n",
    "    summary_df=None,     # Optional: summary dataframe with Rank_L column for bot ranking\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot action intensity over time (with optional timer cutoff).\n",
    "    Modes:\n",
    "      - \"total\": sum MeanCount across all actions -> one line per bot\n",
    "      - \"per_action\": show per-action trends; creates one subplot per action\n",
    "      - \"select\": plot a single action_name for all bots\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Filters ---\n",
    "    if timer is not None:\n",
    "        df = df[df[\"Timer\"] == timer]\n",
    "    if act_interval is not None:\n",
    "        df = df[df[\"ActInterval\"] == act_interval]\n",
    "    if round is not None:\n",
    "        df = df[df[\"Round\"] == round]\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ No data after filtering.\")\n",
    "        return None\n",
    "\n",
    "    # --- Preprocess TimeBin ---\n",
    "    df = df.copy()\n",
    "    df[\"TimeBin\"] = pd.to_numeric(df[\"TimeBin\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"TimeBin\"])\n",
    "    df = df.sort_values(\"TimeBin\")\n",
    "\n",
    "    # --- Add rank to bot names if group_by is \"Bot\" ---\n",
    "    rank_map = None\n",
    "    if group_by == \"Bot\":\n",
    "        # Try to get rank from summary_df first, then from df itself\n",
    "        if summary_df is not None and \"Rank_L\" in summary_df.columns:\n",
    "            rank_map = summary_df.groupby(\"Bot_L\")[\"Rank_L\"].first().to_dict()\n",
    "        elif \"Rank\" in df.columns:\n",
    "            rank_map = df.groupby(\"Bot\")[\"Rank\"].first().to_dict()\n",
    "        elif \"Rank_L\" in df.columns:\n",
    "            rank_map = df.groupby(\"Bot\")[\"Rank_L\"].first().to_dict()\n",
    "\n",
    "    if rank_map:\n",
    "        df[\"BotWithRank\"] = df[\"Bot\"].map(lambda b: f\"{b} (#{int(rank_map.get(b, 999))})\")\n",
    "        group_by_plot = \"BotWithRank\"\n",
    "        # Sort bots by rank\n",
    "        bot_order = sorted(rank_map.keys(), key=lambda b: rank_map.get(b, 999))\n",
    "        bot_order_with_rank = [f\"{b} (#{int(rank_map[b])})\" for b in bot_order]\n",
    "    else:\n",
    "        group_by_plot = group_by\n",
    "        bot_order_with_rank = None\n",
    "\n",
    "    # --- Helper: apply x-axis cutoff ---\n",
    "    def apply_timer_xlim(ax):\n",
    "        if timer is not None:\n",
    "            ax.set_xlim(0, timer)\n",
    "            ax.set_xticks(range(0, int(timer) + 1, max(1, int(timer // 10) or 1)))\n",
    "\n",
    "    # --- Plot modes ---\n",
    "    if mode == \"select\":\n",
    "        if not action_name:\n",
    "            raise ValueError(\"action_name must be provided when mode='select'\")\n",
    "        df_sel = df[df[\"Action\"] == action_name]\n",
    "        if df_sel.empty:\n",
    "            print(f\"âš ï¸ No rows for action '{action_name}' after filtering.\")\n",
    "            return None\n",
    "        grouped = df_sel.groupby([group_by_plot, \"TimeBin\"], as_index=False)[\"MeanCount\"].mean()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        plot_with_bot_markers(ax, data=grouped, x=\"TimeBin\", y=\"MeanCount\",\n",
    "                            hue=group_by_plot, hue_order=bot_order_with_rank)\n",
    "        ax.set_title(f\"Mean {get_metric_name(action_name)} over time\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Mean Count\")\n",
    "        legend_title = \"Bot (Rank)\" if (group_by == \"Bot\" and rank_map is not None) else group_by\n",
    "\n",
    "        # Calculate dynamic padding for legend\n",
    "        legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "        ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=3,\n",
    "                 framealpha=0.9, markerscale=1.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        apply_timer_xlim(ax)\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    elif mode == \"total\":\n",
    "        grouped = df.groupby([group_by_plot, \"TimeBin\"], as_index=False)[\"MeanCount\"].mean()\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        plot_with_bot_markers(ax, data=grouped, x=\"TimeBin\", y=\"MeanCount\",\n",
    "                            hue=group_by_plot, hue_order=bot_order_with_rank)\n",
    "        ax.set_title(\"Total action intensity over time\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Mean Count (summed over actions)\")\n",
    "        legend_title = \"Bot (Rank)\" if (group_by == \"Bot\" and rank_map is not None) else group_by\n",
    "\n",
    "        # Calculate dynamic padding for legend\n",
    "        legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "        ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=3,\n",
    "                 framealpha=0.9, markerscale=1.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        apply_timer_xlim(ax)\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    elif mode == \"per_action\":\n",
    "        actions = sorted(df[\"Action\"].unique())\n",
    "        n = len(actions)\n",
    "        ncols = min(2, n)\n",
    "        nrows = (n + ncols - 1) // ncols\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=nrows,\n",
    "            ncols=ncols,\n",
    "            figsize=(width, max(height, 2.5 * nrows)),\n",
    "            squeeze=False\n",
    "        )\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        handles, labels = None, None\n",
    "        for i, action in enumerate(actions):\n",
    "            ax = axes[i]\n",
    "            sub = df[df[\"Action\"] == action].groupby([group_by_plot, \"TimeBin\"], as_index=False)[\"MeanCount\"].mean()\n",
    "            if sub.empty:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "            plot_with_bot_markers(ax, data=sub, x=\"TimeBin\", y=\"MeanCount\",\n",
    "                                hue=group_by_plot, hue_order=bot_order_with_rank)\n",
    "\n",
    "            # Capture legend handles from first plot\n",
    "            if i == 0:\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "                legend = ax.get_legend()\n",
    "                if legend is not None:\n",
    "                    legend.remove()\n",
    "\n",
    "            ax.set_title(get_metric_name(action))\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "            ax.set_ylabel(\"Mean Count\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            apply_timer_xlim(ax)\n",
    "\n",
    "        # Hide unused axes\n",
    "        for j in range(len(actions), len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "\n",
    "        # Add global legend below\n",
    "        if handles and labels:\n",
    "            legend_title = \"Bot (Rank)\" if (group_by == \"Bot\" and rank_map is not None) else group_by\n",
    "            fig.legend(\n",
    "                handles, labels, title=legend_title,\n",
    "                loc=\"upper center\", bbox_to_anchor=(0.5, -0.02),\n",
    "                ncol=min(6, len(labels))\n",
    "            )\n",
    "        fig.suptitle(\"Per-action intensity over timer\")\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be one of ['total','per_action','select']\")\n",
    "\n",
    "\n",
    "def plot_full_cross_heatmap_half(df, bot_name=\"Bot_NN\", key=\"WinRate_L\", max_labels=40, lower_triangle=True):\n",
    "    cfg_cols = [\"Timer\", \"ActInterval\", \"Round\", \"SkillLeft\", \"SkillRight\"]\n",
    "    df_bot = df[df[\"Bot_L\"] == bot_name].copy()\n",
    "    \n",
    "    # Melt configurations\n",
    "    melted = df_bot.melt(\n",
    "        id_vars=[key],\n",
    "        value_vars=cfg_cols,\n",
    "        var_name=\"ConfigType\",\n",
    "        value_name=\"ConfigValue\"\n",
    "    )\n",
    "\n",
    "    # Cartesian join (self merge)\n",
    "    merged = melted.merge(melted, on=key, suffixes=(\"_X\", \"_Y\"))\n",
    "    merged = merged[merged[\"ConfigType_X\"] != merged[\"ConfigType_Y\"]]\n",
    "\n",
    "    # Aggregate mean WinRate\n",
    "    grouped = (\n",
    "        merged.groupby([\"ConfigType_X\", \"ConfigValue_X\", \"ConfigType_Y\", \"ConfigValue_Y\"])[key]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Label for axes\n",
    "    grouped[\"X\"] = grouped[\"ConfigType_X\"] + \"=\" + grouped[\"ConfigValue_X\"].astype(str)\n",
    "    grouped[\"Y\"] = grouped[\"ConfigType_Y\"] + \"=\" + grouped[\"ConfigValue_Y\"].astype(str)\n",
    "\n",
    "    # Pivot into matrix\n",
    "    pivot = grouped.pivot(index=\"Y\", columns=\"X\", values=key)\n",
    "\n",
    "    # Drop all-NaN rows and columns\n",
    "\n",
    "    # Clip to manageable size\n",
    "    if len(pivot) > max_labels or len(pivot.columns) > max_labels:\n",
    "        pivot = pivot.iloc[:max_labels, :max_labels]\n",
    "\n",
    "    # Ensure symmetry (optional, if slightly different values occur)\n",
    "    pivot = (pivot + pivot.T) / 2\n",
    "\n",
    "    pivot = pivot.dropna(axis=0, how=\"all\")\n",
    "    pivot = pivot.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # Build triangular mask\n",
    "    # mask = np.triu(np.ones_like(pivot, dtype=bool)) if lower_triangle else np.tril(np.ones_like(pivot, dtype=bool))\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(max(10, len(pivot.columns)*0.4), max(8, len(pivot)*0.3)))\n",
    "    sns.heatmap(\n",
    "        pivot,\n",
    "        cmap=\"Blues\",\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        # mask=mask,            # âœ… Hide upper (or lower) triangle\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={'label': 'Win Rate'},\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Cross Configuration Win Rate (Half Matrix) for {bot_name}\", fontsize=14, pad=12)\n",
    "    ax.set_xlabel(\"Config X\", fontsize=12)\n",
    "    ax.set_ylabel(\"Config Y\", fontsize=12)\n",
    "    ax.tick_params(axis=\"x\", rotation=45, labelsize=9)\n",
    "    ax.tick_params(axis=\"y\", labelsize=9)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_grouped_config_winrates(\n",
    "    df: pd.DataFrame,\n",
    "    bot_col: str = \"Bot_L\",\n",
    "    metric: str = \"WinRate_L\",\n",
    "    config_col: str = \"Timer\",\n",
    "    width: int = 10,\n",
    "    height: int = 9,\n",
    "    title: str = None,\n",
    "    ylabel: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a grouped bar chart showing win-rates (or other metrics) grouped by a single configuration parameter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Summary dataframe (e.g., matchup_summary)\n",
    "    bot_col : str\n",
    "        Column name for bots (default: \"Bot_L\")\n",
    "    metric : str\n",
    "        Metric to plot (default: \"WinRate_L\")\n",
    "    config_col : str\n",
    "        Configuration column to group by (default: \"Timer\")\n",
    "        Special case: \"Skill\" will use both SkillLeft and SkillRight\n",
    "    width : int\n",
    "        Figure width\n",
    "    height : int\n",
    "        Figure height\n",
    "    title : str\n",
    "        Plot title (optional)\n",
    "    ylabel : str\n",
    "        Y-axis label (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique bots and sort by rank\n",
    "    rank_col = \"Rank_L\" if bot_col == \"Bot_L\" else \"Rank_R\"\n",
    "    if rank_col in df.columns:\n",
    "        rank_map = df.groupby(bot_col)[rank_col].first().to_dict()\n",
    "        bots = sorted(df[bot_col].unique(), key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bots = sorted(df[bot_col].unique())\n",
    "        rank_map = {}\n",
    "\n",
    "    # Determine if we need to calculate per-game averages\n",
    "    per_game_metrics = [\"Collisions\", \"ActionCounts\", \"Duration\", \"MatchDur\"]\n",
    "    needs_per_game = any(m in metric for m in per_game_metrics)\n",
    "\n",
    "    # Special handling for \"Skill\" - use both SkillLeft and SkillRight\n",
    "    if config_col == \"Skill\":\n",
    "        # Merge left and right data\n",
    "        if needs_per_game:\n",
    "            # Include Games column for per-game calculation\n",
    "            left_data = df[[bot_col, \"SkillLeft\", metric, \"Games\"]].copy()\n",
    "            left_data = left_data.rename(columns={\"SkillLeft\": \"SkillType\"})\n",
    "\n",
    "            right_data = df[[bot_col.replace(\"_L\", \"_R\"), \"SkillRight\", metric.replace(\"_L\", \"_R\"), \"Games\"]].copy()\n",
    "            right_data = right_data.rename(columns={\n",
    "                bot_col.replace(\"_L\", \"_R\"): bot_col,\n",
    "                \"SkillRight\": \"SkillType\",\n",
    "                metric.replace(\"_L\", \"_R\"): metric\n",
    "            })\n",
    "\n",
    "            combined = pd.concat([left_data, right_data], ignore_index=True)\n",
    "            # Calculate per-game average first\n",
    "            combined['metric_per_game'] = combined[metric] / combined['Games']\n",
    "            grouped = combined.groupby([bot_col, \"SkillType\"])['metric_per_game'].agg(['mean', 'std']).reset_index()\n",
    "        else:\n",
    "            left_data = df[[bot_col, \"SkillLeft\", metric]].copy()\n",
    "            left_data = left_data.rename(columns={\"SkillLeft\": \"SkillType\"})\n",
    "\n",
    "            right_data = df[[bot_col.replace(\"_L\", \"_R\"), \"SkillRight\", metric.replace(\"_L\", \"_R\")]].copy()\n",
    "            right_data = right_data.rename(columns={\n",
    "                bot_col.replace(\"_L\", \"_R\"): bot_col,\n",
    "                \"SkillRight\": \"SkillType\",\n",
    "                metric.replace(\"_L\", \"_R\"): metric\n",
    "            })\n",
    "\n",
    "            combined = pd.concat([left_data, right_data], ignore_index=True)\n",
    "            grouped = combined.groupby([bot_col, \"SkillType\"])[metric].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        config_values = sorted(grouped[\"SkillType\"].unique())\n",
    "        config_col_display = \"SkillType\"\n",
    "    else:\n",
    "        # Normal handling for other config columns\n",
    "        config_values = sorted(df[config_col].unique())\n",
    "\n",
    "        if needs_per_game:\n",
    "            # Calculate per-game average first\n",
    "            df_copy = df.copy()\n",
    "            df_copy['metric_per_game'] = df_copy[metric] / df_copy['Games']\n",
    "            grouped = df_copy.groupby([bot_col, config_col])['metric_per_game'].agg(['mean', 'std']).reset_index()\n",
    "        else:\n",
    "            grouped = df.groupby([bot_col, config_col])[metric].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "        config_col_display = config_col\n",
    "\n",
    "    # Create the grouped bar chart\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "    # Define colors for each config value\n",
    "    colors = ['#d62728', '#ff7f0e', '#2ca02c', '#17becf', '#9467bd', '#8c564b']\n",
    "    config_colors = {val: colors[i % len(colors)] for i, val in enumerate(config_values)}\n",
    "\n",
    "    # Set up bar positions\n",
    "    n_bots = len(bots)\n",
    "    n_configs = len(config_values)\n",
    "    bar_width = 0.8 / n_configs\n",
    "    x_positions = np.arange(n_bots)\n",
    "\n",
    "    # Plot bars for each config value\n",
    "    for i, config_val in enumerate(config_values):\n",
    "        if config_col == \"Skill\":\n",
    "            config_data = grouped[grouped[\"SkillType\"] == config_val]\n",
    "        else:\n",
    "            config_data = grouped[grouped[config_col] == config_val]\n",
    "\n",
    "        means = []\n",
    "        # stds = []\n",
    "\n",
    "        for bot in bots:\n",
    "            bot_data = config_data[config_data[bot_col] == bot]\n",
    "            if not bot_data.empty:\n",
    "                means.append(bot_data['mean'].values[0])\n",
    "                # std_val = bot_data['std'].values[0]\n",
    "                # stds.append(std_val if not pd.isna(std_val) else 0)\n",
    "            else:\n",
    "                means.append(0)\n",
    "                # stds.append(0)\n",
    "\n",
    "        offset = (i - n_configs/2 + 0.5) * bar_width\n",
    "        bars = ax.bar(x_positions + offset, means, bar_width,\n",
    "               label=str(config_val), color=config_colors[config_val],)\n",
    "            #    yerr=stds, capsize=3, error_kw={'linewidth': 1.5, 'elinewidth': 1})\n",
    "\n",
    "        # Add value labels inside bars\n",
    "        for bar, mean_val in zip(bars, means):\n",
    "            height = bar.get_height()\n",
    "            if height > 0:  # Only add label if bar has height\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                        f'{mean_val:.1f}',\n",
    "                        ha='center', va='center', fontsize=7, fontweight='bold', color='white')\n",
    "\n",
    "        \n",
    "    # Customize plot\n",
    "    ax.set_xlabel(get_metric_name('Bot'), fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel if ylabel else get_metric_name(metric.replace('_L', '')), fontsize=12, fontweight='bold')\n",
    "\n",
    "    if title:\n",
    "        plot_title = title\n",
    "    else:\n",
    "        display_name = get_metric_name(\"Skill\") if config_col == \"Skill\" else get_metric_name(config_col)\n",
    "        plot_title = f'{get_metric_name(metric.replace(\"_L\", \"\"))} grouped by {display_name}'\n",
    "\n",
    "    ax.set_title(plot_title, fontsize=14, fontweight='bold', pad=15)\n",
    "    ax.set_xticks(x_positions)\n",
    "    # Create bot labels with rank\n",
    "    if rank_map:\n",
    "        bot_labels = [f\"{bot} (#{int(rank_map[bot])})\" for bot in bots]\n",
    "    else:\n",
    "        bot_labels = bots\n",
    "    ax.set_xticklabels(bot_labels, rotation=30, ha='right')\n",
    "\n",
    "    # Calculate dynamic padding for legend\n",
    "    legend_padding = calculate_legend_padding(ax, x_labels=bot_labels, rotation=30)\n",
    "    ax.legend(title=config_col_display, loc='upper center', bbox_to_anchor=(0.5, legend_padding),\n",
    "              ncol=min(6, n_configs), fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_overall_bot_metrics(\n",
    "    df: pd.DataFrame,\n",
    "    bot_col: str = \"Bot_L\",\n",
    "    metric: str = \"Collisions_L\",\n",
    "    width: int = 10,\n",
    "    height: int = 6,\n",
    "    title: str = None,\n",
    "    ylabel: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a simple bar chart showing mean metric values per bot across all configurations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Summary dataframe (e.g., matchup_summary)\n",
    "    bot_col : str\n",
    "        Column name for bots (default: \"Bot_L\")\n",
    "    metric : str\n",
    "        Metric to plot. Options:\n",
    "        - \"Collisions_L\" or \"Collisions_R\": Total collisions\n",
    "        - \"ActionCounts_L\" or \"ActionCounts_R\": Total action counts\n",
    "        - \"Duration_L\" or \"Duration_R\": Action duration\n",
    "        - \"MatchDur\": Match duration\n",
    "        - \"Games\": Total games\n",
    "    width : int\n",
    "        Figure width\n",
    "    height : int\n",
    "        Figure height\n",
    "    title : str\n",
    "        Plot title (optional)\n",
    "    ylabel : str\n",
    "        Y-axis label (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> plot_overall_bot_metrics(df, metric=\"Collisions_L\", title=\"Mean Collisions per Bot\")\n",
    "    >>> plot_overall_bot_metrics(df, metric=\"ActionCounts_L\", title=\"Mean Actions per Bot\")\n",
    "    >>> plot_overall_bot_metrics(df, metric=\"MatchDur\", title=\"Mean Match Duration per Bot\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique bots and sort by rank\n",
    "    rank_col = \"Rank_L\" if bot_col == \"Bot_L\" else \"Rank_R\"\n",
    "    if rank_col in df.columns:\n",
    "        rank_map = df.groupby(bot_col)[rank_col].first().to_dict()\n",
    "        bots = sorted(df[bot_col].unique(), key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bots = sorted(df[bot_col].unique())\n",
    "        rank_map = {}\n",
    "\n",
    "    # Determine if we need to calculate per-game averages\n",
    "    per_game_metrics = [\"Collisions\", \"ActionCounts\", \"Duration\", \"MatchDur\"]\n",
    "    needs_per_game = any(m in metric for m in per_game_metrics)\n",
    "\n",
    "    if needs_per_game:\n",
    "        # Calculate per-game average\n",
    "        df_copy = df.copy()\n",
    "        df_copy['metric_per_game'] = df_copy[metric] / df_copy['Games']\n",
    "        grouped = df_copy.groupby(bot_col)['metric_per_game'].mean().reset_index()\n",
    "        grouped.columns = [bot_col, 'mean_value']\n",
    "    else:\n",
    "        # Direct mean for metrics like winrate\n",
    "        grouped = df.groupby(bot_col)[metric].mean().reset_index()\n",
    "        grouped.columns = [bot_col, 'mean_value']\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    means = []\n",
    "    for bot in bots:\n",
    "        bot_data = grouped[grouped[bot_col] == bot]\n",
    "        if not bot_data.empty:\n",
    "            means.append(bot_data['mean_value'].values[0])\n",
    "        else:\n",
    "            means.append(0)\n",
    "\n",
    "    # Plot bars\n",
    "    x_positions = np.arange(len(bots))\n",
    "    bars = ax.bar(x_positions, means, width=0.6, color='#2ca02c', alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "    # Add value labels inside bars\n",
    "    for bar, mean_val in zip(bars, means):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                f'{mean_val:.1f}',\n",
    "                ha='center', va='center', fontsize=9, fontweight='bold', color='white')\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xlabel(get_metric_name('Bot'), fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel if ylabel else get_metric_name(metric.replace('_L', '')), fontsize=12, fontweight='bold')\n",
    "\n",
    "    if title:\n",
    "        plot_title = title\n",
    "    else:\n",
    "        plot_title = f'Mean {get_metric_name(metric.replace(\"_L\", \"\"))} per {get_metric_name(\"Bot\")} (across all configurations)'\n",
    "\n",
    "    ax.set_title(plot_title, fontsize=14, fontweight='bold', pad=15)\n",
    "    ax.set_xticks(x_positions)\n",
    "\n",
    "    # Create bot labels with rank\n",
    "    if rank_map:\n",
    "        bot_labels = [f\"{bot} (#{int(rank_map[bot])})\" for bot in bots]\n",
    "    else:\n",
    "        bot_labels = bots\n",
    "    ax.set_xticklabels(bot_labels, rotation=30, ha='right')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_action_radar(df, bot_col=\"Bot_L\", width=14, height=12, scale=None, radial_limit=\"auto\"):\n",
    "    \"\"\"\n",
    "    Create a radar chart showing mean action counts per bot.\n",
    "\n",
    "    Parameters:\n",
    "        scale (str): Scale for radial axis (None = linear, \"sqrt\", \"log\")\n",
    "        radial_limit (str or float):\n",
    "                    - \"auto\": Set max based on 95th percentile (recommended for better spacing)\n",
    "                    - \"max\": Use the absolute max value\n",
    "                    - float: Manually set the max radial value\n",
    "    \"\"\"\n",
    "    # Get all action columns\n",
    "    action_cols = [col for col in df.columns if col.endswith(\"_Act_L\")]\n",
    "\n",
    "    # Get unique bots and sort by rank\n",
    "    rank_col = \"Rank_L\" if bot_col == \"Bot_L\" else \"Rank_R\"\n",
    "    if rank_col in df.columns:\n",
    "        rank_map = df.groupby(bot_col)[rank_col].first().to_dict()\n",
    "        bots = sorted(df[bot_col].unique(), key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bots = sorted(df[bot_col].unique())\n",
    "        rank_map = {}\n",
    "\n",
    "    # Calculate mean action counts per bot (raw values)\n",
    "    # Merge SkillBoost and SkillStone into single \"Skill\"\n",
    "    bot_data_raw = {}\n",
    "    action_names = []\n",
    "\n",
    "    for bot in bots:\n",
    "        bot_df = df[df[bot_col] == bot]\n",
    "        means = []\n",
    "\n",
    "        # Build action list on first iteration\n",
    "        if not action_names:\n",
    "            for col in action_cols:\n",
    "                name = col.replace(\"_Act_L\", \"\")\n",
    "\n",
    "                # Skip SkillStone (will be merged with SkillBoost)\n",
    "                if name == \"SkillStone\":\n",
    "                    continue\n",
    "\n",
    "                # Rename SkillBoost to Skill\n",
    "                if name == \"SkillBoost\":\n",
    "                    action_names.append(\"Skill\")\n",
    "                else:\n",
    "                    action_names.append(name)\n",
    "\n",
    "        # Calculate means with merged skills\n",
    "        for col in action_cols:\n",
    "            name = col.replace(\"_Act_L\", \"\")\n",
    "\n",
    "            if name == \"SkillStone\":\n",
    "                continue  # Skip, already merged\n",
    "\n",
    "            if name == \"SkillBoost\":\n",
    "                # Merge SkillBoost + SkillStone\n",
    "                skill_boost = bot_df[col].mean()\n",
    "                skill_stone = bot_df.get(\"SkillStone_Act_L\", bot_df[col] * 0).mean()  # Handle if column doesn't exist\n",
    "                means.append(skill_boost + skill_stone)\n",
    "            else:\n",
    "                means.append(bot_df[col].mean())\n",
    "\n",
    "        bot_data_raw[bot] = means\n",
    "\n",
    "    # Transform values based on scale\n",
    "    bot_data = {}\n",
    "    for bot, values in bot_data_raw.items():\n",
    "        if scale == \"sqrt\":\n",
    "            bot_data[bot] = [np.sqrt(v) for v in values]\n",
    "        elif scale == \"log\":\n",
    "            bot_data[bot] = [np.log10(v + 1) for v in values]  # +1 to handle zeros\n",
    "        else:  # linear / None\n",
    "            bot_data[bot] = values\n",
    "\n",
    "    # Set up radar chart\n",
    "    num_vars = len(action_names)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width, height), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "    # Plot each bot\n",
    "    colors = ['#d62728', '#ff7f0e', '#2ca02c', '#17becf', '#9467bd', '#8c564b']\n",
    "    for i, (bot, values) in enumerate(bot_data.items()):\n",
    "        values += values[:1]  # Complete the circle\n",
    "        # Format label with rank if available\n",
    "        if rank_map and bot in rank_map:\n",
    "            label = f\"{bot} (#{int(rank_map[bot])})\"\n",
    "        else:\n",
    "            label = bot\n",
    "        # Use bot-specific marker\n",
    "        marker = get_bot_marker(bot)\n",
    "        ax.plot(angles, values, f'{marker}-', linewidth=2.5, markersize=8,\n",
    "                label=label, color=colors[i % len(colors)])\n",
    "\n",
    "    # Set labels with better styling\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(action_names, fontsize=11)\n",
    "\n",
    "    # Set radial limit for better spacing\n",
    "    all_values = [v for bot_vals in bot_data.values() for v in bot_vals[:-1]]\n",
    "    if radial_limit == \"auto\":\n",
    "        max_val = np.percentile(all_values, 95)  # Use 95th percentile\n",
    "        ax.set_ylim(0, max_val * 1.15)  # Add 15% padding\n",
    "    elif radial_limit == \"max\":\n",
    "        max_val = max(all_values)\n",
    "        ax.set_ylim(0, max_val * 1.1)\n",
    "    elif isinstance(radial_limit, (int, float)):\n",
    "        ax.set_ylim(0, radial_limit)\n",
    "\n",
    "    # Add more radial grid lines for better readability\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "    # Set y-axis label based on scale\n",
    "    if scale == \"sqrt\":\n",
    "        ax.set_ylabel('âˆš(Mean Action Count)', labelpad=35, fontsize=11)\n",
    "    elif scale == \"log\":\n",
    "        ax.set_ylabel('logâ‚â‚€(Mean Action Count + 1)', labelpad=35, fontsize=11)\n",
    "    else:\n",
    "        ax.set_ylabel('Mean Action Count', labelpad=35, fontsize=11)\n",
    "\n",
    "    ax.set_title('Actions Behaviour', size=16, pad=20, fontweight='bold')\n",
    "    legend_title = \"Bot (Rank)\" if rank_map else \"Bot\"\n",
    "    ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, -0.1), fontsize=10, framealpha=0.9, ncol=3)\n",
    "    ax.grid(True, linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_collision_radar(df, bot_col=\"Bot_L\", width=14, height=12, scale=None):\n",
    "    \"\"\"\n",
    "    Create a triangular radar chart showing collision outcomes per bot.\n",
    "    Three axes: hit (wins), tie (draws), being_hit (losses)\n",
    "\n",
    "    Parameters:\n",
    "        scale (str): Scale for radial axis. Options:\n",
    "                    - \"linear\": Raw values\n",
    "                    - \"sqrt\": Square root scale (recommended - shows all values clearly)\n",
    "                    - \"log\": Logarithmic scale (more aggressive compression)\n",
    "    \"\"\"\n",
    "    # Get unique bots and sort by rank\n",
    "    rank_col = \"Rank_L\" if bot_col == \"Bot_L\" else \"Rank_R\"\n",
    "    if rank_col in df.columns:\n",
    "        rank_map = df.groupby(bot_col)[rank_col].first().to_dict()\n",
    "        bots = sorted(df[bot_col].unique(), key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bots = sorted(df[bot_col].unique())\n",
    "        rank_map = {}\n",
    "\n",
    "    # Calculate collision statistics per bot (raw values)\n",
    "    bot_data_raw = {}\n",
    "    for bot in bots:\n",
    "        # Get data for this bot on left side\n",
    "        left_df = df[df[bot_col] == bot]\n",
    "\n",
    "        # Calculate totals (raw counts)\n",
    "        hit = left_df[\"Collisions_L\"].sum()\n",
    "        being_hit = left_df[\"Collisions_R\"].sum()\n",
    "        ties = left_df[\"Collisions_Tie\"].sum()\n",
    "\n",
    "        # Store as a list: [hit, tie, being_hit]\n",
    "        bot_data_raw[bot] = [hit, ties, being_hit]\n",
    "\n",
    "    # Transform values based on scale\n",
    "    bot_data = {}\n",
    "    for bot, values in bot_data_raw.items():\n",
    "        if scale == \"sqrt\":\n",
    "            bot_data[bot] = [np.sqrt(v) for v in values]\n",
    "        elif scale == \"log\":\n",
    "            bot_data[bot] = [np.log10(v + 1) for v in values]  # +1 to handle zeros\n",
    "        else:  # linear\n",
    "            bot_data[bot] = values\n",
    "\n",
    "    # Set up triangular radar chart (3 vertices)\n",
    "    collision_types = ['hit', 'tie', 'struck']\n",
    "    num_vars = len(collision_types)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Complete the circle\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width, height), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "    # Plot each bot\n",
    "    colors = ['#d62728', '#ff7f0e', '#2ca02c', '#17becf', '#9467bd', '#8c564b']\n",
    "    for i, (bot, values) in enumerate(bot_data.items()):\n",
    "        values += values[:1]  # Complete the circle\n",
    "        # Format label with rank if available\n",
    "        if rank_map and bot in rank_map:\n",
    "            label = f\"{bot} (#{int(rank_map[bot])})\"\n",
    "        else:\n",
    "            label = bot\n",
    "        # Use bot-specific marker\n",
    "        marker = get_bot_marker(bot)\n",
    "        ax.plot(angles, values, f'{marker}-', linewidth=2.5, markersize=8,\n",
    "                label=label, color=colors[i % len(colors)])\n",
    "\n",
    "    # Set labels with better styling\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(collision_types, fontsize=11)\n",
    "\n",
    "    # Add more radial grid lines for better readability\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "    # Set y-axis label based on scale\n",
    "    if scale == \"sqrt\":\n",
    "        ax.set_ylabel('âˆš(Collision Count)', labelpad=35, fontsize=11)\n",
    "    elif scale == \"log\":\n",
    "        ax.set_ylabel('logâ‚â‚€(Collision Count + 1)', labelpad=35, fontsize=11)\n",
    "    else:\n",
    "        ax.set_ylabel('Collision Count', labelpad=35, fontsize=11)\n",
    "\n",
    "    ax.set_title('Collision Behaviour', size=16, pad=20, fontweight='bold')\n",
    "    legend_title = \"Bot (Rank)\" if rank_map else \"Bot\"\n",
    "    ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, -0.1), fontsize=10, framealpha=0.9, ncol=3)\n",
    "    ax.grid(True, linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_action_distribution_stacked(df, bot_col=\"Bot_L\", width=10, height=6, normalize=False):\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart showing action type distribution per bot.\n",
    "\n",
    "    Parameters:\n",
    "        df: Summary dataframe with action counts\n",
    "        bot_col: Column name for bots (default: \"Bot_L\")\n",
    "        width: Figure width\n",
    "        height: Figure height\n",
    "        normalize: If True, normalize bars to 100% (show proportions)\n",
    "                   If False, show absolute counts\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure\n",
    "    \"\"\"\n",
    "    # Define action columns (merge SkillBoost and SkillStone into \"Skill\")\n",
    "    action_mapping = {\n",
    "        'Accelerate': 'Accelerate_Act_L',\n",
    "        'TurnLeft': 'TurnLeft_Act_L',\n",
    "        'TurnRight': 'TurnRight_Act_L',\n",
    "        'Dash': 'Dash_Act_L',\n",
    "        'Skill': ['SkillBoost_Act_L', 'SkillStone_Act_L']\n",
    "    }\n",
    "\n",
    "    # Get unique bots and sort by rank\n",
    "    rank_col = \"Rank_L\" if bot_col == \"Bot_L\" else \"Rank_R\"\n",
    "    if rank_col in df.columns:\n",
    "        rank_map = df.groupby(bot_col)[rank_col].first().to_dict()\n",
    "        bots = sorted(df[bot_col].unique(), key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bots = sorted(df[bot_col].unique())\n",
    "        rank_map = {}\n",
    "\n",
    "    # Prepare data for stacking\n",
    "    action_data = {action: [] for action in action_mapping.keys()}\n",
    "\n",
    "    for bot in bots:\n",
    "        bot_df = df[df[bot_col] == bot]\n",
    "\n",
    "        for action_name, col_names in action_mapping.items():\n",
    "            if isinstance(col_names, list):\n",
    "                # Merge multiple columns (for Skill)\n",
    "                total = sum(bot_df[col].sum() for col in col_names if col in bot_df.columns)\n",
    "            else:\n",
    "                # Single column\n",
    "                total = bot_df[col_names].sum() if col_names in bot_df.columns else 0\n",
    "\n",
    "            action_data[action_name].append(total)\n",
    "\n",
    "    # Convert to DataFrame for easier plotting\n",
    "    data_df = pd.DataFrame(action_data, index=bots)\n",
    "\n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        data_df = data_df.div(data_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Create stacked bar chart\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "    # Define colors for each action type\n",
    "    colors = {\n",
    "        'Accelerate': '#d62728',    # Red\n",
    "        'TurnLeft': '#ff7f0e',      # Orange\n",
    "        'TurnRight': '#2ca02c',     # Green\n",
    "        'Dash': '#17becf',          # Cyan\n",
    "        'Skill': '#1f77b4'          # Blue\n",
    "    }\n",
    "\n",
    "    # Create bot labels with rank\n",
    "    if rank_map:\n",
    "        bot_labels = [f\"{bot} (#{int(rank_map[bot])})\" for bot in bots]\n",
    "    else:\n",
    "        bot_labels = bots\n",
    "\n",
    "    # Plot stacked bars\n",
    "    bottom = np.zeros(len(bots))\n",
    "    x_pos = np.arange(len(bots))\n",
    "    for action in action_mapping.keys():\n",
    "        ax.bar(x_pos, data_df[action], bottom=bottom,\n",
    "               label=action, color=colors[action], width=0.6)\n",
    "        bottom += data_df[action]\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(bot_labels)\n",
    "    ax.set_xlabel('Bots', fontsize=12, fontweight='bold')\n",
    "\n",
    "    if normalize:\n",
    "        ax.set_ylabel('Action Distribution (%)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Action Type Distribution per Bot (Normalized)',\n",
    "                     fontsize=14, fontweight='bold', pad=15)\n",
    "        ax.set_ylim(0, 100)\n",
    "    else:\n",
    "        ax.set_ylabel('Total Action Count', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Action Type Distribution per Bot',\n",
    "                     fontsize=14, fontweight='bold', pad=15)\n",
    "        \n",
    "    legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=5,\n",
    "              fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    # Rotate x-axis labels if many bots\n",
    "    if len(bots) > 5:\n",
    "        plt.setp(ax.get_xticklabels(), rotation=30, ha='right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_collision_distribution_stacked(df, bot_col=\"Bot_L\", width=10, height=6, normalize=False):\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart showing collision type distribution per bot.\n",
    "\n",
    "    Parameters:\n",
    "        df: Summary dataframe with collision counts\n",
    "        bot_col: Column name for bots (default: \"Bot_L\")\n",
    "        width: Figure width\n",
    "        height: Figure height\n",
    "        normalize: If True, normalize bars to 100% (show proportions)\n",
    "                   If False, show absolute counts\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure\n",
    "    \"\"\"\n",
    "    # Get unique bots and sort by rank\n",
    "    rank_col = \"Rank_L\" if bot_col == \"Bot_L\" else \"Rank_R\"\n",
    "    if rank_col in df.columns:\n",
    "        rank_map = df.groupby(bot_col)[rank_col].first().to_dict()\n",
    "        bots = sorted(df[bot_col].unique(), key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bots = sorted(df[bot_col].unique())\n",
    "        rank_map = {}\n",
    "\n",
    "    # Prepare data for stacking\n",
    "    collision_data = {\n",
    "        'Hit': [],           # Collisions won (Collisions_L)\n",
    "        'Struck': [],     # Collisions lost (Collisions_R)\n",
    "        'Tie': []            # Tie collisions\n",
    "    }\n",
    "\n",
    "    for bot in bots:\n",
    "        bot_df = df[df[bot_col] == bot]\n",
    "\n",
    "        # Calculate totals\n",
    "        hit = bot_df['Collisions_L'].sum() if 'Collisions_L' in bot_df.columns else 0\n",
    "        being_hit = bot_df['Collisions_R'].sum() if 'Collisions_R' in bot_df.columns else 0\n",
    "        tie = bot_df['Collisions_Tie'].sum() if 'Collisions_Tie' in bot_df.columns else 0\n",
    "\n",
    "        collision_data['Hit'].append(hit)\n",
    "        collision_data['Struck'].append(being_hit)\n",
    "        collision_data['Tie'].append(tie)\n",
    "\n",
    "    # Convert to DataFrame for easier plotting\n",
    "    data_df = pd.DataFrame(collision_data, index=bots)\n",
    "\n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        data_df = data_df.div(data_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Create stacked bar chart\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "    # Define colors for each collision type\n",
    "    colors = {\n",
    "        'Hit': '#2ca02c',         # Green (wins)\n",
    "        'Struck': '#d62728',   # Red (losses)\n",
    "        'Tie': '#ff7f0e'          # Orange (ties)\n",
    "    }\n",
    "\n",
    "    # Create bot labels with rank\n",
    "    if rank_map:\n",
    "        bot_labels = [f\"{bot} (#{int(rank_map[bot])})\" for bot in bots]\n",
    "    else:\n",
    "        bot_labels = bots\n",
    "\n",
    "    # Plot stacked bars\n",
    "    bottom = np.zeros(len(bots))\n",
    "    x_pos = np.arange(len(bots))\n",
    "    for collision_type in collision_data.keys():\n",
    "        ax.bar(x_pos, data_df[collision_type], bottom=bottom,\n",
    "               label=collision_type, color=colors[collision_type], width=0.6)\n",
    "        bottom += data_df[collision_type]\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(bot_labels)\n",
    "    ax.set_xlabel('Bots', fontsize=12, fontweight='bold')\n",
    "\n",
    "    if normalize:\n",
    "        ax.set_ylabel('Collision Distribution (%)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Collision Type Distribution per Bot (Normalized)',\n",
    "                     fontsize=14, fontweight='bold', pad=15)\n",
    "        ax.set_ylim(0, 100)\n",
    "    else:\n",
    "        ax.set_ylabel('Total Collision Count', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Collision Type Distribution per Bot',\n",
    "                     fontsize=14, fontweight='bold', pad=15)\n",
    "        \n",
    "    legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=3,\n",
    "              fontsize=10, framealpha=0.9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    # Rotate x-axis labels if many bots\n",
    "    if len(bots) > 5:\n",
    "        plt.setp(ax.get_xticklabels(), rotation=30, ha='right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_collision_timebins_intensity(\n",
    "    df,\n",
    "    group_by=\"Bot_L\",  # \"Bot_L\" or \"Bot_R\"\n",
    "    timer=None,\n",
    "    act_interval=None,\n",
    "    round=None,\n",
    "    mode=\"total\",        # \"total\" | \"per_type\" | \"select\"\n",
    "    collision_type=None,  # \"Actor_L\" | \"Actor_R\" | \"Tie\" (used when mode == \"select\")\n",
    "    width=10,\n",
    "    height=6,\n",
    "    summary_df=None,     # Optional: summary dataframe with Rank_L column for bot ranking\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot collision intensity over time (with optional timer cutoff).\n",
    "\n",
    "    Modes:\n",
    "      - \"total\": sum all collision types -> one line per bot pairing\n",
    "      - \"per_type\": show per-collision-type trends; creates one subplot per type (Actor_L, Actor_R, Tie)\n",
    "      - \"select\": plot a single collision_type for all bot pairings\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame from summary_collision_timebins.csv\n",
    "        group_by: \"Bot_L\" or \"Bot_R\" to group by bot\n",
    "        timer: Filter by specific timer value\n",
    "        act_interval: Filter by specific action interval\n",
    "        round: Filter by specific round\n",
    "        mode: Visualization mode\n",
    "        collision_type: Which collision type to show (for mode=\"select\")\n",
    "        width, height: Figure dimensions\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Filters ---\n",
    "    if timer is not None:\n",
    "        df = df[df[\"Timer\"] == timer]\n",
    "    if act_interval is not None:\n",
    "        df = df[df[\"ActInterval\"] == act_interval]\n",
    "    if round is not None:\n",
    "        df = df[df[\"Round\"] == round]\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ No data after filtering.\")\n",
    "        return None\n",
    "\n",
    "    # --- Preprocess TimeBin ---\n",
    "    df = df.copy()\n",
    "    df[\"TimeBin\"] = pd.to_numeric(df[\"TimeBin\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"TimeBin\"])\n",
    "    df = df.sort_values(\"TimeBin\")\n",
    "\n",
    "    # --- Add rank to bot names if group_by is a bot column ---\n",
    "    rank_map = None\n",
    "    if group_by in [\"Bot_L\", \"Bot_R\"]:\n",
    "        # Try to get rank from summary_df first, then from df itself\n",
    "        if summary_df is not None and \"Rank_L\" in summary_df.columns:\n",
    "            rank_map = summary_df.groupby(\"Bot_L\")[\"Rank_L\"].first().to_dict()\n",
    "        elif \"Rank_L\" in df.columns:\n",
    "            rank_map = df.groupby(group_by)[\"Rank_L\"].first().to_dict()\n",
    "\n",
    "    if rank_map:\n",
    "        df[\"BotWithRank\"] = df[group_by].map(lambda b: f\"{b} (#{int(rank_map.get(b, 999))})\")\n",
    "        group_by_plot = \"BotWithRank\"\n",
    "        # Sort bots by rank\n",
    "        bot_order = sorted(rank_map.keys(), key=lambda b: rank_map.get(b, 999))\n",
    "        bot_order_with_rank = [f\"{b} (#{int(rank_map[b])})\" for b in bot_order]\n",
    "    else:\n",
    "        group_by_plot = group_by\n",
    "        bot_order_with_rank = None\n",
    "\n",
    "    # --- Helper: apply x-axis cutoff ---\n",
    "    def apply_timer_xlim(ax):\n",
    "        if timer is not None:\n",
    "            ax.set_xlim(0, timer)\n",
    "            ax.set_xticks(range(0, int(timer) + 1, max(1, int(timer // 10) or 1)))\n",
    "\n",
    "    # --- Plot modes ---\n",
    "    if mode == \"select\":\n",
    "        if not collision_type:\n",
    "            raise ValueError(\"collision_type must be provided when mode='select'\")\n",
    "        if collision_type not in [\"Actor_L\", \"Actor_R\", \"Tie\"]:\n",
    "            raise ValueError(\"collision_type must be one of ['Actor_L', 'Actor_R', 'Tie']\")\n",
    "\n",
    "        grouped = df.groupby([group_by_plot, \"TimeBin\"], as_index=False)[collision_type].mean()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        plot_with_bot_markers(ax, data=grouped, x=\"TimeBin\", y=collision_type,\n",
    "                            hue=group_by_plot, hue_order=bot_order_with_rank)\n",
    "        ax.set_title(f\"Mean {collision_type} collisions over time\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Mean Count\")\n",
    "        legend_title = \"Bot (Rank)\" if (group_by in [\"Bot_L\", \"Bot_R\"] and rank_map is not None) else group_by\n",
    "\n",
    "        # Calculate dynamic padding for legend\n",
    "        legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "        ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=3,\n",
    "                 framealpha=0.9, markerscale=1.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        apply_timer_xlim(ax)\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    elif mode == \"total\":\n",
    "        # Sum all collision types\n",
    "        df[\"TotalCollisions\"] = df[\"Actor_L\"] + df[\"Actor_R\"] + df[\"Tie\"]\n",
    "        grouped = df.groupby([group_by_plot, \"TimeBin\"], as_index=False)[\"TotalCollisions\"].mean()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height))\n",
    "        plot_with_bot_markers(ax, data=grouped, x=\"TimeBin\", y=\"TotalCollisions\",\n",
    "                            hue=group_by_plot, hue_order=bot_order_with_rank)\n",
    "        ax.set_title(\"Total collision intensity over time\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Mean Count (summed over collision types)\")\n",
    "        legend_title = \"Bot (Rank)\" if (group_by in [\"Bot_L\", \"Bot_R\"] and rank_map is not None) else group_by\n",
    "\n",
    "        # Calculate dynamic padding for legend\n",
    "        legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "        ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, legend_padding), ncol=3,\n",
    "                 framealpha=0.9, markerscale=1.2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        apply_timer_xlim(ax)\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    elif mode == \"per_type\":\n",
    "        collision_types = [\"Actor_L\", \"Actor_R\", \"Tie\"]\n",
    "        n = len(collision_types)\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=1,\n",
    "            ncols=n,\n",
    "            figsize=(width, height),\n",
    "            squeeze=False\n",
    "        )\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        handles, labels = None, None\n",
    "        for i, ctype in enumerate(collision_types):\n",
    "            ax = axes[i]\n",
    "            sub = df.groupby([group_by_plot, \"TimeBin\"], as_index=False)[ctype].mean()\n",
    "            if sub.empty:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "            # Plot with bot markers\n",
    "            plot_with_bot_markers(ax, data=sub, x=\"TimeBin\", y=ctype,\n",
    "                                hue=group_by_plot, hue_order=bot_order_with_rank)\n",
    "\n",
    "            # Capture legend handles from first plot, then remove it\n",
    "            if i == 0:\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "                legend = ax.get_legend()\n",
    "                if legend is not None:\n",
    "                    legend.remove()\n",
    "\n",
    "            ax.set_title(ctype)\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "            ax.set_ylabel(\"Mean Count\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            apply_timer_xlim(ax)\n",
    "\n",
    "        # Add global legend below\n",
    "        if handles and labels:\n",
    "            legend_title = \"Bot (Rank)\" if (group_by in [\"Bot_L\", \"Bot_R\"] and rank_map is not None) else group_by\n",
    "            fig.legend(\n",
    "                handles, labels, title=legend_title,\n",
    "                loc=\"upper center\", bbox_to_anchor=(0.5, -0.02),\n",
    "                ncol=min(6, len(labels))\n",
    "            )\n",
    "        fig.suptitle(\"Per-collision-type intensity over timer\")\n",
    "        fig.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be one of ['total','per_type','select']\")\n",
    "\n",
    "\n",
    "def prepare_correlation_data(df):\n",
    "    \"\"\"\n",
    "    Prepare data for correlation analysis by combining left and right perspectives.\n",
    "\n",
    "    Args:\n",
    "        df: Summary matchup dataframe\n",
    "\n",
    "    Returns:\n",
    "        Combined dataframe with all bots' data\n",
    "    \"\"\"\n",
    "    # Bot_L perspective\n",
    "    df_left = df.copy()\n",
    "    df_left['Bot'] = df_left['Bot_L']\n",
    "    df_left['WinRate'] = df_left['WinRate_L']\n",
    "    df_left['Actions'] = df_left['ActionCounts_L']\n",
    "    df_left['Collisions'] = df_left['Collisions_L']\n",
    "    df_left['Duration'] = df_left['Duration_L']\n",
    "    df_left['Accelerate_Act'] = df_left['Accelerate_Act_L']\n",
    "    df_left['TurnLeft_Act'] = df_left['TurnLeft_Act_L']\n",
    "    df_left['TurnRight_Act'] = df_left['TurnRight_Act_L']\n",
    "    df_left['Dash_Act'] = df_left['Dash_Act_L']\n",
    "    df_left['SkillBoost_Act'] = df_left['SkillBoost_Act_L']\n",
    "    df_left['SkillStone_Act'] = df_left['SkillStone_Act_L']\n",
    "    df_left['Accelerate_Dur'] = df_left['Accelerate_Dur_L']\n",
    "    df_left['TurnLeft_Dur'] = df_left['TurnLeft_Dur_L']\n",
    "    df_left['TurnRight_Dur'] = df_left['TurnRight_Dur_L']\n",
    "    df_left['Dash_Dur'] = df_left['Dash_Dur_L']\n",
    "    # df_left['SkillBoost_Dur'] = df_left['SkillBoost_Dur_L']\n",
    "    # df_left['SkillStone_Dur'] = df_left['SkillStone_Dur_L']\n",
    "\n",
    "    # Bot_R perspective\n",
    "    df_right = df.copy()\n",
    "    df_right['Bot'] = df_right['Bot_R']\n",
    "    df_right['WinRate'] = df_right['WinRate_R']\n",
    "    df_right['Actions'] = df_right['ActionCounts_R']\n",
    "    df_right['Collisions'] = df_right['Collisions_R']\n",
    "    df_right['Duration'] = df_right['Duration_R']\n",
    "    df_right['Accelerate_Act'] = df_right['Accelerate_Act_R']\n",
    "    df_right['TurnLeft_Act'] = df_right['TurnLeft_Act_R']\n",
    "    df_right['TurnRight_Act'] = df_right['TurnRight_Act_R']\n",
    "    df_right['Dash_Act'] = df_right['Dash_Act_R']\n",
    "    df_right['SkillBoost_Act'] = df_right['SkillBoost_Act_R']\n",
    "    df_right['SkillStone_Act'] = df_right['SkillStone_Act_R']\n",
    "    df_right['Accelerate_Dur'] = df_right['Accelerate_Dur_R']\n",
    "    df_right['TurnLeft_Dur'] = df_right['TurnLeft_Dur_R']\n",
    "    df_right['TurnRight_Dur'] = df_right['TurnRight_Dur_R']\n",
    "    df_right['Dash_Dur'] = df_right['Dash_Dur_R']\n",
    "    # df_right['SkillBoost_Dur'] = df_right['SkillBoost_Dur_R']\n",
    "    # df_right['SkillStone_Dur'] = df_right['SkillStone_Dur_R']\n",
    "\n",
    "    # Combine both perspectives\n",
    "    df_combined = pd.concat([df_left, df_right], ignore_index=True)\n",
    "\n",
    "    # Add derived columns\n",
    "    df_combined['RoundNumeric'] = df_combined['Round'].map({'BestOf1': 1, 'BestOf3': 3})\n",
    "    df_combined['TotalSkillAct'] = df_combined['SkillBoost_Act'] + df_combined['SkillStone_Act']\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "def plot_correlation_scatter(data, x_col, y_col, title, color_by='Bot',\n",
    "                            alpha=0.95, figsize=(10, 8), add_jitter=False, add_per_bot_regression=False):\n",
    "    \"\"\"\n",
    "    Create scatter plot with regression line and Pearson correlation.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame with data to plot\n",
    "        x_col: Column name for x-axis\n",
    "        y_col: Column name for y-axis (should be WinRate)\n",
    "        title: Plot title\n",
    "        color_by: Column to color points by (default: 'Bot')\n",
    "        alpha: Transparency of scatter points\n",
    "        figsize: Figure size tuple\n",
    "        add_jitter: If True, add jitter to x-axis for discrete variables\n",
    "        add_per_bot_regression: If True, add regression line for each bot\n",
    "\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    # Remove NaN values\n",
    "    plot_data = data[[x_col, y_col, color_by]].dropna().copy()\n",
    "\n",
    "    if len(plot_data) == 0:\n",
    "        return None\n",
    "\n",
    "    # Calculate Pearson correlation (on original data)\n",
    "    pearson_r, pearson_p = stats.pearsonr(plot_data[x_col], plot_data[y_col])\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Add jitter for discrete variables to spread out points\n",
    "    x_values = plot_data[x_col].values.copy()\n",
    "    if add_jitter:\n",
    "        unique_vals = np.unique(x_values)\n",
    "        if len(unique_vals) <= 5:  # Discrete variable\n",
    "            x_range = x_values.max() - x_values.min()\n",
    "            jitter_amount = x_range * 0.02 if x_range > 0 else 0.01\n",
    "            x_jittered = x_values + np.random.normal(0, jitter_amount, size=len(x_values))\n",
    "            plot_data['x_jittered'] = x_jittered\n",
    "        else:\n",
    "            plot_data['x_jittered'] = x_values\n",
    "    else:\n",
    "        plot_data['x_jittered'] = x_values\n",
    "\n",
    "    # Get bot rankings if available\n",
    "    rank_map = {}\n",
    "    if 'Rank_L' in data.columns and color_by == 'Bot':\n",
    "        rank_map = data.groupby('Bot')['Rank_L'].first().to_dict()\n",
    "\n",
    "    # Scatter plot with colors by bot\n",
    "    if color_by in plot_data.columns:\n",
    "        unique_values = plot_data[color_by].unique()\n",
    "        # Sort by rank if available, otherwise alphabetically\n",
    "        if rank_map:\n",
    "            unique_values = sorted(unique_values, key=lambda v: rank_map.get(v, 999))\n",
    "        else:\n",
    "            unique_values = sorted(unique_values)\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_values)))\n",
    "\n",
    "        for idx, value in enumerate(unique_values):\n",
    "            mask = plot_data[color_by] == value\n",
    "\n",
    "            # Get bot marker\n",
    "            marker = get_bot_marker(value) if color_by == 'Bot' else 'o'\n",
    "\n",
    "            # Create label with rank if available\n",
    "            if rank_map and value in rank_map:\n",
    "                label = f\"{value} (#{int(rank_map[value])})\"\n",
    "            else:\n",
    "                label = value\n",
    "\n",
    "            ax.scatter(plot_data[mask]['x_jittered'], plot_data[mask][y_col],\n",
    "                      label=label, alpha=alpha, s=60, color=colors[idx],\n",
    "                      marker=marker, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "            # Add per-bot regression line if requested\n",
    "            if add_per_bot_regression:\n",
    "                bot_x = plot_data[mask][x_col].values\n",
    "                bot_y = plot_data[mask][y_col].values\n",
    "                if len(bot_x) > 1 and bot_x.std() > 0:  # Need at least 2 points and variance for regression\n",
    "                    bot_slope, bot_intercept = np.polyfit(bot_x, bot_y, 1)\n",
    "                    bot_x_line = np.linspace(bot_x.min(), bot_x.max(), 100)\n",
    "                    bot_y_line = bot_slope * bot_x_line + bot_intercept\n",
    "                    ax.plot(bot_x_line, bot_y_line, '--', linewidth=1.5, color=colors[idx], alpha=0.7)\n",
    "    else:\n",
    "        ax.scatter(plot_data['x_jittered'], plot_data[y_col], alpha=alpha, s=60,\n",
    "                  edgecolors='black', linewidth=0.5)\n",
    "\n",
    "    # Add overall regression line (using original non-jittered data)\n",
    "    slope, intercept = np.polyfit(x_values, plot_data[y_col], 1)\n",
    "    x_line = np.linspace(x_values.min(), x_values.max(), 100)\n",
    "    y_line = slope * x_line + intercept\n",
    "    ax.plot(x_line, y_line, 'r-', linewidth=2.5, label=f'Overall Regression')\n",
    "\n",
    "    # Add correlation info to plot\n",
    "    corr_text = f'Pearson r = {pearson_r:.3f}\\np-value = {pearson_p:.3e}\\nn = {len(plot_data)}'\n",
    "    ax.text(0.05, 0.95, corr_text, transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "            facecolor='wheat', alpha=0.8), fontsize=10, family='monospace')\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(get_metric_name(x_col), fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(get_metric_name(y_col), fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Legend - position below x-axis\n",
    "    if color_by in plot_data.columns:\n",
    "        legend_title = \"Bot (Rank)\" if (color_by == 'Bot' and rank_map) else color_by\n",
    "        legend_padding = calculate_legend_padding(ax, rotation=0)\n",
    "        ax.legend(title=legend_title, loc='upper center', bbox_to_anchor=(0.5, legend_padding),\n",
    "                 fontsize=8, framealpha=0.9, ncol=3, markerscale=1.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_all_correlations(df, width=10, height=8,alpha=0.2):\n",
    "    \"\"\"\n",
    "    Create all correlation plots for win rate analysis.\n",
    "    For config variables, creates separate plots for each config value.\n",
    "\n",
    "    Args:\n",
    "        df: Summary matchup dataframe\n",
    "        width: Figure width\n",
    "        height: Figure height\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of figures with nested structure for config-separated plots\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    data = prepare_correlation_data(df)\n",
    "\n",
    "    figs = {}\n",
    "\n",
    "    # a. Winrate vs ActInterval (direct correlation with per-bot regression)\n",
    "    fig = plot_correlation_scatter(\n",
    "        data,\n",
    "        x_col='ActInterval',\n",
    "        y_col='WinRate',\n",
    "        title='Win Rate vs Action Interval\\n(All Bots Combined)',\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False,\n",
    "        add_per_bot_regression=True,alpha=alpha\n",
    "    )\n",
    "    if fig:\n",
    "        figs['actinterval'] = fig\n",
    "\n",
    "    # b. Winrate vs Round type (direct correlation with per-bot regression)\n",
    "    # Build dynamic round type mapping for title\n",
    "    round_mapping = data[['Round', 'RoundNumeric']].drop_duplicates().dropna()\n",
    "    round_labels = ', '.join([f\"{int(row['RoundNumeric'])}={row['Round']}\"\n",
    "                              for _, row in round_mapping.sort_values('RoundNumeric').iterrows()])\n",
    "    round_title = f'Win Rate vs Round Type ({round_labels})\\n(All Bots Combined)' if round_labels else 'Win Rate vs Round Type\\n(All Bots Combined)'\n",
    "\n",
    "    fig = plot_correlation_scatter(\n",
    "        data,\n",
    "        x_col='RoundNumeric',\n",
    "        y_col='WinRate',\n",
    "        title=round_title,\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False,\n",
    "        add_per_bot_regression=True,alpha=alpha\n",
    "    )\n",
    "    if fig:\n",
    "        figs['roundtype'] = fig\n",
    "\n",
    "    # c. Winrate vs Timer (direct correlation with per-bot regression)\n",
    "    fig = plot_correlation_scatter(\n",
    "        data,\n",
    "        x_col='Timer',\n",
    "        y_col='WinRate',\n",
    "        title='Win Rate vs Timer Duration\\n(All Bots Combined)',\n",
    "        figsize=(width, height),\n",
    "        add_jitter=False,\n",
    "        add_per_bot_regression=True,alpha=alpha\n",
    "    )\n",
    "    if fig:\n",
    "        figs['timer'] = fig\n",
    "\n",
    "    # d. Winrate vs Skill Type (direct correlation with per-bot regression)\n",
    "    # Add numeric encoding for skill type\n",
    "    if 'SkillLeft' in data.columns:\n",
    "        skill_map = {'Stone': 1, 'Boost': 2}\n",
    "        data['SkillNumeric'] = data['SkillLeft'].map(skill_map)\n",
    "        fig = plot_correlation_scatter(\n",
    "            data,\n",
    "            x_col='SkillNumeric',\n",
    "            y_col='WinRate',\n",
    "            title='Win Rate vs Skill Type (1=Stone, 2=Boost)\\n(All Bots Combined)',\n",
    "            figsize=(width, height),\n",
    "            add_jitter=False,\n",
    "            add_per_bot_regression=True,alpha=alpha\n",
    "        )\n",
    "        if fig:\n",
    "            figs['skilltype'] = fig\n",
    "\n",
    "    # e. Winrate vs Individual Actions\n",
    "    action_types = ['Accelerate_Act', 'TurnLeft_Act', 'TurnRight_Act',\n",
    "                   'Dash_Act', 'SkillBoost_Act', 'SkillStone_Act']\n",
    "\n",
    "    # Get bot rankings if available\n",
    "    rank_map = {}\n",
    "    if 'Rank_L' in data.columns:\n",
    "        rank_map = data.groupby('Bot')['Rank_L'].first().to_dict()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(width*1.2, height*1.5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, action in enumerate(action_types):\n",
    "        if action not in data.columns:\n",
    "            continue\n",
    "\n",
    "        plot_data = data[[action, 'WinRate', 'Bot']].dropna()\n",
    "\n",
    "        if len(plot_data) == 0:\n",
    "            axes[idx].text(0.5, 0.5, f'No data for {action}',\n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            continue\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson_r, pearson_p = stats.pearsonr(plot_data[action], plot_data['WinRate'])\n",
    "\n",
    "        # Scatter plot - sort bots by rank\n",
    "        unique_bots = plot_data['Bot'].unique()\n",
    "        if rank_map:\n",
    "            # Sort bots by rank\n",
    "            unique_bots = sorted(unique_bots, key=lambda b: rank_map.get(b, 999))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_bots)))\n",
    "\n",
    "        for bot_idx, bot in enumerate(unique_bots):\n",
    "            mask = plot_data['Bot'] == bot\n",
    "            marker = get_bot_marker(bot)\n",
    "\n",
    "            # Create label with rank if available\n",
    "            if rank_map and bot in rank_map:\n",
    "                label = f\"{bot} (#{int(rank_map[bot])})\"\n",
    "            else:\n",
    "                label = bot\n",
    "\n",
    "            axes[idx].scatter(plot_data[mask][action], plot_data[mask]['WinRate'],\n",
    "                            label=label, alpha=alpha, s=30, color=colors[bot_idx],\n",
    "                            marker=marker, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "            # Per-bot regression line\n",
    "            bot_x = plot_data[mask][action].values\n",
    "            bot_y = plot_data[mask]['WinRate'].values\n",
    "            if len(bot_x) > 1 and bot_x.std() > 0:  # Need at least 2 points and variance for regression\n",
    "                bot_slope, bot_intercept = np.polyfit(bot_x, bot_y, 1)\n",
    "                bot_x_line = np.linspace(bot_x.min(), bot_x.max(), 100)\n",
    "                bot_y_line = bot_slope * bot_x_line + bot_intercept\n",
    "                axes[idx].plot(bot_x_line, bot_y_line, '--', linewidth=1.5, color=colors[bot_idx], alpha=0.7)\n",
    "\n",
    "        # Overall regression line\n",
    "        slope, intercept = np.polyfit(plot_data[action], plot_data['WinRate'], 1)\n",
    "        x_line = np.linspace(plot_data[action].min(), plot_data[action].max(), 100)\n",
    "        y_line = slope * x_line + intercept\n",
    "        axes[idx].plot(x_line, y_line, 'r-', linewidth=2.5)\n",
    "\n",
    "        # Correlation info\n",
    "        corr_text = f'r={pearson_r:.3f}\\np={pearson_p:.2e}'\n",
    "        axes[idx].text(0.05, 0.95, corr_text, transform=axes[idx].transAxes,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat', alpha=0.8), fontsize=8, family='monospace')\n",
    "\n",
    "        axes[idx].set_xlabel(get_metric_name(action), fontsize=10)\n",
    "        axes[idx].set_ylabel(get_metric_name('WinRate'), fontsize=10)\n",
    "        axes[idx].set_title(f'{get_metric_name(\"WinRate\")} vs {get_metric_name(action)}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add legend below x-axis with rank title if rankings are available\n",
    "    handles, labels = [], []\n",
    "    for ax in fig.axes:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        handles.extend(h)\n",
    "        labels.extend(l)\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    unique = dict(zip(labels, handles))\n",
    "    legend_title = 'Bot (Rank)' if rank_map else 'Bot'\n",
    "    fig.legend(unique.values(), unique.keys(),\n",
    "           title=legend_title, fontsize=6,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, -0.05),\n",
    "           framealpha=0.7, ncol=3)\n",
    "\n",
    "    plt.suptitle('Win Rate vs Individual Action Types\\n(All Bots Combined)',\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    figs['actions'] = fig\n",
    "\n",
    "    # e. Winrate vs Individual Actions\n",
    "    action_types = ['Accelerate_Dur', 'TurnLeft_Dur', 'TurnRight_Dur', 'Dash_Dur']\n",
    "\n",
    "    # Get bot rankings if available (reuse from above if already set)\n",
    "    if 'rank_map' not in locals():\n",
    "        rank_map = {}\n",
    "        if 'Rank_L' in data.columns:\n",
    "            rank_map = data.groupby('Bot')['Rank_L'].first().to_dict()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(width*1.2, height*1.5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, action in enumerate(action_types):\n",
    "        if action not in data.columns:\n",
    "            continue\n",
    "\n",
    "        plot_data = data[[action, 'WinRate', 'Bot']].dropna()\n",
    "\n",
    "        if len(plot_data) == 0:\n",
    "            axes[idx].text(0.5, 0.5, f'No data for {action}',\n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            continue\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson_r, pearson_p = stats.pearsonr(plot_data[action], plot_data['WinRate'])\n",
    "\n",
    "        # Scatter plot - sort bots by rank\n",
    "        unique_bots = plot_data['Bot'].unique()\n",
    "        if rank_map:\n",
    "            # Sort bots by rank\n",
    "            unique_bots = sorted(unique_bots, key=lambda b: rank_map.get(b, 999))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_bots)))\n",
    "\n",
    "        for bot_idx, bot in enumerate(unique_bots):\n",
    "            mask = plot_data['Bot'] == bot\n",
    "            marker = get_bot_marker(bot)\n",
    "\n",
    "            # Create label with rank if available\n",
    "            if rank_map and bot in rank_map:\n",
    "                label = f\"{bot} (#{int(rank_map[bot])})\"\n",
    "            else:\n",
    "                label = bot\n",
    "\n",
    "            axes[idx].scatter(plot_data[mask][action], plot_data[mask]['WinRate'],\n",
    "                            label=label, alpha=alpha, s=30, color=colors[bot_idx],\n",
    "                            marker=marker, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "            # Per-bot regression line\n",
    "            bot_x = plot_data[mask][action].values\n",
    "            bot_y = plot_data[mask]['WinRate'].values\n",
    "            if len(bot_x) > 1 and bot_x.std() > 0:  # Need at least 2 points and variance for regression\n",
    "                bot_slope, bot_intercept = np.polyfit(bot_x, bot_y, 1)\n",
    "                bot_x_line = np.linspace(bot_x.min(), bot_x.max(), 100)\n",
    "                bot_y_line = bot_slope * bot_x_line + bot_intercept\n",
    "                axes[idx].plot(bot_x_line, bot_y_line, '--', linewidth=1.5, color=colors[bot_idx], alpha=0.7)\n",
    "\n",
    "        # Overall regression line\n",
    "        slope, intercept = np.polyfit(plot_data[action], plot_data['WinRate'], 1)\n",
    "        x_line = np.linspace(plot_data[action].min(), plot_data[action].max(), 100)\n",
    "        y_line = slope * x_line + intercept\n",
    "        axes[idx].plot(x_line, y_line, 'r-', linewidth=2.5)\n",
    "\n",
    "        # Correlation info\n",
    "        corr_text = f'r={pearson_r:.3f}\\np={pearson_p:.2e}'\n",
    "        axes[idx].text(0.05, 0.95, corr_text, transform=axes[idx].transAxes,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat', alpha=0.8), fontsize=8, family='monospace')\n",
    "\n",
    "        axes[idx].set_xlabel(get_metric_name(action), fontsize=10)\n",
    "        axes[idx].set_ylabel(get_metric_name('WinRate'), fontsize=10)\n",
    "        axes[idx].set_title(f'{get_metric_name(\"WinRate\")} vs {get_metric_name(action)}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add legend below x-axis with rank title if rankings are available\n",
    "    handles, labels = [], []\n",
    "    for ax in fig.axes:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        handles.extend(h)\n",
    "        labels.extend(l)\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    unique = dict(zip(labels, handles))\n",
    "    legend_title = 'Bot (Rank)' if rank_map else 'Bot'\n",
    "    fig.legend(unique.values(), unique.keys(),\n",
    "           title=legend_title, fontsize=6,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, -0.05),\n",
    "           framealpha=0.7, ncol=3)\n",
    "\n",
    "    plt.suptitle('Win Rate vs Individual Action Duration\\n(All Bots Combined)',\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    figs['actions_dur'] = fig\n",
    "\n",
    "    # f. Winrate vs Collision Types (Hit, Struck, Tie) - Combined across all configs\n",
    "    collision_types = ['Collisions_L', 'Collisions_R', 'Collisions_Tie']\n",
    "    collision_labels = {'Collisions_L': 'Hit', 'Collisions_R': 'Struck', 'Collisions_Tie': 'Tie'}\n",
    "\n",
    "    # Get bot rankings if available\n",
    "    rank_map = {}\n",
    "    if 'Rank_L' in data.columns:\n",
    "        rank_map = data.groupby('Bot')['Rank_L'].first().to_dict()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(width*1.8, height))\n",
    "\n",
    "    for idx, col_type in enumerate(collision_types):\n",
    "        if col_type not in data.columns:\n",
    "            continue\n",
    "\n",
    "        plot_data = data[[col_type, 'WinRate', 'Bot']].dropna()\n",
    "\n",
    "        if len(plot_data) < 2:\n",
    "            axes[idx].text(0.5, 0.5, f'Insufficient data',\n",
    "                          ha='center', va='center', transform=axes[idx].transAxes)\n",
    "            continue\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        pearson_r, pearson_p = stats.pearsonr(plot_data[col_type], plot_data['WinRate'])\n",
    "\n",
    "        # Get unique bots and assign colors - sort by rank\n",
    "        unique_bots = plot_data['Bot'].unique()\n",
    "        if rank_map:\n",
    "            # Sort bots by rank\n",
    "            unique_bots = sorted(unique_bots, key=lambda b: rank_map.get(b, 999))\n",
    "        else:\n",
    "            unique_bots = sorted(unique_bots)\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_bots)))\n",
    "\n",
    "        # Scatter plot colored by bot\n",
    "        for bot_idx, bot in enumerate(unique_bots):\n",
    "            bot_data = plot_data[plot_data['Bot'] == bot]\n",
    "            marker = get_bot_marker(bot)\n",
    "\n",
    "            # Create label with rank if available\n",
    "            if rank_map and bot in rank_map:\n",
    "                label = f\"{bot} (#{int(rank_map[bot])})\"\n",
    "            else:\n",
    "                label = bot\n",
    "\n",
    "            axes[idx].scatter(bot_data[col_type], bot_data['WinRate'],\n",
    "                            alpha=alpha, s=60, color=colors[bot_idx], marker=marker,\n",
    "                            label=label, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "        # Overall regression line\n",
    "        if len(plot_data) >= 2 and plot_data[col_type].std() > 0:\n",
    "            slope, intercept = np.polyfit(plot_data[col_type], plot_data['WinRate'], 1)\n",
    "            x_line = np.linspace(plot_data[col_type].min(), plot_data[col_type].max(), 100)\n",
    "            y_line = slope * x_line + intercept\n",
    "            axes[idx].plot(x_line, y_line, 'r-', linewidth=2.5, label='Overall Regression')\n",
    "\n",
    "        # Correlation info\n",
    "        corr_text = f'r={pearson_r:.3f}\\np={pearson_p:.2e}'\n",
    "        axes[idx].text(0.05, 0.95, corr_text, transform=axes[idx].transAxes,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                      facecolor='wheat', alpha=0.8), fontsize=10, family='monospace')\n",
    "\n",
    "        axes[idx].set_xlabel(collision_labels[col_type], fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_ylabel(get_metric_name('WinRate'), fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_title(f'{get_metric_name(\"WinRate\")} vs {collision_labels[col_type]}',\n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "    # Add legend below x-axis with rank title if rankings are available\n",
    "    handles, labels = [], []\n",
    "    for ax in fig.axes:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        handles.extend(h)\n",
    "        labels.extend(l)\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    unique = dict(zip(labels, handles))\n",
    "    legend_title = 'Bot (Rank)' if rank_map else 'Bot'\n",
    "    fig.legend(unique.values(), unique.keys(),\n",
    "           title=legend_title, fontsize=6,\n",
    "           loc='upper center',\n",
    "           bbox_to_anchor=(0.5, -0.05),\n",
    "           framealpha=0.7, ncol=3)\n",
    "\n",
    "\n",
    "    plt.suptitle(f'Win Rate vs Collision Types\\n(All Bots Combined)',\n",
    "                 fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    figs['collisions'] = fig\n",
    "\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary data\n",
    "df_sum = pd.read_csv(\"summary_bot.csv\").rename(columns={\"Duration\": \"Duration (ms)\"})\n",
    "df = pd.read_csv(\"summary_matchup.csv\")\n",
    "df_timebins = pd.read_csv(\"summary_action_timebins.csv\")\n",
    "df_collision_timebins = pd.read_csv(\"summary_collision_timebins.csv\")\n",
    "\n",
    "# Configuration\n",
    "cfg = {\n",
    "    \"Timer\": sorted(df[\"Timer\"].unique().tolist()),\n",
    "    \"ActInterval\": sorted(df[\"ActInterval\"].unique().tolist()),\n",
    "    \"Round\": sorted(df[\"Round\"].unique().tolist()),\n",
    "    \"SkillLeft\": sorted(df[\"SkillLeft\"].unique().tolist()),\n",
    "    \"SkillRight\": sorted(df[\"SkillRight\"].unique().tolist()),\n",
    "    \"Bots\": sorted(df[\"Bot_L\"].unique().tolist()),\n",
    "}\n",
    "bots = str.join(\", \", cfg[\"Bots\"])\n",
    "\n",
    "# Display settings\n",
    "width = 10\n",
    "height = 6\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"\\nBots in experiment: {bots}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Matchup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Matchup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Analysis\n",
    "\n",
    "Analyze bot agents facing other agents with similar configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot Behaviour Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions Behaviour\n",
    "Mean action counts per bot across all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_action_radar(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collision Behaviour\n",
    "Hit/Struck/Tie distribution per bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_collision_radar(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win Rate Matrix\n",
    "\n",
    "Shows how often each bot wins against others across different matchups.\n",
    "This is calculated with taking mean of each configuration (10-games iteration matchup) resulting 240 games in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_winrate_matrix(df, width, height)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Taken (All Configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_overall_bot_metrics(df, metric=\"ActionCounts_L\", title=\"Mean Action per Bot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Duration (All Configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_overall_bot_metrics(df, metric=\"Duration_L\", title=\"Mean Action Duration per Bot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision (All Configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_overall_bot_metrics(df, metric=\"Collisions_L\", title=\"Mean Collisions per Bot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Duration (All Configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_overall_bot_metrics(df, metric=\"MatchDur\", title=\"Mean Match Duration per Bot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win Rate Grouped by Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, config_col=\"Timer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win Rate Grouped by Action Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, config_col=\"ActInterval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win Rate Grouped by Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, config_col=\"Round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Win Rate Grouped by Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, config_col=\"Skill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Grouped by Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Collisions_L\", config_col=\"Timer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Grouped by Action Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Collisions_L\", config_col=\"ActInterval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Grouped by Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Collisions_L\", config_col=\"Round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Grouped by Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Collisions_L\", config_col=\"Skill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Taken Grouped by Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"ActionCounts_L\", config_col=\"Timer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Taken Grouped by Action Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"ActionCounts_L\", config_col=\"ActInterval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Taken Grouped by Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"ActionCounts_L\", config_col=\"Round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Taken Grouped by Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"ActionCounts_L\", config_col=\"Skill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Duration Grouped by Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Duration_L\", config_col=\"Timer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Duration Grouped by Action Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Duration_L\", config_col=\"ActInterval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Duration Grouped by Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Duration_L\", config_col=\"Round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Duration Grouped by Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"Duration_L\", config_col=\"Skill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Duration Grouped by Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"MatchDur\", config_col=\"Timer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Duration Grouped by Action Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"MatchDur\", config_col=\"ActInterval\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Duration Grouped by Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"MatchDur\", config_col=\"Round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Duration Grouped by Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_grouped_config_winrates(df, metric=\"MatchDur\", config_col=\"Skill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Related Trends\n",
    "\n",
    "Analyzes Bots aggressiveness over game duration with determining how much action taken duration related to the overall game duration (Time Setting).\n",
    "Higher timers don't always lead to longer matches. Some matchups finish fights early regardless of time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = plot_time_related(df, width, height)\n",
    "for fig in figs:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Distribution per Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_action_distribution_stacked(df, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Intensity Over Time (Per Configuration)\n",
    "\n",
    "Shows action intensity over time for different timer and action interval configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timI in cfg[\"Timer\"]:\n",
    "    for actI in cfg[\"ActInterval\"]:\n",
    "        print(f\"\\n--- Timer={timI}, ActionInterval={actI} ---\")\n",
    "        \n",
    "        # Total action intensity\n",
    "        fig = plot_timebins_intensity(df_timebins, timer=timI, act_interval=actI, mode=\"total\", summary_df=df)\n",
    "        if fig:\n",
    "            plt.show()\n",
    "        \n",
    "        # Per-action intensity\n",
    "        fig = plot_timebins_intensity(df_timebins, timer=timI, act_interval=actI, mode=\"per_action\", summary_df=df)\n",
    "        if fig:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Intensity Over All Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total action intensity\n",
    "fig = plot_timebins_intensity(df_timebins, mode=\"total\", timer=60, summary_df=df)\n",
    "if fig:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-action intensity\n",
    "fig = plot_timebins_intensity(df_timebins, mode=\"per_action\", timer=60, summary_df=df)\n",
    "if fig:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Intensity Over Time (Per Configuration)\n",
    "\n",
    "Shows collision intensity over time for different timer and action interval configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timI in cfg[\"Timer\"]:\n",
    "    for actI in cfg[\"ActInterval\"]:\n",
    "        print(f\"\\n--- Timer={timI}, ActionInterval={actI} ---\")\n",
    "        \n",
    "        # Total collision intensity\n",
    "        fig = plot_collision_timebins_intensity(df_collision_timebins, timer=timI, act_interval=actI, mode=\"total\", summary_df=df)\n",
    "        if fig:\n",
    "            plt.show()\n",
    "        \n",
    "        # Per-type collision intensity\n",
    "        fig = plot_collision_timebins_intensity(df_collision_timebins, timer=timI, act_interval=actI, mode=\"per_type\", summary_df=df)\n",
    "        if fig:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Detail Distribution per Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_collision_distribution_stacked(df, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Intensity Over All Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total collision intensity\n",
    "fig = plot_collision_timebins_intensity(df_collision_timebins, mode=\"total\", timer=60, summary_df=df)\n",
    "if fig:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-type collision intensity\n",
    "fig = plot_collision_timebins_intensity(df_collision_timebins, mode=\"per_type\", timer=60, summary_df=df)\n",
    "if fig:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Taken vs. Win Relation\n",
    "\n",
    "Does spending most action (aggressive) lead to a win?\n",
    "This taking mean of action-taken per games versus win-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_action_win_related(df, width, height)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Analysis (Overall)\n",
    "\n",
    "Correlation analysis using Pearson coefficient with scatter plots and regression lines.\n",
    "All data from all bots combined, separated by configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_figs = plot_all_correlations(df, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Bot Analysis\n",
    "\n",
    "Analyze bot agent against its different configurations.\n",
    "Each of report: Win Rate; Collision; Action-Taken; Duration; is calculated with averaging data from matchup (left and right position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Analysis (Per Bot)\n",
    "\n",
    "Detailed plots for individual bots, separated by configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique bots\n",
    "bots_list = sorted(df['Bot_L'].unique())\n",
    "print(f\"Analyzing {len(bots_list)} bots: {bots_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual bot correlation analysis\n",
    "for bot in bots_list:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing correlations for {bot}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    correlation_figs = plot_individual_bot_correlations(df, bot, width, height)\n",
    "    \n",
    "    if not correlation_figs:\n",
    "        print(f\"No data available for {bot}\")\n",
    "        continue\n",
    "    \n",
    "    # Win Rate vs ActInterval\n",
    "    if 'actinterval' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Action Interval Configuration ---\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Win Rate vs Round Type\n",
    "    if 'roundtype' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Round Type Configuration ---\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Win Rate vs Timer\n",
    "    if 'timer' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Timer Configuration ---\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Win Rate vs Skill Type\n",
    "    if 'skilltype' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Skill Type Configuration ---\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Win Rate vs Action Types\n",
    "    if 'actions' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Individual Action Types ---\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Win Rate vs Action Duration\n",
    "    if 'actions_dur' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Individual Action Duration ---\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Win Rate vs Collisions\n",
    "    if 'collisions' in correlation_figs:\n",
    "        print(\"\\n--- Win Rate vs Collision Types (Hit, Struck, Tie) ---\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena Heatmaps - Bot Movement Analysis\n",
    "\n",
    "Visualize bot movement patterns across different game phases (Early, Mid, Late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if arena_heatmap directory exists\n",
    "heatmap_dir = \"arena_heatmaps\"\n",
    "\n",
    "if os.path.exists(heatmap_dir):\n",
    "    # Get all bot directories\n",
    "    bot_dirs = [d for d in os.listdir(heatmap_dir)\n",
    "               if os.path.isdir(os.path.join(heatmap_dir, d))]\n",
    "    \n",
    "    # Sort bot directories by rank from df_sum\n",
    "    if \"Rank\" in df_sum.columns and \"Bot\" in df_sum.columns:\n",
    "        rank_map = df_sum.groupby(\"Bot\")[\"Rank\"].first().to_dict()\n",
    "        bot_dirs = sorted(bot_dirs, key=lambda b: rank_map.get(b, 9999))\n",
    "    else:\n",
    "        bot_dirs = sorted(bot_dirs)\n",
    "    \n",
    "    if bot_dirs:\n",
    "        phase_names = [\"window_2.5-15s.png\", \"window_15-30s.png\", \"window_30-45s.png\", \"window_45-60s.png\"]\n",
    "        \n",
    "        # Display heatmaps for each bot\n",
    "        for bot_name in bot_dirs:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"{bot_name} (#{bot_dirs.index(bot_name)+1})\")\n",
    "            print(f\"{'='*60}\")\n",
    "            bot_dir = os.path.join(heatmap_dir, bot_name)\n",
    "            \n",
    "            # Display phase heatmaps\n",
    "            fig, axes = plt.subplots(1, len(phase_names), figsize=(20, 5))\n",
    "            for idx, phase_name in enumerate(phase_names):\n",
    "                image_path = os.path.join(bot_dir, phase_name)\n",
    "                if os.path.exists(image_path):\n",
    "                    image = Image.open(image_path)\n",
    "                    axes[idx].imshow(image)\n",
    "                    axes[idx].set_title(phase_name)\n",
    "                    axes[idx].axis('off')\n",
    "                else:\n",
    "                    axes[idx].text(0.5, 0.5, f\"Image not found:\\n{phase_name}\",\n",
    "                                  ha='center', va='center')\n",
    "                    axes[idx].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Display position distribution\n",
    "            dist_path = os.path.join(bot_dir, \"position_distribution.png\")\n",
    "            if os.path.exists(dist_path):\n",
    "                print(\"\\nPosition Distribution (X & Y Overlayed)\")\n",
    "                dist_image = Image.open(dist_path)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.imshow(dist_image)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            \n",
    "            # Display distance distribution\n",
    "            dist_path = os.path.join(bot_dir, \"distance_distribution.png\")\n",
    "            if os.path.exists(dist_path):\n",
    "                print(\"\\nDistance Distribution\")\n",
    "                dist_image = Image.open(dist_path)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.imshow(dist_image)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "            print(\"\\nFull Configuration Analysis\")\n",
    "            fig = plot_full_cross_heatmap_half(df, bot_name=bot_name, lower_triangle=True)\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No bot heatmaps found in directory\")\n",
    "        print(\"Run: `python detailed_analyzer.py all` to generate heatmaps\")\n",
    "else:\n",
    "    print(f\"Heatmap directory not found: {heatmap_dir}\")\n",
    "    print(\"Run: `python detailed_analyzer.py all` to generate heatmaps for all bots\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
